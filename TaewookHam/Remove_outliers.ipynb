{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03cddf50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import optuna\n",
    "from optuna.trial import Trial\n",
    "from optuna.samplers import TPESampler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from typing import List, Any, Tuple\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a0b5315",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Loading\n",
    "X_model = pd.read_csv('X_model.csv')\n",
    "Y_model = pd.read_csv('Y_model.csv')\n",
    "scaler = MinMaxScaler(feature_range=(0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f75183d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering outliers...\n",
      "44655\n",
      "2432\n",
      "65185\n",
      "2333\n",
      "45549\n",
      "2469\n",
      "Defining preprocessors...\n"
     ]
    }
   ],
   "source": [
    "# Filter outliers by \"entire\"\n",
    "# Ref: https://machinelearningmastery.com/how-to-use-statistics-to-identify-outliers-in-data/\n",
    "print(\"Filtering outliers...\")\n",
    "df_base = pd.concat([X_model, Y_model], axis=1)\n",
    "df_processed = pd.DataFrame(data=df_base, columns=['business'])\n",
    "df_processed['cEntire'] = df_base.filter(regex=\"c\" + r\"2022[0-9]*\", axis=1).fillna(0).sum(axis=1)\n",
    "df_processed['tEntire'] = df_base.filter(regex=\"t\" + r\"2022[0-9]*\", axis=1).fillna(0).sum(axis=1)\n",
    "df_processed['sEntire'] = df_base.filter(regex=\"s\" + r\"2022[0-9]*\", axis=1).fillna(0).sum(axis=1)\n",
    "\n",
    "outliers = []\n",
    "\n",
    "def collect_outliers(business: int, key: str):\n",
    "    df_target = df_processed[df_processed['business'] == business]\n",
    "    q1, q3 = df_target[key].quantile([0.25, 0.75])\n",
    "    iqr = q3 - q1\n",
    "    cutoff = iqr * 2.0\n",
    "    lower, upper = q1 - cutoff, q3 + cutoff\n",
    "    _outliers = df_target[(df_target[key] < lower) | (df_target[key] > upper)].index.tolist()\n",
    "    print(len(_outliers))\n",
    "    outliers.extend(_outliers)\n",
    "\n",
    "collect_outliers(0, 'cEntire')\n",
    "collect_outliers(1, 'cEntire')\n",
    "collect_outliers(0, 'tEntire')\n",
    "collect_outliers(1, 'tEntire')\n",
    "collect_outliers(0, 'sEntire')\n",
    "collect_outliers(1, 'sEntire')\n",
    "\n",
    "outliers = list(set(outliers))\n",
    "\n",
    "# Filter outliers from df\n",
    "def filter_outliers_from_df(df: pd.DataFrame, outliers):\n",
    "    return df.drop(outliers)\n",
    "\n",
    "X_model = filter_outliers_from_df(X_model, outliers)\n",
    "Y_model = filter_outliers_from_df(Y_model, outliers)\n",
    "\n",
    "# Get columns of \"c\" prefix of last 5 days of month\n",
    "last_5_days = [\n",
    "    *[f\"c202201{i + 27}\" for i in range(5)],\n",
    "    *[f\"c202202{i + 24}\" for i in range(5)],\n",
    "    *[f\"c202203{i + 27}\" for i in range(5)],\n",
    "    *[f\"c202204{i + 26}\" for i in range(5)],\n",
    "    *[f\"c202205{i + 27}\" for i in range(5)],\n",
    "    *[f\"c202206{i + 26}\" for i in range(5)],\n",
    "    *[f\"c202207{i + 27}\" for i in range(5)],\n",
    "]\n",
    "last_5_days_sum = X_model.filter(last_5_days, axis=1).fillna(0).sum(axis=1)\n",
    "# print(last_5_days_sum.head())\n",
    "last_5_days_sum = last_5_days_sum.sort_values(ascending=False)\n",
    "# print(last_5_days_sum.index)\n",
    "\n",
    "# Define scaler\n",
    "# print(\"Defining scaler...\")\n",
    "# scaler = MinMaxScaler(feature_range=(0,1))\n",
    "\n",
    "# Define preprocessors\n",
    "print(\"Defining preprocessors...\")\n",
    "def column(colnames: List[str]):\n",
    "    def _column(X: pd.DataFrame):\n",
    "        X = X.fillna(0)\n",
    "        return [\n",
    "            [colname, X[colname].values] for colname in colnames\n",
    "        ]\n",
    "    return _column\n",
    "\n",
    "def rangesum(\n",
    "    name:str, \n",
    "    regex: str, \n",
    "    prefixes: str, \n",
    "    dist: np.ndarray\n",
    "):\n",
    "    def _rangesum(X: pd.DataFrame):\n",
    "        X = X.fillna(0)\n",
    "        return [\n",
    "            [\n",
    "                prefix + name, \n",
    "                X.filter(regex=(prefix + regex), axis=1).values.dot(dist)\n",
    "            ] for prefix in prefixes\n",
    "        ]\n",
    "    return _rangesum\n",
    "\n",
    "def rangesum_from_list(\n",
    "    name: str, \n",
    "    namelist: List[str], \n",
    "    prefix: str,\n",
    "    dist: np.ndarray,    \n",
    "):\n",
    "    def _rangesum_from_list(X: pd.DataFrame):\n",
    "        X = X.fillna(0)\n",
    "        return [\n",
    "            [\n",
    "                prefix + name, \n",
    "                X[namelist].values.dot(dist)\n",
    "            ]\n",
    "        ]\n",
    "    return _rangesum_from_list\n",
    "\n",
    "def _fillna(X: np.ndarray) -> np.ndarray:\n",
    "    return np.nan_to_num(X, copy=True, nan=0)\n",
    "\n",
    "def array_divide(\n",
    "    numerator: List[Tuple[str, np.ndarray]], \n",
    "    denominator: List[Tuple[str, np.ndarray]]\n",
    ") -> List[Any]:\n",
    "    assert len(numerator) == len(denominator)\n",
    "    return [\n",
    "        [\n",
    "            \"r\" + numerator_colname, \n",
    "            _fillna(np.divide(numerator_col, denominator_col))\n",
    "        ] for [numerator_colname, numerator_col], [_, denominator_col] in zip(numerator, denominator)\n",
    "    ]\n",
    "\n",
    "def one_hot_encode(column: str) -> pd.DataFrame:\n",
    "    def _one_hot_encode(X: pd.DataFrame):\n",
    "        X = X.fillna(0)\n",
    "        df_dummies = pd.get_dummies(X[column], prefix=column)\n",
    "        return [\n",
    "            [colname, df_dummies[colname].values] for colname in df_dummies.columns\n",
    "        ]\n",
    "    return _one_hot_encode\n",
    "\n",
    "def preprocess(X: pd.DataFrame, processors: List[Any]) -> pd.DataFrame:\n",
    "    X_new = pd.DataFrame()\n",
    "\n",
    "    for processor in processors:\n",
    "        for colname, col in processor if type(processor) == type([]) else processor(X):\n",
    "            X_new[colname] = col\n",
    "\n",
    "    X_new = X_new.fillna(0)\n",
    "\n",
    "#     X_new = pd.DataFrame(scaler.fit_transform(X_new), columns=X_new.columns)\n",
    "\n",
    "    return X_new\n",
    "\n",
    "def equal_dist(length: int) -> np.ndarray:\n",
    "    return np.ones(length)\n",
    "\n",
    "def linear_dist(length: int) -> np.ndarray:\n",
    "    return np.arange(start=0, stop=1, step=1/length)\n",
    "\n",
    "def triangle_dist(length: int) -> np.ndarray:\n",
    "    return np.concatenate(\n",
    "        [\n",
    "            np.arange(start=0, stop=1, step=1/length),\n",
    "            np.arange(start=1, stop=0, step=-1/length)\n",
    "        ]\n",
    "    )\n",
    "# 62317\n",
    "# 3595\n",
    "# 85519\n",
    "# 3461\n",
    "# 63063\n",
    "# 3548"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4bea1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get columns of \"c\" prefix of last 5 days of month\n",
    "last_5_days = [\n",
    "    *[f\"c202201{i + 27}\" for i in range(5)],\n",
    "    *[f\"c202202{i + 24}\" for i in range(5)],\n",
    "    *[f\"c202203{i + 27}\" for i in range(5)],\n",
    "    *[f\"c202204{i + 26}\" for i in range(5)],\n",
    "    *[f\"c202205{i + 27}\" for i in range(5)],\n",
    "    *[f\"c202206{i + 26}\" for i in range(5)],\n",
    "    *[f\"c202207{i + 27}\" for i in range(5)],\n",
    "]\n",
    "last_5_days_sum = X_model.filter(last_5_days, axis=1).fillna(0).sum(axis=1)\n",
    "last5_code = np.array(last_5_days_sum)\n",
    "last_5_days_sum_list =[]\n",
    "last_5_days_sum_list.append(['last_5_days_sum',last5_code])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b586d3fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data preprocessing...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age_code</th>\n",
       "      <th>region_code</th>\n",
       "      <th>cGIT</th>\n",
       "      <th>tGIT</th>\n",
       "      <th>sGIT</th>\n",
       "      <th>tVAT</th>\n",
       "      <th>sVAT</th>\n",
       "      <th>cEntire</th>\n",
       "      <th>tEntire</th>\n",
       "      <th>sEntire</th>\n",
       "      <th>last_5_days_sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>790.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2253.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1712.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5119.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender  age_code  region_code  cGIT  tGIT    sGIT  tVAT    sVAT  cEntire  \\\n",
       "0      13        13            7   0.0   0.0     0.0   0.0     0.0      1.0   \n",
       "1       5         5            1   2.0   0.0    17.0   0.0   185.0     39.0   \n",
       "2       6         6            2   6.0   3.0  2253.0   0.0  1712.0     26.0   \n",
       "\n",
       "   tEntire  sEntire  last_5_days_sum  \n",
       "0      1.0     93.0              0.0  \n",
       "1      0.0    790.0              4.0  \n",
       "2      3.0   5119.0              0.0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Data preprocessing...\")\n",
    "dist_GIT = rangesum(\n",
    "    'GIT', \n",
    "    r\"202205[0-9]{2}\", \n",
    "    \"cts\", \n",
    "    equal_dist(31)\n",
    ")(X_model)\n",
    "dist_VAT = rangesum(\n",
    "    'VAT', \n",
    "    r\"20220[17](?:[01][0-9]|2[0-5])\", \n",
    "    \"ts\", \n",
    "    np.concatenate((equal_dist(25), equal_dist(25)))\n",
    ")(X_model)\n",
    "entire_days = 31 + 29 + 31 + 30 + 31 + 30 + 31 + 25\n",
    "entire = rangesum(\n",
    "    'Entire', \n",
    "    r\"2022[0-9]{4}\", \n",
    "    \"cts\", \n",
    "    equal_dist(entire_days)\n",
    ")(X_model)\n",
    "\n",
    "age_code = np.array(X_model['age_code'])\n",
    "gender_code = np.array(X_model['gender'])\n",
    "region_code = np.array(X_model['region_code'])\n",
    "cat_Featrues = []\n",
    "cat_Featrues.append(['gender',age_code])\n",
    "cat_Featrues.append(['age_code',age_code])\n",
    "cat_Featrues.append(['region_code',region_code])\n",
    "\n",
    "X_processed = preprocess(\n",
    "    X_model, \n",
    "    [\n",
    "        cat_Featrues,\n",
    "        dist_GIT,\n",
    "        dist_VAT,\n",
    "        entire,\n",
    "        last_5_days_sum_list\n",
    "        # array_divide(dist_GIT, entire), # rel_GIT\n",
    "        # array_divide(dist_VAT, entire[1:]), # rel_VAT\n",
    "    ]\n",
    ")\n",
    "X_processed.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d826009c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing for hyperparameter tuning...\n",
      "Hyperparameter tuning started...\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=938, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=938\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.8072204248705719, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.8072204248705719\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8319573959797029, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8319573959797029\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.02242682046824625, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.02242682046824625\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=938, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=938\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.8072204248705719, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.8072204248705719\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8319573959797029, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8319573959797029\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.02242682046824625, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.02242682046824625\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=938, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=938\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.8072204248705719, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.8072204248705719\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8319573959797029, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8319573959797029\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.02242682046824625, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.02242682046824625\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=938, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=938\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.8072204248705719, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.8072204248705719\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8319573959797029, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8319573959797029\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.02242682046824625, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.02242682046824625\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=938, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=938\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.8072204248705719, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.8072204248705719\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8319573959797029, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8319573959797029\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.02242682046824625, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.02242682046824625\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=107, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=107\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.09721172407485189, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.09721172407485189\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5153472999341122, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5153472999341122\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0023177821930569103, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0023177821930569103\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=107, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=107\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.09721172407485189, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.09721172407485189\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5153472999341122, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5153472999341122\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0023177821930569103, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0023177821930569103\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=107, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=107\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.09721172407485189, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.09721172407485189\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5153472999341122, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5153472999341122\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0023177821930569103, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0023177821930569103\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=107, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=107\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.09721172407485189, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.09721172407485189\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5153472999341122, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5153472999341122\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0023177821930569103, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0023177821930569103\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=107, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=107\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.09721172407485189, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.09721172407485189\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5153472999341122, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5153472999341122\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0023177821930569103, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0023177821930569103\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=817, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=817\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.16792020377527667, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.16792020377527667\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4841021586712092, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4841021586712092\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.067660071545357, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.067660071545357\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=817, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=817\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.16792020377527667, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.16792020377527667\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4841021586712092, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4841021586712092\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.067660071545357, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.067660071545357\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=817, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=817\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.16792020377527667, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.16792020377527667\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4841021586712092, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4841021586712092\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.067660071545357, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.067660071545357\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=817, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=817\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.16792020377527667, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.16792020377527667\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4841021586712092, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4841021586712092\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.067660071545357, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.067660071545357\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=817, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=817\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.16792020377527667, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.16792020377527667\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4841021586712092, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4841021586712092\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.067660071545357, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.067660071545357\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=875, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=875\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.010994563380651353, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.010994563380651353\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.47499621094048017, subsample=1.0 will be ignored. Current value: bagging_fraction=0.47499621094048017\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.13606891911243962, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.13606891911243962\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=875, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=875\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.010994563380651353, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.010994563380651353\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.47499621094048017, subsample=1.0 will be ignored. Current value: bagging_fraction=0.47499621094048017\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.13606891911243962, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.13606891911243962\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=875, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=875\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.010994563380651353, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.010994563380651353\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.47499621094048017, subsample=1.0 will be ignored. Current value: bagging_fraction=0.47499621094048017\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.13606891911243962, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.13606891911243962\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=875, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=875\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.010994563380651353, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.010994563380651353\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.47499621094048017, subsample=1.0 will be ignored. Current value: bagging_fraction=0.47499621094048017\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.13606891911243962, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.13606891911243962\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=875, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=875\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.010994563380651353, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.010994563380651353\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.47499621094048017, subsample=1.0 will be ignored. Current value: bagging_fraction=0.47499621094048017\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.13606891911243962, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.13606891911243962\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=764, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=764\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.715709824102391, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.715709824102391\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.3082923516269005, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3082923516269005\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.07213803177624604, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.07213803177624604\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=764, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=764\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.715709824102391, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.715709824102391\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.3082923516269005, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3082923516269005\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.07213803177624604, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.07213803177624604\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=764, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=764\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.715709824102391, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.715709824102391\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.3082923516269005, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3082923516269005\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.07213803177624604, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.07213803177624604\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=764, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=764\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.715709824102391, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.715709824102391\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.3082923516269005, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3082923516269005\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.07213803177624604, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.07213803177624604\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=764, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=764\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.715709824102391, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.715709824102391\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.3082923516269005, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3082923516269005\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.07213803177624604, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.07213803177624604\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=879, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=879\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0019157128774117515, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0019157128774117515\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.3950829564266918, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3950829564266918\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0017452800577763663, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0017452800577763663\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=879, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=879\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0019157128774117515, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0019157128774117515\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.3950829564266918, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3950829564266918\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0017452800577763663, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0017452800577763663\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=879, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=879\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0019157128774117515, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0019157128774117515\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.3950829564266918, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3950829564266918\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0017452800577763663, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0017452800577763663\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=879, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=879\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0019157128774117515, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0019157128774117515\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.3950829564266918, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3950829564266918\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0017452800577763663, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0017452800577763663\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=879, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=879\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0019157128774117515, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0019157128774117515\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.3950829564266918, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3950829564266918\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0017452800577763663, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0017452800577763663\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=559, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=559\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.010845545571066668, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.010845545571066668\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.24010791665140263, subsample=1.0 will be ignored. Current value: bagging_fraction=0.24010791665140263\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007055908060137408, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007055908060137408\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=559, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=559\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.010845545571066668, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.010845545571066668\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.24010791665140263, subsample=1.0 will be ignored. Current value: bagging_fraction=0.24010791665140263\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007055908060137408, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007055908060137408\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=559, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=559\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.010845545571066668, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.010845545571066668\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.24010791665140263, subsample=1.0 will be ignored. Current value: bagging_fraction=0.24010791665140263\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007055908060137408, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007055908060137408\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=559, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=559\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.010845545571066668, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.010845545571066668\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.24010791665140263, subsample=1.0 will be ignored. Current value: bagging_fraction=0.24010791665140263\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007055908060137408, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007055908060137408\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=559, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=559\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.010845545571066668, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.010845545571066668\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.24010791665140263, subsample=1.0 will be ignored. Current value: bagging_fraction=0.24010791665140263\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.007055908060137408, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007055908060137408\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=421, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=421\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1468116744235313, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1468116744235313\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4057686625580055, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4057686625580055\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.07912665366072733, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.07912665366072733\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=421, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=421\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1468116744235313, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1468116744235313\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4057686625580055, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4057686625580055\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.07912665366072733, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.07912665366072733\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=421, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=421\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1468116744235313, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1468116744235313\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4057686625580055, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4057686625580055\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.07912665366072733, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.07912665366072733\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=421, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=421\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1468116744235313, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1468116744235313\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4057686625580055, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4057686625580055\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.07912665366072733, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.07912665366072733\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=421, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=421\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1468116744235313, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1468116744235313\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4057686625580055, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4057686625580055\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.07912665366072733, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.07912665366072733\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=984, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=984\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.10055977356198367, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.10055977356198367\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.33689952567714143, subsample=1.0 will be ignored. Current value: bagging_fraction=0.33689952567714143\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.011105576683708762, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.011105576683708762\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=984, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=984\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.10055977356198367, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.10055977356198367\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.33689952567714143, subsample=1.0 will be ignored. Current value: bagging_fraction=0.33689952567714143\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.011105576683708762, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.011105576683708762\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=984, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=984\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.10055977356198367, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.10055977356198367\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.33689952567714143, subsample=1.0 will be ignored. Current value: bagging_fraction=0.33689952567714143\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.011105576683708762, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.011105576683708762\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=984, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=984\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.10055977356198367, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.10055977356198367\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.33689952567714143, subsample=1.0 will be ignored. Current value: bagging_fraction=0.33689952567714143\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.011105576683708762, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.011105576683708762\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=984, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=984\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.10055977356198367, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.10055977356198367\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.33689952567714143, subsample=1.0 will be ignored. Current value: bagging_fraction=0.33689952567714143\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.011105576683708762, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.011105576683708762\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=522, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=522\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.010815978738787315, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.010815978738787315\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.23684876647852016, subsample=1.0 will be ignored. Current value: bagging_fraction=0.23684876647852016\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.522863566413219, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.522863566413219\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=522, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=522\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.010815978738787315, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.010815978738787315\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.23684876647852016, subsample=1.0 will be ignored. Current value: bagging_fraction=0.23684876647852016\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.522863566413219, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.522863566413219\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=522, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=522\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.010815978738787315, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.010815978738787315\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.23684876647852016, subsample=1.0 will be ignored. Current value: bagging_fraction=0.23684876647852016\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.522863566413219, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.522863566413219\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=522, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=522\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.010815978738787315, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.010815978738787315\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.23684876647852016, subsample=1.0 will be ignored. Current value: bagging_fraction=0.23684876647852016\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.522863566413219, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.522863566413219\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=522, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=522\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.010815978738787315, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.010815978738787315\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.23684876647852016, subsample=1.0 will be ignored. Current value: bagging_fraction=0.23684876647852016\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.522863566413219, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.522863566413219\n",
      "Best params\n",
      "{'n_estimators': 222, 'max_depth': 10, 'learning_rate': 0.041435226343818604, 'num_leaves': 932, 'min_data_in_leaf': 522, 'max_bin': 317, 'lambda_l1': 0.010815978738787315, 'lambda_l2': 2.522863566413219, 'min_child_weight': 10, 'bagging_fraction': 0.23684876647852016, 'pos_bagging_fraction': 0.23130127933103428, 'neg_bagging_fraction': 0.9451474530443466}\n"
     ]
    }
   ],
   "source": [
    "print(\"Preparing for hyperparameter tuning...\")\n",
    "def _construct_and_cross_validate(**kwargs):\n",
    "\n",
    "    lgbm = LGBMClassifier(\n",
    "        task = \"train\",\n",
    "        objective = \"binary\", #cross-entropy\n",
    "        metric = \"auc\",\n",
    "        tree_learner = \"data\",\n",
    "        random_state=100,\n",
    "        categorical_feature = [0,1,2],\n",
    "        class_weight={0: 1, 1: 14.291397},\n",
    "        n_estimators=kwargs['n_estimators'],\n",
    "        # to deal with overfitting, very important param\n",
    "        max_depth=kwargs['max_depth'],\n",
    "        learning_rate=kwargs['learning_rate'],\n",
    "        num_leaves=kwargs['num_leaves'],\n",
    "        min_data_in_leaf=kwargs['min_data_in_leaf'],\n",
    "        #if max_bin becomes small, the accuracy goes up\n",
    "        max_bin=kwargs['max_bin'],\n",
    "        lambda_l1=kwargs['lambda_l1'],\n",
    "        lambda_l2=kwargs['lambda_l2'],\n",
    "        # to deal with overfitting\n",
    "        min_child_weight=kwargs['min_child_weight'],\n",
    "        #for bagging imbalanced\n",
    "        bagging_fraction=kwargs['bagging_fraction'],\n",
    "        pos_bagging_fraction=kwargs['pos_bagging_fraction'],\n",
    "        neg_bagging_fraction=kwargs['neg_bagging_fraction'],\n",
    "    )\n",
    "    #cross validation K=5\n",
    "    scores = cross_val_score(\n",
    "        lgbm, \n",
    "        X_processed, \n",
    "        Y_model, \n",
    "        cv=StratifiedKFold(n_splits=5, shuffle=True),\n",
    "        scoring=\"roc_auc\"\n",
    "    )\n",
    "    return scores\n",
    "\n",
    "# Task: Hyperparameter tuning with Optuna\n",
    "def objective(trial: Trial):\n",
    "    # Construct a DecisionTreeClassifier object\n",
    "    scores = _construct_and_cross_validate(\n",
    "        n_estimators=trial.suggest_int('n_estimators',100,500),\n",
    "        # to deal with overfitting, very important param\n",
    "        max_depth = trial.suggest_int('max_depth',10,20),\n",
    "        learning_rate = trial.suggest_float('learning_rate',0.02,0.1),\n",
    "        num_leaves = trial.suggest_int('num_leaves',500,1000),\n",
    "        min_data_in_leaf = trial.suggest_int('min_data_in_leaf',100,1000),\n",
    "        #if max_bin becomes small, the accuracy goes up\n",
    "        max_bin = trial.suggest_int('max_bin',255,350),\n",
    "        lambda_l1 = trial.suggest_loguniform('lambda_l1', 1e-3, 10.0),\n",
    "        lambda_l2 = trial.suggest_loguniform('lambda_l2', 1e-3, 10.0),\n",
    "        # to deal with overfitting\n",
    "        min_child_weight = trial.suggest_int('min_child_weight', 1, 10),\n",
    "        #for bagging imbalanced\n",
    "        bagging_fraction = trial.suggest_float('bagging_fraction', 0,1),\n",
    "        pos_bagging_fraction = trial.suggest_float('pos_bagging_fraction', 0,1),\n",
    "        neg_bagging_fraction = trial.suggest_float('neg_bagging_fraction', 0,1),\n",
    "    )\n",
    "\n",
    "    return scores.mean()\n",
    "\n",
    "print(\"Hyperparameter tuning started...\")\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=10)\n",
    "\n",
    "# Print the best parameters\n",
    "print(\"Best params\")\n",
    "print(study.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c2cae29c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finalizing model...\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=522, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=522\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.010815978738787315, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.010815978738787315\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.23684876647852016, subsample=1.0 will be ignored. Current value: bagging_fraction=0.23684876647852016\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.522863566413219, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.522863566413219\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=522, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=522\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.010815978738787315, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.010815978738787315\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.23684876647852016, subsample=1.0 will be ignored. Current value: bagging_fraction=0.23684876647852016\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.522863566413219, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.522863566413219\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=522, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=522\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.010815978738787315, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.010815978738787315\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.23684876647852016, subsample=1.0 will be ignored. Current value: bagging_fraction=0.23684876647852016\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.522863566413219, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.522863566413219\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=522, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=522\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.010815978738787315, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.010815978738787315\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.23684876647852016, subsample=1.0 will be ignored. Current value: bagging_fraction=0.23684876647852016\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.522863566413219, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.522863566413219\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=522, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=522\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.010815978738787315, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.010815978738787315\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.23684876647852016, subsample=1.0 will be ignored. Current value: bagging_fraction=0.23684876647852016\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.522863566413219, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.522863566413219\n",
      "Average ROC AUC Score 0.9282811241682133\n",
      "Standard Deviation of ROC AUC Score 0.0014156586964495792\n"
     ]
    }
   ],
   "source": [
    "print(\"Finalizing model...\")\n",
    "scores = _construct_and_cross_validate(\n",
    "    n_estimators=study.best_params['n_estimators'],\n",
    "    # to deal with overfitting, very important param\n",
    "    max_depth=study.best_params['max_depth'],\n",
    "    learning_rate=study.best_params['learning_rate'],\n",
    "    num_leaves=study.best_params['num_leaves'],\n",
    "    min_data_in_leaf=study.best_params['min_data_in_leaf'],\n",
    "    #if max_bin becomes small, the accuracy goes up\n",
    "    max_bin=study.best_params['max_bin'],\n",
    "    lambda_l1=study.best_params['lambda_l1'],\n",
    "    lambda_l2=study.best_params['lambda_l2'],\n",
    "    # to deal with overfitting\n",
    "    min_child_weight=study.best_params['min_child_weight'],\n",
    "    #for bagging imbalanced\n",
    "    bagging_fraction=study.best_params['bagging_fraction'],\n",
    "    pos_bagging_fraction=study.best_params['pos_bagging_fraction'],\n",
    "    neg_bagging_fraction=study.best_params['neg_bagging_fraction'],\n",
    ")\n",
    "\n",
    "print(\"Average ROC AUC Score\", np.mean(scores))\n",
    "print(\"Standard Deviation of ROC AUC Score\", np.std(scores))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d8df6dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimized_LGBM = LGBMClassifier(\n",
    "    task = \"predict\",\n",
    "    objective = \"binary\",\n",
    "    metric = \"auc\",\n",
    "    tree_learner = \"data\",\n",
    "    categorical_feature = [0,1,2],\n",
    "    class_weight={0: 1, 1: 14.291397},\n",
    "    n_estimators=study.best_params['n_estimators'],\n",
    "    \n",
    "    # to deal with overfitting, very important param\n",
    "    max_depth=study.best_params['max_depth'],\n",
    "    learning_rate=study.best_params['learning_rate'],\n",
    "    num_leaves=study.best_params['num_leaves'],\n",
    "    min_data_in_leaf=study.best_params['min_data_in_leaf'],\n",
    "    \n",
    "    #if max_bin becomes small, the accuracy goes up\n",
    "    max_bin=study.best_params['max_bin'],\n",
    "    lambda_l1=study.best_params['lambda_l1'],\n",
    "    lambda_l2=study.best_params['lambda_l2'],\n",
    "    \n",
    "    # to deal with overfitting\n",
    "    min_child_weight=study.best_params['min_child_weight'],\n",
    "    #for bagging imbalanced\n",
    "    bagging_fraction=study.best_params['bagging_fraction'],\n",
    "    pos_bagging_fraction=study.best_params['pos_bagging_fraction'],\n",
    "    neg_bagging_fraction=study.best_params['neg_bagging_fraction'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7628209c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing...\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=798, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=798\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.15602359629209078, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.15602359629209078\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.24397531382432613, subsample=1.0 will be ignored. Current value: bagging_fraction=0.24397531382432613\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.05176012844110056, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.05176012844110056\n",
      "[1]\ttraining's auc: 0.921668\tvalid_1's auc: 0.920071\n",
      "[2]\ttraining's auc: 0.921888\tvalid_1's auc: 0.920536\n",
      "[3]\ttraining's auc: 0.922567\tvalid_1's auc: 0.921094\n",
      "[4]\ttraining's auc: 0.922614\tvalid_1's auc: 0.921126\n",
      "[5]\ttraining's auc: 0.922796\tvalid_1's auc: 0.92131\n",
      "[6]\ttraining's auc: 0.923726\tvalid_1's auc: 0.922375\n",
      "[7]\ttraining's auc: 0.924201\tvalid_1's auc: 0.922671\n",
      "[8]\ttraining's auc: 0.924369\tvalid_1's auc: 0.923\n",
      "[9]\ttraining's auc: 0.924404\tvalid_1's auc: 0.923025\n",
      "[10]\ttraining's auc: 0.924763\tvalid_1's auc: 0.923265\n",
      "[11]\ttraining's auc: 0.924955\tvalid_1's auc: 0.9234\n",
      "[12]\ttraining's auc: 0.925009\tvalid_1's auc: 0.923374\n",
      "[13]\ttraining's auc: 0.925087\tvalid_1's auc: 0.923423\n",
      "[14]\ttraining's auc: 0.925072\tvalid_1's auc: 0.923343\n",
      "[15]\ttraining's auc: 0.925155\tvalid_1's auc: 0.923318\n",
      "[16]\ttraining's auc: 0.925186\tvalid_1's auc: 0.923392\n",
      "[17]\ttraining's auc: 0.92516\tvalid_1's auc: 0.923369\n",
      "[18]\ttraining's auc: 0.92526\tvalid_1's auc: 0.923424\n",
      "[19]\ttraining's auc: 0.92546\tvalid_1's auc: 0.923586\n",
      "[20]\ttraining's auc: 0.925535\tvalid_1's auc: 0.923623\n",
      "[21]\ttraining's auc: 0.925559\tvalid_1's auc: 0.923621\n",
      "[22]\ttraining's auc: 0.925716\tvalid_1's auc: 0.923821\n",
      "[23]\ttraining's auc: 0.925901\tvalid_1's auc: 0.924037\n",
      "[24]\ttraining's auc: 0.92599\tvalid_1's auc: 0.924102\n",
      "[25]\ttraining's auc: 0.926172\tvalid_1's auc: 0.924317\n",
      "[26]\ttraining's auc: 0.926274\tvalid_1's auc: 0.924421\n",
      "[27]\ttraining's auc: 0.926398\tvalid_1's auc: 0.924523\n",
      "[28]\ttraining's auc: 0.926445\tvalid_1's auc: 0.9246\n",
      "[29]\ttraining's auc: 0.926506\tvalid_1's auc: 0.924679\n",
      "[30]\ttraining's auc: 0.926558\tvalid_1's auc: 0.924668\n",
      "[31]\ttraining's auc: 0.926635\tvalid_1's auc: 0.924722\n",
      "[32]\ttraining's auc: 0.926676\tvalid_1's auc: 0.924805\n",
      "[33]\ttraining's auc: 0.926737\tvalid_1's auc: 0.924889\n",
      "[34]\ttraining's auc: 0.926836\tvalid_1's auc: 0.924968\n",
      "[35]\ttraining's auc: 0.926867\tvalid_1's auc: 0.925015\n",
      "[36]\ttraining's auc: 0.926896\tvalid_1's auc: 0.925038\n",
      "[37]\ttraining's auc: 0.926987\tvalid_1's auc: 0.925112\n",
      "[38]\ttraining's auc: 0.927076\tvalid_1's auc: 0.925174\n",
      "[39]\ttraining's auc: 0.927108\tvalid_1's auc: 0.925177\n",
      "[40]\ttraining's auc: 0.927156\tvalid_1's auc: 0.925192\n",
      "[41]\ttraining's auc: 0.927222\tvalid_1's auc: 0.925255\n",
      "[42]\ttraining's auc: 0.927248\tvalid_1's auc: 0.925281\n",
      "[43]\ttraining's auc: 0.927278\tvalid_1's auc: 0.925308\n",
      "[44]\ttraining's auc: 0.927328\tvalid_1's auc: 0.92534\n",
      "[45]\ttraining's auc: 0.927371\tvalid_1's auc: 0.925358\n",
      "[46]\ttraining's auc: 0.927395\tvalid_1's auc: 0.925388\n",
      "[47]\ttraining's auc: 0.927525\tvalid_1's auc: 0.925474\n",
      "[48]\ttraining's auc: 0.927601\tvalid_1's auc: 0.925539\n",
      "[49]\ttraining's auc: 0.927665\tvalid_1's auc: 0.925582\n",
      "[50]\ttraining's auc: 0.927717\tvalid_1's auc: 0.925626\n",
      "[51]\ttraining's auc: 0.927801\tvalid_1's auc: 0.925683\n",
      "[52]\ttraining's auc: 0.927827\tvalid_1's auc: 0.925699\n",
      "[53]\ttraining's auc: 0.927905\tvalid_1's auc: 0.925722\n",
      "[54]\ttraining's auc: 0.928041\tvalid_1's auc: 0.925825\n",
      "[55]\ttraining's auc: 0.928094\tvalid_1's auc: 0.925881\n",
      "[56]\ttraining's auc: 0.928139\tvalid_1's auc: 0.925913\n",
      "[57]\ttraining's auc: 0.928195\tvalid_1's auc: 0.925942\n",
      "[58]\ttraining's auc: 0.928239\tvalid_1's auc: 0.925983\n",
      "[59]\ttraining's auc: 0.928317\tvalid_1's auc: 0.926049\n",
      "[60]\ttraining's auc: 0.928387\tvalid_1's auc: 0.926093\n",
      "[61]\ttraining's auc: 0.928472\tvalid_1's auc: 0.926161\n",
      "[62]\ttraining's auc: 0.928494\tvalid_1's auc: 0.926177\n",
      "[63]\ttraining's auc: 0.928522\tvalid_1's auc: 0.926204\n",
      "[64]\ttraining's auc: 0.92859\tvalid_1's auc: 0.926258\n",
      "[65]\ttraining's auc: 0.928606\tvalid_1's auc: 0.926278\n",
      "[66]\ttraining's auc: 0.928668\tvalid_1's auc: 0.926314\n",
      "[67]\ttraining's auc: 0.928702\tvalid_1's auc: 0.926347\n",
      "[68]\ttraining's auc: 0.928735\tvalid_1's auc: 0.92637\n",
      "[69]\ttraining's auc: 0.92878\tvalid_1's auc: 0.926378\n",
      "[70]\ttraining's auc: 0.928846\tvalid_1's auc: 0.9264\n",
      "[71]\ttraining's auc: 0.928963\tvalid_1's auc: 0.926493\n",
      "[72]\ttraining's auc: 0.929007\tvalid_1's auc: 0.926515\n",
      "[73]\ttraining's auc: 0.929105\tvalid_1's auc: 0.926596\n",
      "[74]\ttraining's auc: 0.929164\tvalid_1's auc: 0.926628\n",
      "[75]\ttraining's auc: 0.929205\tvalid_1's auc: 0.926642\n",
      "[76]\ttraining's auc: 0.929253\tvalid_1's auc: 0.92667\n",
      "[77]\ttraining's auc: 0.92931\tvalid_1's auc: 0.926703\n",
      "[78]\ttraining's auc: 0.929403\tvalid_1's auc: 0.926748\n",
      "[79]\ttraining's auc: 0.929431\tvalid_1's auc: 0.926765\n",
      "[80]\ttraining's auc: 0.929471\tvalid_1's auc: 0.92678\n",
      "[81]\ttraining's auc: 0.929519\tvalid_1's auc: 0.926803\n",
      "[82]\ttraining's auc: 0.929572\tvalid_1's auc: 0.926828\n",
      "[83]\ttraining's auc: 0.929617\tvalid_1's auc: 0.926861\n",
      "[84]\ttraining's auc: 0.929663\tvalid_1's auc: 0.926887\n",
      "[85]\ttraining's auc: 0.929723\tvalid_1's auc: 0.926911\n",
      "[86]\ttraining's auc: 0.92974\tvalid_1's auc: 0.926925\n",
      "[87]\ttraining's auc: 0.929808\tvalid_1's auc: 0.926949\n",
      "[88]\ttraining's auc: 0.929869\tvalid_1's auc: 0.926971\n",
      "[89]\ttraining's auc: 0.929912\tvalid_1's auc: 0.926998\n",
      "[90]\ttraining's auc: 0.929986\tvalid_1's auc: 0.927028\n",
      "[91]\ttraining's auc: 0.930031\tvalid_1's auc: 0.927069\n",
      "[92]\ttraining's auc: 0.930087\tvalid_1's auc: 0.927111\n",
      "[93]\ttraining's auc: 0.930118\tvalid_1's auc: 0.927116\n",
      "[94]\ttraining's auc: 0.930134\tvalid_1's auc: 0.927121\n",
      "[95]\ttraining's auc: 0.930153\tvalid_1's auc: 0.927122\n",
      "[96]\ttraining's auc: 0.930246\tvalid_1's auc: 0.927183\n",
      "[97]\ttraining's auc: 0.930312\tvalid_1's auc: 0.927196\n",
      "[98]\ttraining's auc: 0.930335\tvalid_1's auc: 0.927209\n",
      "[99]\ttraining's auc: 0.930416\tvalid_1's auc: 0.927221\n",
      "[100]\ttraining's auc: 0.930458\tvalid_1's auc: 0.927224\n",
      "[101]\ttraining's auc: 0.930533\tvalid_1's auc: 0.927236\n",
      "[102]\ttraining's auc: 0.930618\tvalid_1's auc: 0.927285\n",
      "[103]\ttraining's auc: 0.930654\tvalid_1's auc: 0.927317\n",
      "[104]\ttraining's auc: 0.930687\tvalid_1's auc: 0.927342\n",
      "[105]\ttraining's auc: 0.930704\tvalid_1's auc: 0.927377\n",
      "[106]\ttraining's auc: 0.93072\tvalid_1's auc: 0.927392\n",
      "[107]\ttraining's auc: 0.930752\tvalid_1's auc: 0.927406\n",
      "[108]\ttraining's auc: 0.930771\tvalid_1's auc: 0.927412\n",
      "[109]\ttraining's auc: 0.930787\tvalid_1's auc: 0.927414\n",
      "[110]\ttraining's auc: 0.93082\tvalid_1's auc: 0.927437\n",
      "[111]\ttraining's auc: 0.930839\tvalid_1's auc: 0.927446\n",
      "[112]\ttraining's auc: 0.930915\tvalid_1's auc: 0.927483\n",
      "[113]\ttraining's auc: 0.930933\tvalid_1's auc: 0.927486\n",
      "[114]\ttraining's auc: 0.931025\tvalid_1's auc: 0.927537\n",
      "[115]\ttraining's auc: 0.93107\tvalid_1's auc: 0.927558\n",
      "[116]\ttraining's auc: 0.931107\tvalid_1's auc: 0.927562\n",
      "[117]\ttraining's auc: 0.931139\tvalid_1's auc: 0.92757\n",
      "[118]\ttraining's auc: 0.931184\tvalid_1's auc: 0.927575\n",
      "[119]\ttraining's auc: 0.931208\tvalid_1's auc: 0.927576\n",
      "[120]\ttraining's auc: 0.931255\tvalid_1's auc: 0.927591\n",
      "[121]\ttraining's auc: 0.931301\tvalid_1's auc: 0.927608\n",
      "[122]\ttraining's auc: 0.931388\tvalid_1's auc: 0.927622\n",
      "[123]\ttraining's auc: 0.931434\tvalid_1's auc: 0.927629\n",
      "[124]\ttraining's auc: 0.931513\tvalid_1's auc: 0.927635\n",
      "[125]\ttraining's auc: 0.931555\tvalid_1's auc: 0.927652\n",
      "[126]\ttraining's auc: 0.931582\tvalid_1's auc: 0.92765\n",
      "[127]\ttraining's auc: 0.931601\tvalid_1's auc: 0.92767\n",
      "[128]\ttraining's auc: 0.931609\tvalid_1's auc: 0.927676\n",
      "[129]\ttraining's auc: 0.93162\tvalid_1's auc: 0.927686\n",
      "[130]\ttraining's auc: 0.931656\tvalid_1's auc: 0.927704\n",
      "[131]\ttraining's auc: 0.931665\tvalid_1's auc: 0.927707\n",
      "[132]\ttraining's auc: 0.931676\tvalid_1's auc: 0.927715\n",
      "[133]\ttraining's auc: 0.931702\tvalid_1's auc: 0.927715\n",
      "[134]\ttraining's auc: 0.931735\tvalid_1's auc: 0.927712\n",
      "[135]\ttraining's auc: 0.931769\tvalid_1's auc: 0.927723\n",
      "[136]\ttraining's auc: 0.931799\tvalid_1's auc: 0.927733\n",
      "[137]\ttraining's auc: 0.931809\tvalid_1's auc: 0.927739\n",
      "[138]\ttraining's auc: 0.931839\tvalid_1's auc: 0.927746\n",
      "[139]\ttraining's auc: 0.93187\tvalid_1's auc: 0.927756\n",
      "[140]\ttraining's auc: 0.93191\tvalid_1's auc: 0.927764\n",
      "[141]\ttraining's auc: 0.931948\tvalid_1's auc: 0.927766\n",
      "[142]\ttraining's auc: 0.931957\tvalid_1's auc: 0.92777\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[143]\ttraining's auc: 0.93198\tvalid_1's auc: 0.927778\n",
      "[144]\ttraining's auc: 0.932009\tvalid_1's auc: 0.927781\n",
      "[145]\ttraining's auc: 0.932026\tvalid_1's auc: 0.927791\n",
      "[146]\ttraining's auc: 0.932047\tvalid_1's auc: 0.927787\n",
      "[147]\ttraining's auc: 0.932078\tvalid_1's auc: 0.927803\n",
      "[148]\ttraining's auc: 0.932102\tvalid_1's auc: 0.927798\n",
      "[149]\ttraining's auc: 0.932123\tvalid_1's auc: 0.927796\n",
      "[150]\ttraining's auc: 0.93214\tvalid_1's auc: 0.927801\n",
      "[151]\ttraining's auc: 0.932167\tvalid_1's auc: 0.927815\n",
      "[152]\ttraining's auc: 0.932211\tvalid_1's auc: 0.927815\n",
      "[153]\ttraining's auc: 0.932234\tvalid_1's auc: 0.927814\n",
      "[154]\ttraining's auc: 0.932275\tvalid_1's auc: 0.927819\n",
      "[155]\ttraining's auc: 0.932311\tvalid_1's auc: 0.927833\n",
      "[156]\ttraining's auc: 0.932356\tvalid_1's auc: 0.927853\n",
      "[157]\ttraining's auc: 0.932391\tvalid_1's auc: 0.927855\n",
      "[158]\ttraining's auc: 0.932445\tvalid_1's auc: 0.927868\n",
      "[159]\ttraining's auc: 0.932481\tvalid_1's auc: 0.927891\n",
      "[160]\ttraining's auc: 0.932528\tvalid_1's auc: 0.927892\n",
      "[161]\ttraining's auc: 0.932627\tvalid_1's auc: 0.927909\n",
      "[162]\ttraining's auc: 0.932693\tvalid_1's auc: 0.927922\n",
      "[163]\ttraining's auc: 0.932742\tvalid_1's auc: 0.927921\n",
      "[164]\ttraining's auc: 0.932787\tvalid_1's auc: 0.927919\n",
      "[165]\ttraining's auc: 0.932881\tvalid_1's auc: 0.927938\n",
      "[166]\ttraining's auc: 0.93292\tvalid_1's auc: 0.927935\n",
      "[167]\ttraining's auc: 0.93298\tvalid_1's auc: 0.927935\n",
      "[168]\ttraining's auc: 0.933068\tvalid_1's auc: 0.927943\n",
      "[169]\ttraining's auc: 0.933135\tvalid_1's auc: 0.927929\n",
      "[170]\ttraining's auc: 0.933184\tvalid_1's auc: 0.927938\n",
      "[171]\ttraining's auc: 0.933243\tvalid_1's auc: 0.927945\n",
      "[172]\ttraining's auc: 0.933319\tvalid_1's auc: 0.927948\n",
      "[173]\ttraining's auc: 0.933353\tvalid_1's auc: 0.927952\n",
      "[174]\ttraining's auc: 0.933389\tvalid_1's auc: 0.927953\n",
      "[175]\ttraining's auc: 0.933471\tvalid_1's auc: 0.927952\n",
      "[176]\ttraining's auc: 0.933553\tvalid_1's auc: 0.927966\n",
      "[177]\ttraining's auc: 0.933637\tvalid_1's auc: 0.927985\n",
      "[178]\ttraining's auc: 0.933689\tvalid_1's auc: 0.927984\n",
      "[179]\ttraining's auc: 0.933746\tvalid_1's auc: 0.927975\n",
      "[180]\ttraining's auc: 0.933807\tvalid_1's auc: 0.927972\n",
      "[181]\ttraining's auc: 0.933924\tvalid_1's auc: 0.927978\n",
      "[182]\ttraining's auc: 0.933998\tvalid_1's auc: 0.927966\n",
      "[183]\ttraining's auc: 0.934045\tvalid_1's auc: 0.927968\n",
      "[184]\ttraining's auc: 0.934087\tvalid_1's auc: 0.927966\n",
      "[185]\ttraining's auc: 0.934157\tvalid_1's auc: 0.927965\n",
      "[186]\ttraining's auc: 0.934189\tvalid_1's auc: 0.927963\n",
      "[187]\ttraining's auc: 0.934241\tvalid_1's auc: 0.927948\n",
      "[188]\ttraining's auc: 0.934298\tvalid_1's auc: 0.92794\n",
      "[189]\ttraining's auc: 0.934353\tvalid_1's auc: 0.927957\n",
      "[190]\ttraining's auc: 0.934408\tvalid_1's auc: 0.927968\n",
      "[191]\ttraining's auc: 0.934431\tvalid_1's auc: 0.927972\n",
      "[192]\ttraining's auc: 0.93449\tvalid_1's auc: 0.927976\n",
      "[193]\ttraining's auc: 0.934505\tvalid_1's auc: 0.927975\n",
      "[194]\ttraining's auc: 0.934537\tvalid_1's auc: 0.927978\n",
      "[195]\ttraining's auc: 0.934589\tvalid_1's auc: 0.927978\n",
      "[196]\ttraining's auc: 0.934637\tvalid_1's auc: 0.927976\n",
      "[197]\ttraining's auc: 0.934674\tvalid_1's auc: 0.927988\n",
      "[198]\ttraining's auc: 0.934699\tvalid_1's auc: 0.927984\n",
      "[199]\ttraining's auc: 0.934735\tvalid_1's auc: 0.927983\n",
      "[200]\ttraining's auc: 0.934795\tvalid_1's auc: 0.927998\n",
      "[201]\ttraining's auc: 0.934865\tvalid_1's auc: 0.928006\n",
      "[202]\ttraining's auc: 0.934945\tvalid_1's auc: 0.928018\n",
      "[203]\ttraining's auc: 0.93497\tvalid_1's auc: 0.928022\n",
      "[204]\ttraining's auc: 0.935032\tvalid_1's auc: 0.928014\n",
      "[205]\ttraining's auc: 0.935077\tvalid_1's auc: 0.928007\n",
      "[206]\ttraining's auc: 0.935159\tvalid_1's auc: 0.928004\n",
      "[207]\ttraining's auc: 0.935211\tvalid_1's auc: 0.928005\n",
      "[208]\ttraining's auc: 0.935273\tvalid_1's auc: 0.928004\n",
      "[209]\ttraining's auc: 0.935324\tvalid_1's auc: 0.928004\n",
      "[210]\ttraining's auc: 0.935345\tvalid_1's auc: 0.928009\n",
      "[211]\ttraining's auc: 0.935383\tvalid_1's auc: 0.927993\n",
      "[212]\ttraining's auc: 0.935492\tvalid_1's auc: 0.927964\n",
      "[213]\ttraining's auc: 0.935544\tvalid_1's auc: 0.927961\n",
      "[214]\ttraining's auc: 0.935618\tvalid_1's auc: 0.927951\n",
      "[215]\ttraining's auc: 0.935729\tvalid_1's auc: 0.927907\n",
      "[216]\ttraining's auc: 0.935772\tvalid_1's auc: 0.927889\n",
      "[217]\ttraining's auc: 0.935845\tvalid_1's auc: 0.927884\n",
      "[218]\ttraining's auc: 0.93589\tvalid_1's auc: 0.927874\n",
      "[219]\ttraining's auc: 0.935915\tvalid_1's auc: 0.927875\n",
      "[220]\ttraining's auc: 0.935969\tvalid_1's auc: 0.927874\n",
      "[221]\ttraining's auc: 0.936055\tvalid_1's auc: 0.927866\n",
      "[222]\ttraining's auc: 0.936092\tvalid_1's auc: 0.927859\n",
      "[223]\ttraining's auc: 0.936148\tvalid_1's auc: 0.927848\n",
      "[224]\ttraining's auc: 0.936197\tvalid_1's auc: 0.927852\n",
      "[225]\ttraining's auc: 0.936236\tvalid_1's auc: 0.92785\n",
      "[226]\ttraining's auc: 0.936287\tvalid_1's auc: 0.927852\n",
      "[227]\ttraining's auc: 0.936305\tvalid_1's auc: 0.927846\n",
      "[228]\ttraining's auc: 0.936334\tvalid_1's auc: 0.927831\n",
      "[229]\ttraining's auc: 0.93635\tvalid_1's auc: 0.927824\n",
      "[230]\ttraining's auc: 0.936395\tvalid_1's auc: 0.927825\n",
      "[231]\ttraining's auc: 0.936441\tvalid_1's auc: 0.927823\n",
      "[232]\ttraining's auc: 0.936464\tvalid_1's auc: 0.927816\n",
      "[233]\ttraining's auc: 0.936492\tvalid_1's auc: 0.927807\n",
      "[234]\ttraining's auc: 0.936529\tvalid_1's auc: 0.9278\n",
      "[235]\ttraining's auc: 0.936555\tvalid_1's auc: 0.927805\n",
      "[236]\ttraining's auc: 0.936575\tvalid_1's auc: 0.927796\n",
      "[237]\ttraining's auc: 0.936603\tvalid_1's auc: 0.927791\n",
      "[238]\ttraining's auc: 0.936614\tvalid_1's auc: 0.927793\n",
      "[239]\ttraining's auc: 0.936696\tvalid_1's auc: 0.927795\n",
      "[240]\ttraining's auc: 0.936775\tvalid_1's auc: 0.92779\n",
      "[241]\ttraining's auc: 0.936817\tvalid_1's auc: 0.927793\n",
      "[242]\ttraining's auc: 0.936866\tvalid_1's auc: 0.927797\n",
      "[243]\ttraining's auc: 0.936886\tvalid_1's auc: 0.927797\n",
      "[244]\ttraining's auc: 0.936898\tvalid_1's auc: 0.927799\n",
      "[245]\ttraining's auc: 0.936953\tvalid_1's auc: 0.927787\n",
      "[246]\ttraining's auc: 0.936973\tvalid_1's auc: 0.927787\n",
      "[247]\ttraining's auc: 0.936983\tvalid_1's auc: 0.927785\n",
      "[248]\ttraining's auc: 0.937025\tvalid_1's auc: 0.927777\n",
      "[249]\ttraining's auc: 0.937099\tvalid_1's auc: 0.927771\n",
      "[250]\ttraining's auc: 0.937182\tvalid_1's auc: 0.927776\n",
      "[251]\ttraining's auc: 0.937287\tvalid_1's auc: 0.927753\n",
      "[252]\ttraining's auc: 0.937303\tvalid_1's auc: 0.927753\n",
      "[253]\ttraining's auc: 0.937313\tvalid_1's auc: 0.927754\n",
      "[254]\ttraining's auc: 0.937325\tvalid_1's auc: 0.927761\n",
      "[255]\ttraining's auc: 0.937356\tvalid_1's auc: 0.927756\n",
      "[256]\ttraining's auc: 0.937384\tvalid_1's auc: 0.927751\n",
      "[257]\ttraining's auc: 0.937426\tvalid_1's auc: 0.927741\n",
      "[258]\ttraining's auc: 0.937448\tvalid_1's auc: 0.927741\n",
      "[259]\ttraining's auc: 0.937513\tvalid_1's auc: 0.927745\n",
      "[260]\ttraining's auc: 0.937592\tvalid_1's auc: 0.927755\n",
      "[261]\ttraining's auc: 0.937628\tvalid_1's auc: 0.927765\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=798, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=798\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.15602359629209078, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.15602359629209078\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.24397531382432613, subsample=1.0 will be ignored. Current value: bagging_fraction=0.24397531382432613\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.05176012844110056, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.05176012844110056\n",
      "[1]\ttraining's auc: 0.922923\tvalid_1's auc: 0.920654\n",
      "[2]\ttraining's auc: 0.923409\tvalid_1's auc: 0.921334\n",
      "[3]\ttraining's auc: 0.924077\tvalid_1's auc: 0.921989\n",
      "[4]\ttraining's auc: 0.924243\tvalid_1's auc: 0.922035\n",
      "[5]\ttraining's auc: 0.924486\tvalid_1's auc: 0.92231\n",
      "[6]\ttraining's auc: 0.924463\tvalid_1's auc: 0.922376\n",
      "[7]\ttraining's auc: 0.924667\tvalid_1's auc: 0.922447\n",
      "[8]\ttraining's auc: 0.924712\tvalid_1's auc: 0.922595\n",
      "[9]\ttraining's auc: 0.925091\tvalid_1's auc: 0.922951\n",
      "[10]\ttraining's auc: 0.925067\tvalid_1's auc: 0.9229\n",
      "[11]\ttraining's auc: 0.925185\tvalid_1's auc: 0.922971\n",
      "[12]\ttraining's auc: 0.925369\tvalid_1's auc: 0.923161\n",
      "[13]\ttraining's auc: 0.925449\tvalid_1's auc: 0.923321\n",
      "[14]\ttraining's auc: 0.925508\tvalid_1's auc: 0.923412\n",
      "[15]\ttraining's auc: 0.925592\tvalid_1's auc: 0.923493\n",
      "[16]\ttraining's auc: 0.925761\tvalid_1's auc: 0.923587\n",
      "[17]\ttraining's auc: 0.92582\tvalid_1's auc: 0.923611\n",
      "[18]\ttraining's auc: 0.925876\tvalid_1's auc: 0.923673\n",
      "[19]\ttraining's auc: 0.92596\tvalid_1's auc: 0.923762\n",
      "[20]\ttraining's auc: 0.926169\tvalid_1's auc: 0.923906\n",
      "[21]\ttraining's auc: 0.926273\tvalid_1's auc: 0.923992\n",
      "[22]\ttraining's auc: 0.926434\tvalid_1's auc: 0.924066\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23]\ttraining's auc: 0.926529\tvalid_1's auc: 0.924118\n",
      "[24]\ttraining's auc: 0.926636\tvalid_1's auc: 0.9242\n",
      "[25]\ttraining's auc: 0.926729\tvalid_1's auc: 0.924281\n",
      "[26]\ttraining's auc: 0.926788\tvalid_1's auc: 0.924368\n",
      "[27]\ttraining's auc: 0.926828\tvalid_1's auc: 0.924373\n",
      "[28]\ttraining's auc: 0.926872\tvalid_1's auc: 0.92437\n",
      "[29]\ttraining's auc: 0.926908\tvalid_1's auc: 0.924373\n",
      "[30]\ttraining's auc: 0.926989\tvalid_1's auc: 0.924445\n",
      "[31]\ttraining's auc: 0.927046\tvalid_1's auc: 0.924433\n",
      "[32]\ttraining's auc: 0.927093\tvalid_1's auc: 0.924467\n",
      "[33]\ttraining's auc: 0.927122\tvalid_1's auc: 0.924468\n",
      "[34]\ttraining's auc: 0.927248\tvalid_1's auc: 0.92454\n",
      "[35]\ttraining's auc: 0.927279\tvalid_1's auc: 0.924562\n",
      "[36]\ttraining's auc: 0.927306\tvalid_1's auc: 0.924582\n",
      "[37]\ttraining's auc: 0.92731\tvalid_1's auc: 0.924574\n",
      "[38]\ttraining's auc: 0.927381\tvalid_1's auc: 0.924614\n",
      "[39]\ttraining's auc: 0.927411\tvalid_1's auc: 0.924605\n",
      "[40]\ttraining's auc: 0.927424\tvalid_1's auc: 0.9246\n",
      "[41]\ttraining's auc: 0.927457\tvalid_1's auc: 0.924631\n",
      "[42]\ttraining's auc: 0.927509\tvalid_1's auc: 0.924666\n",
      "[43]\ttraining's auc: 0.927535\tvalid_1's auc: 0.924666\n",
      "[44]\ttraining's auc: 0.927625\tvalid_1's auc: 0.924755\n",
      "[45]\ttraining's auc: 0.927694\tvalid_1's auc: 0.924816\n",
      "[46]\ttraining's auc: 0.927726\tvalid_1's auc: 0.924846\n",
      "[47]\ttraining's auc: 0.927795\tvalid_1's auc: 0.924898\n",
      "[48]\ttraining's auc: 0.927857\tvalid_1's auc: 0.924928\n",
      "[49]\ttraining's auc: 0.927906\tvalid_1's auc: 0.92496\n",
      "[50]\ttraining's auc: 0.927955\tvalid_1's auc: 0.925006\n",
      "[51]\ttraining's auc: 0.928076\tvalid_1's auc: 0.925105\n",
      "[52]\ttraining's auc: 0.928094\tvalid_1's auc: 0.925096\n",
      "[53]\ttraining's auc: 0.928156\tvalid_1's auc: 0.925103\n",
      "[54]\ttraining's auc: 0.928263\tvalid_1's auc: 0.925164\n",
      "[55]\ttraining's auc: 0.928283\tvalid_1's auc: 0.925148\n",
      "[56]\ttraining's auc: 0.928308\tvalid_1's auc: 0.925152\n",
      "[57]\ttraining's auc: 0.928416\tvalid_1's auc: 0.925237\n",
      "[58]\ttraining's auc: 0.928447\tvalid_1's auc: 0.925273\n",
      "[59]\ttraining's auc: 0.928504\tvalid_1's auc: 0.92531\n",
      "[60]\ttraining's auc: 0.928592\tvalid_1's auc: 0.925351\n",
      "[61]\ttraining's auc: 0.928675\tvalid_1's auc: 0.925482\n",
      "[62]\ttraining's auc: 0.928708\tvalid_1's auc: 0.925512\n",
      "[63]\ttraining's auc: 0.928747\tvalid_1's auc: 0.92554\n",
      "[64]\ttraining's auc: 0.928786\tvalid_1's auc: 0.925557\n",
      "[65]\ttraining's auc: 0.928815\tvalid_1's auc: 0.925547\n",
      "[66]\ttraining's auc: 0.928841\tvalid_1's auc: 0.925547\n",
      "[67]\ttraining's auc: 0.928929\tvalid_1's auc: 0.925621\n",
      "[68]\ttraining's auc: 0.928981\tvalid_1's auc: 0.925671\n",
      "[69]\ttraining's auc: 0.929029\tvalid_1's auc: 0.925712\n",
      "[70]\ttraining's auc: 0.929077\tvalid_1's auc: 0.925736\n",
      "[71]\ttraining's auc: 0.929129\tvalid_1's auc: 0.925778\n",
      "[72]\ttraining's auc: 0.929153\tvalid_1's auc: 0.925787\n",
      "[73]\ttraining's auc: 0.929187\tvalid_1's auc: 0.925806\n",
      "[74]\ttraining's auc: 0.92926\tvalid_1's auc: 0.925839\n",
      "[75]\ttraining's auc: 0.92929\tvalid_1's auc: 0.925842\n",
      "[76]\ttraining's auc: 0.929311\tvalid_1's auc: 0.925859\n",
      "[77]\ttraining's auc: 0.929392\tvalid_1's auc: 0.92589\n",
      "[78]\ttraining's auc: 0.929426\tvalid_1's auc: 0.925937\n",
      "[79]\ttraining's auc: 0.929469\tvalid_1's auc: 0.92595\n",
      "[80]\ttraining's auc: 0.92962\tvalid_1's auc: 0.926085\n",
      "[81]\ttraining's auc: 0.929678\tvalid_1's auc: 0.9261\n",
      "[82]\ttraining's auc: 0.929819\tvalid_1's auc: 0.926221\n",
      "[83]\ttraining's auc: 0.929848\tvalid_1's auc: 0.926237\n",
      "[84]\ttraining's auc: 0.92989\tvalid_1's auc: 0.926255\n",
      "[85]\ttraining's auc: 0.929912\tvalid_1's auc: 0.926261\n",
      "[86]\ttraining's auc: 0.929942\tvalid_1's auc: 0.92627\n",
      "[87]\ttraining's auc: 0.929971\tvalid_1's auc: 0.926265\n",
      "[88]\ttraining's auc: 0.930099\tvalid_1's auc: 0.926348\n",
      "[89]\ttraining's auc: 0.930122\tvalid_1's auc: 0.926354\n",
      "[90]\ttraining's auc: 0.930159\tvalid_1's auc: 0.926361\n",
      "[91]\ttraining's auc: 0.930198\tvalid_1's auc: 0.926373\n",
      "[92]\ttraining's auc: 0.930228\tvalid_1's auc: 0.926389\n",
      "[93]\ttraining's auc: 0.93027\tvalid_1's auc: 0.926426\n",
      "[94]\ttraining's auc: 0.93033\tvalid_1's auc: 0.92646\n",
      "[95]\ttraining's auc: 0.930399\tvalid_1's auc: 0.926479\n",
      "[96]\ttraining's auc: 0.930445\tvalid_1's auc: 0.926498\n",
      "[97]\ttraining's auc: 0.930529\tvalid_1's auc: 0.926547\n",
      "[98]\ttraining's auc: 0.93058\tvalid_1's auc: 0.926575\n",
      "[99]\ttraining's auc: 0.930598\tvalid_1's auc: 0.926583\n",
      "[100]\ttraining's auc: 0.930618\tvalid_1's auc: 0.926596\n",
      "[101]\ttraining's auc: 0.930624\tvalid_1's auc: 0.9266\n",
      "[102]\ttraining's auc: 0.930656\tvalid_1's auc: 0.926603\n",
      "[103]\ttraining's auc: 0.930702\tvalid_1's auc: 0.92661\n",
      "[104]\ttraining's auc: 0.930729\tvalid_1's auc: 0.926615\n",
      "[105]\ttraining's auc: 0.930746\tvalid_1's auc: 0.92662\n",
      "[106]\ttraining's auc: 0.930766\tvalid_1's auc: 0.92662\n",
      "[107]\ttraining's auc: 0.930813\tvalid_1's auc: 0.926629\n",
      "[108]\ttraining's auc: 0.930852\tvalid_1's auc: 0.926642\n",
      "[109]\ttraining's auc: 0.930894\tvalid_1's auc: 0.926655\n",
      "[110]\ttraining's auc: 0.930907\tvalid_1's auc: 0.926655\n",
      "[111]\ttraining's auc: 0.930924\tvalid_1's auc: 0.926662\n",
      "[112]\ttraining's auc: 0.930948\tvalid_1's auc: 0.926674\n",
      "[113]\ttraining's auc: 0.93099\tvalid_1's auc: 0.926693\n",
      "[114]\ttraining's auc: 0.93103\tvalid_1's auc: 0.926703\n",
      "[115]\ttraining's auc: 0.931094\tvalid_1's auc: 0.926716\n",
      "[116]\ttraining's auc: 0.931139\tvalid_1's auc: 0.926723\n",
      "[117]\ttraining's auc: 0.931166\tvalid_1's auc: 0.926727\n",
      "[118]\ttraining's auc: 0.931213\tvalid_1's auc: 0.926742\n",
      "[119]\ttraining's auc: 0.931223\tvalid_1's auc: 0.926744\n",
      "[120]\ttraining's auc: 0.931268\tvalid_1's auc: 0.926774\n",
      "[121]\ttraining's auc: 0.931325\tvalid_1's auc: 0.926807\n",
      "[122]\ttraining's auc: 0.931354\tvalid_1's auc: 0.92685\n",
      "[123]\ttraining's auc: 0.931395\tvalid_1's auc: 0.926865\n",
      "[124]\ttraining's auc: 0.931401\tvalid_1's auc: 0.926867\n",
      "[125]\ttraining's auc: 0.931452\tvalid_1's auc: 0.926884\n",
      "[126]\ttraining's auc: 0.931471\tvalid_1's auc: 0.926892\n",
      "[127]\ttraining's auc: 0.931507\tvalid_1's auc: 0.926905\n",
      "[128]\ttraining's auc: 0.931549\tvalid_1's auc: 0.926929\n",
      "[129]\ttraining's auc: 0.931556\tvalid_1's auc: 0.926929\n",
      "[130]\ttraining's auc: 0.931599\tvalid_1's auc: 0.926961\n",
      "[131]\ttraining's auc: 0.931615\tvalid_1's auc: 0.926955\n",
      "[132]\ttraining's auc: 0.931654\tvalid_1's auc: 0.926987\n",
      "[133]\ttraining's auc: 0.931662\tvalid_1's auc: 0.926993\n",
      "[134]\ttraining's auc: 0.93174\tvalid_1's auc: 0.927034\n",
      "[135]\ttraining's auc: 0.931747\tvalid_1's auc: 0.927035\n",
      "[136]\ttraining's auc: 0.931805\tvalid_1's auc: 0.92706\n",
      "[137]\ttraining's auc: 0.931813\tvalid_1's auc: 0.927056\n",
      "[138]\ttraining's auc: 0.931834\tvalid_1's auc: 0.927065\n",
      "[139]\ttraining's auc: 0.931868\tvalid_1's auc: 0.927076\n",
      "[140]\ttraining's auc: 0.931877\tvalid_1's auc: 0.927078\n",
      "[141]\ttraining's auc: 0.931905\tvalid_1's auc: 0.927084\n",
      "[142]\ttraining's auc: 0.931935\tvalid_1's auc: 0.927084\n",
      "[143]\ttraining's auc: 0.93196\tvalid_1's auc: 0.927088\n",
      "[144]\ttraining's auc: 0.931969\tvalid_1's auc: 0.927092\n",
      "[145]\ttraining's auc: 0.932007\tvalid_1's auc: 0.927105\n",
      "[146]\ttraining's auc: 0.93205\tvalid_1's auc: 0.92714\n",
      "[147]\ttraining's auc: 0.93207\tvalid_1's auc: 0.927138\n",
      "[148]\ttraining's auc: 0.932098\tvalid_1's auc: 0.927153\n",
      "[149]\ttraining's auc: 0.932111\tvalid_1's auc: 0.927157\n",
      "[150]\ttraining's auc: 0.932166\tvalid_1's auc: 0.927173\n",
      "[151]\ttraining's auc: 0.932191\tvalid_1's auc: 0.927176\n",
      "[152]\ttraining's auc: 0.932222\tvalid_1's auc: 0.927193\n",
      "[153]\ttraining's auc: 0.93224\tvalid_1's auc: 0.927193\n",
      "[154]\ttraining's auc: 0.932287\tvalid_1's auc: 0.927196\n",
      "[155]\ttraining's auc: 0.932323\tvalid_1's auc: 0.92721\n",
      "[156]\ttraining's auc: 0.932415\tvalid_1's auc: 0.927243\n",
      "[157]\ttraining's auc: 0.932435\tvalid_1's auc: 0.927251\n",
      "[158]\ttraining's auc: 0.932513\tvalid_1's auc: 0.927275\n",
      "[159]\ttraining's auc: 0.932548\tvalid_1's auc: 0.927272\n",
      "[160]\ttraining's auc: 0.932581\tvalid_1's auc: 0.927289\n",
      "[161]\ttraining's auc: 0.932632\tvalid_1's auc: 0.927293\n",
      "[162]\ttraining's auc: 0.932662\tvalid_1's auc: 0.927285\n",
      "[163]\ttraining's auc: 0.93273\tvalid_1's auc: 0.927289\n",
      "[164]\ttraining's auc: 0.932808\tvalid_1's auc: 0.927301\n",
      "[165]\ttraining's auc: 0.932841\tvalid_1's auc: 0.927321\n",
      "[166]\ttraining's auc: 0.932875\tvalid_1's auc: 0.927338\n",
      "[167]\ttraining's auc: 0.932922\tvalid_1's auc: 0.92735\n",
      "[168]\ttraining's auc: 0.932987\tvalid_1's auc: 0.92738\n",
      "[169]\ttraining's auc: 0.933023\tvalid_1's auc: 0.92738\n",
      "[170]\ttraining's auc: 0.933076\tvalid_1's auc: 0.927391\n",
      "[171]\ttraining's auc: 0.933105\tvalid_1's auc: 0.927392\n",
      "[172]\ttraining's auc: 0.933193\tvalid_1's auc: 0.927403\n",
      "[173]\ttraining's auc: 0.933223\tvalid_1's auc: 0.927405\n",
      "[174]\ttraining's auc: 0.933279\tvalid_1's auc: 0.927413\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[175]\ttraining's auc: 0.933324\tvalid_1's auc: 0.927425\n",
      "[176]\ttraining's auc: 0.933356\tvalid_1's auc: 0.927438\n",
      "[177]\ttraining's auc: 0.933401\tvalid_1's auc: 0.927445\n",
      "[178]\ttraining's auc: 0.933465\tvalid_1's auc: 0.927467\n",
      "[179]\ttraining's auc: 0.933529\tvalid_1's auc: 0.927459\n",
      "[180]\ttraining's auc: 0.93357\tvalid_1's auc: 0.927465\n",
      "[181]\ttraining's auc: 0.933642\tvalid_1's auc: 0.927476\n",
      "[182]\ttraining's auc: 0.933724\tvalid_1's auc: 0.927478\n",
      "[183]\ttraining's auc: 0.933831\tvalid_1's auc: 0.927495\n",
      "[184]\ttraining's auc: 0.93389\tvalid_1's auc: 0.927494\n",
      "[185]\ttraining's auc: 0.933933\tvalid_1's auc: 0.927503\n",
      "[186]\ttraining's auc: 0.934019\tvalid_1's auc: 0.927486\n",
      "[187]\ttraining's auc: 0.934053\tvalid_1's auc: 0.927486\n",
      "[188]\ttraining's auc: 0.934081\tvalid_1's auc: 0.92749\n",
      "[189]\ttraining's auc: 0.934212\tvalid_1's auc: 0.927486\n",
      "[190]\ttraining's auc: 0.934248\tvalid_1's auc: 0.927495\n",
      "[191]\ttraining's auc: 0.934297\tvalid_1's auc: 0.927501\n",
      "[192]\ttraining's auc: 0.934336\tvalid_1's auc: 0.927514\n",
      "[193]\ttraining's auc: 0.934368\tvalid_1's auc: 0.927515\n",
      "[194]\ttraining's auc: 0.934454\tvalid_1's auc: 0.92754\n",
      "[195]\ttraining's auc: 0.934465\tvalid_1's auc: 0.92754\n",
      "[196]\ttraining's auc: 0.934501\tvalid_1's auc: 0.927543\n",
      "[197]\ttraining's auc: 0.934518\tvalid_1's auc: 0.927544\n",
      "[198]\ttraining's auc: 0.934578\tvalid_1's auc: 0.927544\n",
      "[199]\ttraining's auc: 0.93464\tvalid_1's auc: 0.927549\n",
      "[200]\ttraining's auc: 0.934649\tvalid_1's auc: 0.927547\n",
      "[201]\ttraining's auc: 0.934701\tvalid_1's auc: 0.927553\n",
      "[202]\ttraining's auc: 0.934736\tvalid_1's auc: 0.927559\n",
      "[203]\ttraining's auc: 0.934766\tvalid_1's auc: 0.927558\n",
      "[204]\ttraining's auc: 0.934807\tvalid_1's auc: 0.927561\n",
      "[205]\ttraining's auc: 0.934843\tvalid_1's auc: 0.927554\n",
      "[206]\ttraining's auc: 0.934952\tvalid_1's auc: 0.927565\n",
      "[207]\ttraining's auc: 0.935056\tvalid_1's auc: 0.927566\n",
      "[208]\ttraining's auc: 0.935171\tvalid_1's auc: 0.92754\n",
      "[209]\ttraining's auc: 0.935219\tvalid_1's auc: 0.927544\n",
      "[210]\ttraining's auc: 0.935232\tvalid_1's auc: 0.92754\n",
      "[211]\ttraining's auc: 0.935322\tvalid_1's auc: 0.927534\n",
      "[212]\ttraining's auc: 0.935366\tvalid_1's auc: 0.927532\n",
      "[213]\ttraining's auc: 0.935376\tvalid_1's auc: 0.927533\n",
      "[214]\ttraining's auc: 0.935438\tvalid_1's auc: 0.92754\n",
      "[215]\ttraining's auc: 0.935476\tvalid_1's auc: 0.92754\n",
      "[216]\ttraining's auc: 0.935511\tvalid_1's auc: 0.927547\n",
      "[217]\ttraining's auc: 0.935552\tvalid_1's auc: 0.927539\n",
      "[218]\ttraining's auc: 0.935604\tvalid_1's auc: 0.927552\n",
      "[219]\ttraining's auc: 0.93567\tvalid_1's auc: 0.927561\n",
      "[220]\ttraining's auc: 0.935699\tvalid_1's auc: 0.927559\n",
      "[221]\ttraining's auc: 0.935725\tvalid_1's auc: 0.927556\n",
      "[222]\ttraining's auc: 0.93573\tvalid_1's auc: 0.927558\n",
      "[223]\ttraining's auc: 0.935763\tvalid_1's auc: 0.927558\n",
      "[224]\ttraining's auc: 0.935823\tvalid_1's auc: 0.927546\n",
      "[225]\ttraining's auc: 0.935881\tvalid_1's auc: 0.927557\n",
      "[226]\ttraining's auc: 0.935904\tvalid_1's auc: 0.927559\n",
      "[227]\ttraining's auc: 0.935998\tvalid_1's auc: 0.92756\n",
      "[228]\ttraining's auc: 0.936005\tvalid_1's auc: 0.927558\n",
      "[229]\ttraining's auc: 0.936041\tvalid_1's auc: 0.927562\n",
      "[230]\ttraining's auc: 0.93607\tvalid_1's auc: 0.927571\n",
      "[231]\ttraining's auc: 0.936122\tvalid_1's auc: 0.927578\n",
      "[232]\ttraining's auc: 0.936255\tvalid_1's auc: 0.927574\n",
      "[233]\ttraining's auc: 0.936292\tvalid_1's auc: 0.927572\n",
      "[234]\ttraining's auc: 0.936336\tvalid_1's auc: 0.927566\n",
      "[235]\ttraining's auc: 0.936368\tvalid_1's auc: 0.927558\n",
      "[236]\ttraining's auc: 0.936378\tvalid_1's auc: 0.927556\n",
      "[237]\ttraining's auc: 0.936401\tvalid_1's auc: 0.927557\n",
      "[238]\ttraining's auc: 0.936504\tvalid_1's auc: 0.927536\n",
      "[239]\ttraining's auc: 0.936533\tvalid_1's auc: 0.927539\n",
      "[240]\ttraining's auc: 0.936655\tvalid_1's auc: 0.927526\n",
      "[241]\ttraining's auc: 0.936686\tvalid_1's auc: 0.927528\n",
      "[242]\ttraining's auc: 0.93671\tvalid_1's auc: 0.927535\n",
      "[243]\ttraining's auc: 0.93673\tvalid_1's auc: 0.927533\n",
      "[244]\ttraining's auc: 0.936752\tvalid_1's auc: 0.927532\n",
      "[245]\ttraining's auc: 0.936799\tvalid_1's auc: 0.92753\n",
      "[246]\ttraining's auc: 0.93683\tvalid_1's auc: 0.927531\n",
      "[247]\ttraining's auc: 0.936845\tvalid_1's auc: 0.927531\n",
      "[248]\ttraining's auc: 0.936914\tvalid_1's auc: 0.927534\n",
      "[249]\ttraining's auc: 0.937004\tvalid_1's auc: 0.927529\n",
      "[250]\ttraining's auc: 0.937028\tvalid_1's auc: 0.927528\n",
      "[251]\ttraining's auc: 0.937096\tvalid_1's auc: 0.92753\n",
      "[252]\ttraining's auc: 0.937171\tvalid_1's auc: 0.927525\n",
      "[253]\ttraining's auc: 0.937254\tvalid_1's auc: 0.927513\n",
      "[254]\ttraining's auc: 0.93728\tvalid_1's auc: 0.92752\n",
      "[255]\ttraining's auc: 0.937308\tvalid_1's auc: 0.927525\n",
      "[256]\ttraining's auc: 0.937316\tvalid_1's auc: 0.927522\n",
      "[257]\ttraining's auc: 0.937341\tvalid_1's auc: 0.927524\n",
      "[258]\ttraining's auc: 0.937355\tvalid_1's auc: 0.927522\n",
      "[259]\ttraining's auc: 0.937409\tvalid_1's auc: 0.927523\n",
      "[260]\ttraining's auc: 0.937445\tvalid_1's auc: 0.92752\n",
      "[261]\ttraining's auc: 0.937458\tvalid_1's auc: 0.927517\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=798, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=798\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.15602359629209078, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.15602359629209078\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.24397531382432613, subsample=1.0 will be ignored. Current value: bagging_fraction=0.24397531382432613\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.05176012844110056, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.05176012844110056\n",
      "[1]\ttraining's auc: 0.922714\tvalid_1's auc: 0.920476\n",
      "[2]\ttraining's auc: 0.922802\tvalid_1's auc: 0.920786\n",
      "[3]\ttraining's auc: 0.92333\tvalid_1's auc: 0.921422\n",
      "[4]\ttraining's auc: 0.923914\tvalid_1's auc: 0.922149\n",
      "[5]\ttraining's auc: 0.92413\tvalid_1's auc: 0.922282\n",
      "[6]\ttraining's auc: 0.924329\tvalid_1's auc: 0.922449\n",
      "[7]\ttraining's auc: 0.924406\tvalid_1's auc: 0.922458\n",
      "[8]\ttraining's auc: 0.924691\tvalid_1's auc: 0.922674\n",
      "[9]\ttraining's auc: 0.924759\tvalid_1's auc: 0.922716\n",
      "[10]\ttraining's auc: 0.924862\tvalid_1's auc: 0.922863\n",
      "[11]\ttraining's auc: 0.924993\tvalid_1's auc: 0.922878\n",
      "[12]\ttraining's auc: 0.925153\tvalid_1's auc: 0.923071\n",
      "[13]\ttraining's auc: 0.925234\tvalid_1's auc: 0.923165\n",
      "[14]\ttraining's auc: 0.925332\tvalid_1's auc: 0.923253\n",
      "[15]\ttraining's auc: 0.925421\tvalid_1's auc: 0.923323\n",
      "[16]\ttraining's auc: 0.925452\tvalid_1's auc: 0.923325\n",
      "[17]\ttraining's auc: 0.925511\tvalid_1's auc: 0.923319\n",
      "[18]\ttraining's auc: 0.925715\tvalid_1's auc: 0.923564\n",
      "[19]\ttraining's auc: 0.925791\tvalid_1's auc: 0.923688\n",
      "[20]\ttraining's auc: 0.925825\tvalid_1's auc: 0.92366\n",
      "[21]\ttraining's auc: 0.925958\tvalid_1's auc: 0.923726\n",
      "[22]\ttraining's auc: 0.92615\tvalid_1's auc: 0.923892\n",
      "[23]\ttraining's auc: 0.926274\tvalid_1's auc: 0.923988\n",
      "[24]\ttraining's auc: 0.926397\tvalid_1's auc: 0.924042\n",
      "[25]\ttraining's auc: 0.926524\tvalid_1's auc: 0.924196\n",
      "[26]\ttraining's auc: 0.926655\tvalid_1's auc: 0.924234\n",
      "[27]\ttraining's auc: 0.926759\tvalid_1's auc: 0.924322\n",
      "[28]\ttraining's auc: 0.926827\tvalid_1's auc: 0.92439\n",
      "[29]\ttraining's auc: 0.926868\tvalid_1's auc: 0.924415\n",
      "[30]\ttraining's auc: 0.926913\tvalid_1's auc: 0.924437\n",
      "[31]\ttraining's auc: 0.926961\tvalid_1's auc: 0.924475\n",
      "[32]\ttraining's auc: 0.927016\tvalid_1's auc: 0.924544\n",
      "[33]\ttraining's auc: 0.92705\tvalid_1's auc: 0.924577\n",
      "[34]\ttraining's auc: 0.927092\tvalid_1's auc: 0.924627\n",
      "[35]\ttraining's auc: 0.927111\tvalid_1's auc: 0.924668\n",
      "[36]\ttraining's auc: 0.92716\tvalid_1's auc: 0.924686\n",
      "[37]\ttraining's auc: 0.927168\tvalid_1's auc: 0.924687\n",
      "[38]\ttraining's auc: 0.927244\tvalid_1's auc: 0.924727\n",
      "[39]\ttraining's auc: 0.927271\tvalid_1's auc: 0.924759\n",
      "[40]\ttraining's auc: 0.927295\tvalid_1's auc: 0.924797\n",
      "[41]\ttraining's auc: 0.927331\tvalid_1's auc: 0.924834\n",
      "[42]\ttraining's auc: 0.927379\tvalid_1's auc: 0.924887\n",
      "[43]\ttraining's auc: 0.92749\tvalid_1's auc: 0.925036\n",
      "[44]\ttraining's auc: 0.927533\tvalid_1's auc: 0.925084\n",
      "[45]\ttraining's auc: 0.927576\tvalid_1's auc: 0.925142\n",
      "[46]\ttraining's auc: 0.92759\tvalid_1's auc: 0.925162\n",
      "[47]\ttraining's auc: 0.927599\tvalid_1's auc: 0.925188\n",
      "[48]\ttraining's auc: 0.927612\tvalid_1's auc: 0.925187\n",
      "[49]\ttraining's auc: 0.927633\tvalid_1's auc: 0.925227\n",
      "[50]\ttraining's auc: 0.927766\tvalid_1's auc: 0.925307\n",
      "[51]\ttraining's auc: 0.927877\tvalid_1's auc: 0.925386\n",
      "[52]\ttraining's auc: 0.927934\tvalid_1's auc: 0.925443\n",
      "[53]\ttraining's auc: 0.927966\tvalid_1's auc: 0.925467\n",
      "[54]\ttraining's auc: 0.928043\tvalid_1's auc: 0.925558\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[55]\ttraining's auc: 0.928132\tvalid_1's auc: 0.92565\n",
      "[56]\ttraining's auc: 0.928164\tvalid_1's auc: 0.925676\n",
      "[57]\ttraining's auc: 0.92822\tvalid_1's auc: 0.925748\n",
      "[58]\ttraining's auc: 0.928263\tvalid_1's auc: 0.925786\n",
      "[59]\ttraining's auc: 0.928368\tvalid_1's auc: 0.92588\n",
      "[60]\ttraining's auc: 0.928391\tvalid_1's auc: 0.925892\n",
      "[61]\ttraining's auc: 0.928426\tvalid_1's auc: 0.925914\n",
      "[62]\ttraining's auc: 0.928461\tvalid_1's auc: 0.925945\n",
      "[63]\ttraining's auc: 0.928538\tvalid_1's auc: 0.926\n",
      "[64]\ttraining's auc: 0.928568\tvalid_1's auc: 0.926025\n",
      "[65]\ttraining's auc: 0.928652\tvalid_1's auc: 0.92608\n",
      "[66]\ttraining's auc: 0.928673\tvalid_1's auc: 0.926088\n",
      "[67]\ttraining's auc: 0.928723\tvalid_1's auc: 0.926122\n",
      "[68]\ttraining's auc: 0.928784\tvalid_1's auc: 0.926175\n",
      "[69]\ttraining's auc: 0.928887\tvalid_1's auc: 0.926234\n",
      "[70]\ttraining's auc: 0.928911\tvalid_1's auc: 0.926243\n",
      "[71]\ttraining's auc: 0.928965\tvalid_1's auc: 0.926277\n",
      "[72]\ttraining's auc: 0.929025\tvalid_1's auc: 0.926307\n",
      "[73]\ttraining's auc: 0.929071\tvalid_1's auc: 0.926332\n",
      "[74]\ttraining's auc: 0.929116\tvalid_1's auc: 0.926363\n",
      "[75]\ttraining's auc: 0.929164\tvalid_1's auc: 0.926393\n",
      "[76]\ttraining's auc: 0.929227\tvalid_1's auc: 0.926425\n",
      "[77]\ttraining's auc: 0.929261\tvalid_1's auc: 0.926442\n",
      "[78]\ttraining's auc: 0.929302\tvalid_1's auc: 0.926463\n",
      "[79]\ttraining's auc: 0.929351\tvalid_1's auc: 0.926496\n",
      "[80]\ttraining's auc: 0.929397\tvalid_1's auc: 0.926523\n",
      "[81]\ttraining's auc: 0.929433\tvalid_1's auc: 0.926537\n",
      "[82]\ttraining's auc: 0.929468\tvalid_1's auc: 0.926545\n",
      "[83]\ttraining's auc: 0.9295\tvalid_1's auc: 0.926559\n",
      "[84]\ttraining's auc: 0.929569\tvalid_1's auc: 0.926573\n",
      "[85]\ttraining's auc: 0.929592\tvalid_1's auc: 0.926577\n",
      "[86]\ttraining's auc: 0.929651\tvalid_1's auc: 0.926569\n",
      "[87]\ttraining's auc: 0.929693\tvalid_1's auc: 0.926589\n",
      "[88]\ttraining's auc: 0.929793\tvalid_1's auc: 0.926663\n",
      "[89]\ttraining's auc: 0.929871\tvalid_1's auc: 0.926686\n",
      "[90]\ttraining's auc: 0.929945\tvalid_1's auc: 0.926721\n",
      "[91]\ttraining's auc: 0.929996\tvalid_1's auc: 0.926737\n",
      "[92]\ttraining's auc: 0.930019\tvalid_1's auc: 0.926744\n",
      "[93]\ttraining's auc: 0.930064\tvalid_1's auc: 0.926761\n",
      "[94]\ttraining's auc: 0.930108\tvalid_1's auc: 0.926778\n",
      "[95]\ttraining's auc: 0.930138\tvalid_1's auc: 0.926787\n",
      "[96]\ttraining's auc: 0.930209\tvalid_1's auc: 0.926796\n",
      "[97]\ttraining's auc: 0.930273\tvalid_1's auc: 0.926827\n",
      "[98]\ttraining's auc: 0.930309\tvalid_1's auc: 0.926838\n",
      "[99]\ttraining's auc: 0.930343\tvalid_1's auc: 0.926856\n",
      "[100]\ttraining's auc: 0.930435\tvalid_1's auc: 0.926901\n",
      "[101]\ttraining's auc: 0.930468\tvalid_1's auc: 0.926918\n",
      "[102]\ttraining's auc: 0.930541\tvalid_1's auc: 0.926944\n",
      "[103]\ttraining's auc: 0.930569\tvalid_1's auc: 0.92695\n",
      "[104]\ttraining's auc: 0.930619\tvalid_1's auc: 0.926963\n",
      "[105]\ttraining's auc: 0.930659\tvalid_1's auc: 0.926995\n",
      "[106]\ttraining's auc: 0.93069\tvalid_1's auc: 0.92701\n",
      "[107]\ttraining's auc: 0.930714\tvalid_1's auc: 0.927026\n",
      "[108]\ttraining's auc: 0.930733\tvalid_1's auc: 0.92706\n",
      "[109]\ttraining's auc: 0.930775\tvalid_1's auc: 0.927072\n",
      "[110]\ttraining's auc: 0.930816\tvalid_1's auc: 0.927096\n",
      "[111]\ttraining's auc: 0.930855\tvalid_1's auc: 0.927117\n",
      "[112]\ttraining's auc: 0.930869\tvalid_1's auc: 0.92713\n",
      "[113]\ttraining's auc: 0.930911\tvalid_1's auc: 0.927138\n",
      "[114]\ttraining's auc: 0.930935\tvalid_1's auc: 0.927149\n",
      "[115]\ttraining's auc: 0.930971\tvalid_1's auc: 0.927158\n",
      "[116]\ttraining's auc: 0.930995\tvalid_1's auc: 0.927164\n",
      "[117]\ttraining's auc: 0.93102\tvalid_1's auc: 0.927173\n",
      "[118]\ttraining's auc: 0.93107\tvalid_1's auc: 0.927177\n",
      "[119]\ttraining's auc: 0.931101\tvalid_1's auc: 0.927198\n",
      "[120]\ttraining's auc: 0.931163\tvalid_1's auc: 0.927216\n",
      "[121]\ttraining's auc: 0.931225\tvalid_1's auc: 0.927232\n",
      "[122]\ttraining's auc: 0.931264\tvalid_1's auc: 0.92725\n",
      "[123]\ttraining's auc: 0.931306\tvalid_1's auc: 0.92727\n",
      "[124]\ttraining's auc: 0.931362\tvalid_1's auc: 0.927282\n",
      "[125]\ttraining's auc: 0.931375\tvalid_1's auc: 0.927285\n",
      "[126]\ttraining's auc: 0.931412\tvalid_1's auc: 0.927285\n",
      "[127]\ttraining's auc: 0.931444\tvalid_1's auc: 0.927293\n",
      "[128]\ttraining's auc: 0.931477\tvalid_1's auc: 0.927297\n",
      "[129]\ttraining's auc: 0.931485\tvalid_1's auc: 0.927298\n",
      "[130]\ttraining's auc: 0.931492\tvalid_1's auc: 0.927301\n",
      "[131]\ttraining's auc: 0.931497\tvalid_1's auc: 0.927303\n",
      "[132]\ttraining's auc: 0.931523\tvalid_1's auc: 0.927306\n",
      "[133]\ttraining's auc: 0.931531\tvalid_1's auc: 0.927311\n",
      "[134]\ttraining's auc: 0.931556\tvalid_1's auc: 0.927314\n",
      "[135]\ttraining's auc: 0.931572\tvalid_1's auc: 0.927323\n",
      "[136]\ttraining's auc: 0.93158\tvalid_1's auc: 0.927326\n",
      "[137]\ttraining's auc: 0.931599\tvalid_1's auc: 0.927324\n",
      "[138]\ttraining's auc: 0.931645\tvalid_1's auc: 0.927333\n",
      "[139]\ttraining's auc: 0.931666\tvalid_1's auc: 0.927332\n",
      "[140]\ttraining's auc: 0.9317\tvalid_1's auc: 0.92735\n",
      "[141]\ttraining's auc: 0.93172\tvalid_1's auc: 0.927353\n",
      "[142]\ttraining's auc: 0.931755\tvalid_1's auc: 0.927363\n",
      "[143]\ttraining's auc: 0.931799\tvalid_1's auc: 0.927374\n",
      "[144]\ttraining's auc: 0.931834\tvalid_1's auc: 0.927379\n",
      "[145]\ttraining's auc: 0.931873\tvalid_1's auc: 0.927389\n",
      "[146]\ttraining's auc: 0.931896\tvalid_1's auc: 0.927392\n",
      "[147]\ttraining's auc: 0.931929\tvalid_1's auc: 0.927396\n",
      "[148]\ttraining's auc: 0.931948\tvalid_1's auc: 0.927397\n",
      "[149]\ttraining's auc: 0.931975\tvalid_1's auc: 0.927411\n",
      "[150]\ttraining's auc: 0.932019\tvalid_1's auc: 0.927412\n",
      "[151]\ttraining's auc: 0.93205\tvalid_1's auc: 0.927412\n",
      "[152]\ttraining's auc: 0.932071\tvalid_1's auc: 0.927412\n",
      "[153]\ttraining's auc: 0.932127\tvalid_1's auc: 0.927418\n",
      "[154]\ttraining's auc: 0.932149\tvalid_1's auc: 0.927417\n",
      "[155]\ttraining's auc: 0.93219\tvalid_1's auc: 0.927404\n",
      "[156]\ttraining's auc: 0.932247\tvalid_1's auc: 0.92741\n",
      "[157]\ttraining's auc: 0.932351\tvalid_1's auc: 0.927422\n",
      "[158]\ttraining's auc: 0.932393\tvalid_1's auc: 0.92743\n",
      "[159]\ttraining's auc: 0.93246\tvalid_1's auc: 0.927445\n",
      "[160]\ttraining's auc: 0.932504\tvalid_1's auc: 0.927449\n",
      "[161]\ttraining's auc: 0.932532\tvalid_1's auc: 0.927445\n",
      "[162]\ttraining's auc: 0.932568\tvalid_1's auc: 0.927447\n",
      "[163]\ttraining's auc: 0.932596\tvalid_1's auc: 0.927453\n",
      "[164]\ttraining's auc: 0.932625\tvalid_1's auc: 0.927457\n",
      "[165]\ttraining's auc: 0.932651\tvalid_1's auc: 0.927459\n",
      "[166]\ttraining's auc: 0.932679\tvalid_1's auc: 0.927463\n",
      "[167]\ttraining's auc: 0.932703\tvalid_1's auc: 0.927468\n",
      "[168]\ttraining's auc: 0.932729\tvalid_1's auc: 0.927466\n",
      "[169]\ttraining's auc: 0.932756\tvalid_1's auc: 0.927461\n",
      "[170]\ttraining's auc: 0.932816\tvalid_1's auc: 0.927472\n",
      "[171]\ttraining's auc: 0.932879\tvalid_1's auc: 0.927468\n",
      "[172]\ttraining's auc: 0.932903\tvalid_1's auc: 0.927468\n",
      "[173]\ttraining's auc: 0.932947\tvalid_1's auc: 0.927467\n",
      "[174]\ttraining's auc: 0.932985\tvalid_1's auc: 0.927471\n",
      "[175]\ttraining's auc: 0.933017\tvalid_1's auc: 0.927474\n",
      "[176]\ttraining's auc: 0.933041\tvalid_1's auc: 0.927475\n",
      "[177]\ttraining's auc: 0.933072\tvalid_1's auc: 0.927489\n",
      "[178]\ttraining's auc: 0.933125\tvalid_1's auc: 0.927489\n",
      "[179]\ttraining's auc: 0.933158\tvalid_1's auc: 0.927493\n",
      "[180]\ttraining's auc: 0.933261\tvalid_1's auc: 0.927486\n",
      "[181]\ttraining's auc: 0.933288\tvalid_1's auc: 0.927491\n",
      "[182]\ttraining's auc: 0.93334\tvalid_1's auc: 0.927496\n",
      "[183]\ttraining's auc: 0.933376\tvalid_1's auc: 0.927502\n",
      "[184]\ttraining's auc: 0.93343\tvalid_1's auc: 0.927513\n",
      "[185]\ttraining's auc: 0.933506\tvalid_1's auc: 0.927514\n",
      "[186]\ttraining's auc: 0.933546\tvalid_1's auc: 0.927514\n",
      "[187]\ttraining's auc: 0.933598\tvalid_1's auc: 0.927515\n",
      "[188]\ttraining's auc: 0.933642\tvalid_1's auc: 0.927518\n",
      "[189]\ttraining's auc: 0.933699\tvalid_1's auc: 0.927524\n",
      "[190]\ttraining's auc: 0.933782\tvalid_1's auc: 0.927502\n",
      "[191]\ttraining's auc: 0.933832\tvalid_1's auc: 0.927499\n",
      "[192]\ttraining's auc: 0.933881\tvalid_1's auc: 0.927489\n",
      "[193]\ttraining's auc: 0.933946\tvalid_1's auc: 0.927489\n",
      "[194]\ttraining's auc: 0.933968\tvalid_1's auc: 0.927484\n",
      "[195]\ttraining's auc: 0.933992\tvalid_1's auc: 0.927485\n",
      "[196]\ttraining's auc: 0.934086\tvalid_1's auc: 0.927471\n",
      "[197]\ttraining's auc: 0.934119\tvalid_1's auc: 0.927478\n",
      "[198]\ttraining's auc: 0.934224\tvalid_1's auc: 0.927452\n",
      "[199]\ttraining's auc: 0.934258\tvalid_1's auc: 0.927454\n",
      "[200]\ttraining's auc: 0.93432\tvalid_1's auc: 0.927446\n",
      "[201]\ttraining's auc: 0.934368\tvalid_1's auc: 0.927458\n",
      "[202]\ttraining's auc: 0.934507\tvalid_1's auc: 0.927443\n",
      "[203]\ttraining's auc: 0.934529\tvalid_1's auc: 0.927434\n",
      "[204]\ttraining's auc: 0.934549\tvalid_1's auc: 0.92744\n",
      "[205]\ttraining's auc: 0.934639\tvalid_1's auc: 0.927425\n",
      "[206]\ttraining's auc: 0.934659\tvalid_1's auc: 0.927425\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[207]\ttraining's auc: 0.93468\tvalid_1's auc: 0.92742\n",
      "[208]\ttraining's auc: 0.934783\tvalid_1's auc: 0.927424\n",
      "[209]\ttraining's auc: 0.93488\tvalid_1's auc: 0.927429\n",
      "[210]\ttraining's auc: 0.934905\tvalid_1's auc: 0.927433\n",
      "[211]\ttraining's auc: 0.934923\tvalid_1's auc: 0.927429\n",
      "[212]\ttraining's auc: 0.935006\tvalid_1's auc: 0.927444\n",
      "[213]\ttraining's auc: 0.935075\tvalid_1's auc: 0.92744\n",
      "[214]\ttraining's auc: 0.935093\tvalid_1's auc: 0.92743\n",
      "[215]\ttraining's auc: 0.9351\tvalid_1's auc: 0.927433\n",
      "[216]\ttraining's auc: 0.935205\tvalid_1's auc: 0.927432\n",
      "[217]\ttraining's auc: 0.935246\tvalid_1's auc: 0.927427\n",
      "[218]\ttraining's auc: 0.935263\tvalid_1's auc: 0.92743\n",
      "[219]\ttraining's auc: 0.935329\tvalid_1's auc: 0.927417\n",
      "[220]\ttraining's auc: 0.935434\tvalid_1's auc: 0.927421\n",
      "[221]\ttraining's auc: 0.935453\tvalid_1's auc: 0.927412\n",
      "[222]\ttraining's auc: 0.935512\tvalid_1's auc: 0.927408\n",
      "[223]\ttraining's auc: 0.935563\tvalid_1's auc: 0.927411\n",
      "[224]\ttraining's auc: 0.935583\tvalid_1's auc: 0.927411\n",
      "[225]\ttraining's auc: 0.935596\tvalid_1's auc: 0.927405\n",
      "[226]\ttraining's auc: 0.935607\tvalid_1's auc: 0.927407\n",
      "[227]\ttraining's auc: 0.935663\tvalid_1's auc: 0.927405\n",
      "[228]\ttraining's auc: 0.935699\tvalid_1's auc: 0.927401\n",
      "[229]\ttraining's auc: 0.93577\tvalid_1's auc: 0.927403\n",
      "[230]\ttraining's auc: 0.935832\tvalid_1's auc: 0.927404\n",
      "[231]\ttraining's auc: 0.935845\tvalid_1's auc: 0.927395\n",
      "[232]\ttraining's auc: 0.935866\tvalid_1's auc: 0.927394\n",
      "[233]\ttraining's auc: 0.935926\tvalid_1's auc: 0.927399\n",
      "[234]\ttraining's auc: 0.93595\tvalid_1's auc: 0.927403\n",
      "[235]\ttraining's auc: 0.935998\tvalid_1's auc: 0.927388\n",
      "[236]\ttraining's auc: 0.936047\tvalid_1's auc: 0.927391\n",
      "[237]\ttraining's auc: 0.936111\tvalid_1's auc: 0.927372\n",
      "[238]\ttraining's auc: 0.936144\tvalid_1's auc: 0.927369\n",
      "[239]\ttraining's auc: 0.936159\tvalid_1's auc: 0.927371\n",
      "[240]\ttraining's auc: 0.93621\tvalid_1's auc: 0.927366\n",
      "[241]\ttraining's auc: 0.936216\tvalid_1's auc: 0.927365\n",
      "[242]\ttraining's auc: 0.936231\tvalid_1's auc: 0.927363\n",
      "[243]\ttraining's auc: 0.936284\tvalid_1's auc: 0.927348\n",
      "[244]\ttraining's auc: 0.936323\tvalid_1's auc: 0.927338\n",
      "[245]\ttraining's auc: 0.936359\tvalid_1's auc: 0.927328\n",
      "[246]\ttraining's auc: 0.936442\tvalid_1's auc: 0.927327\n",
      "[247]\ttraining's auc: 0.936453\tvalid_1's auc: 0.927318\n",
      "[248]\ttraining's auc: 0.936485\tvalid_1's auc: 0.927322\n",
      "[249]\ttraining's auc: 0.936528\tvalid_1's auc: 0.927327\n",
      "[250]\ttraining's auc: 0.936606\tvalid_1's auc: 0.927332\n",
      "[251]\ttraining's auc: 0.936627\tvalid_1's auc: 0.927338\n",
      "[252]\ttraining's auc: 0.936661\tvalid_1's auc: 0.92733\n",
      "[253]\ttraining's auc: 0.936738\tvalid_1's auc: 0.927326\n",
      "[254]\ttraining's auc: 0.93684\tvalid_1's auc: 0.927327\n",
      "[255]\ttraining's auc: 0.936888\tvalid_1's auc: 0.927326\n",
      "[256]\ttraining's auc: 0.93695\tvalid_1's auc: 0.927318\n",
      "[257]\ttraining's auc: 0.936989\tvalid_1's auc: 0.927312\n",
      "[258]\ttraining's auc: 0.937008\tvalid_1's auc: 0.927311\n",
      "[259]\ttraining's auc: 0.937027\tvalid_1's auc: 0.927305\n",
      "[260]\ttraining's auc: 0.937098\tvalid_1's auc: 0.927297\n",
      "[261]\ttraining's auc: 0.937106\tvalid_1's auc: 0.927298\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=798, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=798\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.15602359629209078, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.15602359629209078\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.24397531382432613, subsample=1.0 will be ignored. Current value: bagging_fraction=0.24397531382432613\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.05176012844110056, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.05176012844110056\n",
      "[1]\ttraining's auc: 0.922567\tvalid_1's auc: 0.919602\n",
      "[2]\ttraining's auc: 0.923209\tvalid_1's auc: 0.920756\n",
      "[3]\ttraining's auc: 0.923322\tvalid_1's auc: 0.920988\n",
      "[4]\ttraining's auc: 0.923659\tvalid_1's auc: 0.921362\n",
      "[5]\ttraining's auc: 0.923738\tvalid_1's auc: 0.921323\n",
      "[6]\ttraining's auc: 0.923969\tvalid_1's auc: 0.92158\n",
      "[7]\ttraining's auc: 0.924091\tvalid_1's auc: 0.921676\n",
      "[8]\ttraining's auc: 0.924477\tvalid_1's auc: 0.921984\n",
      "[9]\ttraining's auc: 0.924533\tvalid_1's auc: 0.922032\n",
      "[10]\ttraining's auc: 0.924644\tvalid_1's auc: 0.922087\n",
      "[11]\ttraining's auc: 0.924947\tvalid_1's auc: 0.922494\n",
      "[12]\ttraining's auc: 0.925051\tvalid_1's auc: 0.922626\n",
      "[13]\ttraining's auc: 0.92521\tvalid_1's auc: 0.922743\n",
      "[14]\ttraining's auc: 0.925286\tvalid_1's auc: 0.92276\n",
      "[15]\ttraining's auc: 0.925421\tvalid_1's auc: 0.922899\n",
      "[16]\ttraining's auc: 0.925505\tvalid_1's auc: 0.922967\n",
      "[17]\ttraining's auc: 0.925593\tvalid_1's auc: 0.923083\n",
      "[18]\ttraining's auc: 0.925607\tvalid_1's auc: 0.923103\n",
      "[19]\ttraining's auc: 0.925736\tvalid_1's auc: 0.923207\n",
      "[20]\ttraining's auc: 0.926009\tvalid_1's auc: 0.923455\n",
      "[21]\ttraining's auc: 0.926218\tvalid_1's auc: 0.923631\n",
      "[22]\ttraining's auc: 0.926342\tvalid_1's auc: 0.923704\n",
      "[23]\ttraining's auc: 0.92642\tvalid_1's auc: 0.923766\n",
      "[24]\ttraining's auc: 0.926549\tvalid_1's auc: 0.923922\n",
      "[25]\ttraining's auc: 0.926563\tvalid_1's auc: 0.923986\n",
      "[26]\ttraining's auc: 0.926599\tvalid_1's auc: 0.924047\n",
      "[27]\ttraining's auc: 0.926704\tvalid_1's auc: 0.924134\n",
      "[28]\ttraining's auc: 0.926793\tvalid_1's auc: 0.924212\n",
      "[29]\ttraining's auc: 0.926866\tvalid_1's auc: 0.92428\n",
      "[30]\ttraining's auc: 0.926966\tvalid_1's auc: 0.924375\n",
      "[31]\ttraining's auc: 0.926993\tvalid_1's auc: 0.924388\n",
      "[32]\ttraining's auc: 0.92704\tvalid_1's auc: 0.924476\n",
      "[33]\ttraining's auc: 0.927121\tvalid_1's auc: 0.924562\n",
      "[34]\ttraining's auc: 0.92719\tvalid_1's auc: 0.924622\n",
      "[35]\ttraining's auc: 0.927234\tvalid_1's auc: 0.924633\n",
      "[36]\ttraining's auc: 0.927293\tvalid_1's auc: 0.924654\n",
      "[37]\ttraining's auc: 0.927335\tvalid_1's auc: 0.924671\n",
      "[38]\ttraining's auc: 0.927381\tvalid_1's auc: 0.924676\n",
      "[39]\ttraining's auc: 0.927384\tvalid_1's auc: 0.924658\n",
      "[40]\ttraining's auc: 0.927428\tvalid_1's auc: 0.924613\n",
      "[41]\ttraining's auc: 0.927455\tvalid_1's auc: 0.92465\n",
      "[42]\ttraining's auc: 0.927487\tvalid_1's auc: 0.92467\n",
      "[43]\ttraining's auc: 0.927507\tvalid_1's auc: 0.924685\n",
      "[44]\ttraining's auc: 0.927554\tvalid_1's auc: 0.92468\n",
      "[45]\ttraining's auc: 0.927562\tvalid_1's auc: 0.924665\n",
      "[46]\ttraining's auc: 0.927595\tvalid_1's auc: 0.924695\n",
      "[47]\ttraining's auc: 0.927661\tvalid_1's auc: 0.92475\n",
      "[48]\ttraining's auc: 0.927804\tvalid_1's auc: 0.924881\n",
      "[49]\ttraining's auc: 0.92786\tvalid_1's auc: 0.925078\n",
      "[50]\ttraining's auc: 0.927976\tvalid_1's auc: 0.925141\n",
      "[51]\ttraining's auc: 0.928008\tvalid_1's auc: 0.925174\n",
      "[52]\ttraining's auc: 0.928074\tvalid_1's auc: 0.925221\n",
      "[53]\ttraining's auc: 0.928149\tvalid_1's auc: 0.925264\n",
      "[54]\ttraining's auc: 0.928187\tvalid_1's auc: 0.925293\n",
      "[55]\ttraining's auc: 0.928281\tvalid_1's auc: 0.925406\n",
      "[56]\ttraining's auc: 0.928327\tvalid_1's auc: 0.925439\n",
      "[57]\ttraining's auc: 0.928382\tvalid_1's auc: 0.925555\n",
      "[58]\ttraining's auc: 0.928415\tvalid_1's auc: 0.925582\n",
      "[59]\ttraining's auc: 0.928465\tvalid_1's auc: 0.925591\n",
      "[60]\ttraining's auc: 0.928492\tvalid_1's auc: 0.925612\n",
      "[61]\ttraining's auc: 0.928541\tvalid_1's auc: 0.925645\n",
      "[62]\ttraining's auc: 0.928572\tvalid_1's auc: 0.925677\n",
      "[63]\ttraining's auc: 0.928622\tvalid_1's auc: 0.925721\n",
      "[64]\ttraining's auc: 0.928666\tvalid_1's auc: 0.925748\n",
      "[65]\ttraining's auc: 0.928698\tvalid_1's auc: 0.925773\n",
      "[66]\ttraining's auc: 0.928737\tvalid_1's auc: 0.925812\n",
      "[67]\ttraining's auc: 0.928811\tvalid_1's auc: 0.925852\n",
      "[68]\ttraining's auc: 0.928867\tvalid_1's auc: 0.925893\n",
      "[69]\ttraining's auc: 0.928938\tvalid_1's auc: 0.925916\n",
      "[70]\ttraining's auc: 0.92898\tvalid_1's auc: 0.925926\n",
      "[71]\ttraining's auc: 0.929045\tvalid_1's auc: 0.925954\n",
      "[72]\ttraining's auc: 0.929123\tvalid_1's auc: 0.925991\n",
      "[73]\ttraining's auc: 0.929171\tvalid_1's auc: 0.926028\n",
      "[74]\ttraining's auc: 0.929248\tvalid_1's auc: 0.926046\n",
      "[75]\ttraining's auc: 0.929321\tvalid_1's auc: 0.926082\n",
      "[76]\ttraining's auc: 0.929337\tvalid_1's auc: 0.926093\n",
      "[77]\ttraining's auc: 0.929354\tvalid_1's auc: 0.926114\n",
      "[78]\ttraining's auc: 0.929375\tvalid_1's auc: 0.926122\n",
      "[79]\ttraining's auc: 0.929465\tvalid_1's auc: 0.92618\n",
      "[80]\ttraining's auc: 0.929548\tvalid_1's auc: 0.926222\n",
      "[81]\ttraining's auc: 0.929615\tvalid_1's auc: 0.926247\n",
      "[82]\ttraining's auc: 0.929735\tvalid_1's auc: 0.926337\n",
      "[83]\ttraining's auc: 0.929792\tvalid_1's auc: 0.926362\n",
      "[84]\ttraining's auc: 0.929811\tvalid_1's auc: 0.92636\n",
      "[85]\ttraining's auc: 0.929843\tvalid_1's auc: 0.926372\n",
      "[86]\ttraining's auc: 0.929869\tvalid_1's auc: 0.926375\n",
      "[87]\ttraining's auc: 0.929903\tvalid_1's auc: 0.926387\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[88]\ttraining's auc: 0.929967\tvalid_1's auc: 0.9264\n",
      "[89]\ttraining's auc: 0.930007\tvalid_1's auc: 0.926416\n",
      "[90]\ttraining's auc: 0.930046\tvalid_1's auc: 0.926431\n",
      "[91]\ttraining's auc: 0.930086\tvalid_1's auc: 0.926432\n",
      "[92]\ttraining's auc: 0.930157\tvalid_1's auc: 0.926472\n",
      "[93]\ttraining's auc: 0.930218\tvalid_1's auc: 0.926482\n",
      "[94]\ttraining's auc: 0.930258\tvalid_1's auc: 0.926504\n",
      "[95]\ttraining's auc: 0.930308\tvalid_1's auc: 0.926524\n",
      "[96]\ttraining's auc: 0.930338\tvalid_1's auc: 0.926542\n",
      "[97]\ttraining's auc: 0.930401\tvalid_1's auc: 0.926568\n",
      "[98]\ttraining's auc: 0.930505\tvalid_1's auc: 0.926625\n",
      "[99]\ttraining's auc: 0.930538\tvalid_1's auc: 0.926655\n",
      "[100]\ttraining's auc: 0.930614\tvalid_1's auc: 0.926691\n",
      "[101]\ttraining's auc: 0.930669\tvalid_1's auc: 0.926711\n",
      "[102]\ttraining's auc: 0.930731\tvalid_1's auc: 0.92676\n",
      "[103]\ttraining's auc: 0.930785\tvalid_1's auc: 0.926763\n",
      "[104]\ttraining's auc: 0.930796\tvalid_1's auc: 0.926765\n",
      "[105]\ttraining's auc: 0.930808\tvalid_1's auc: 0.926767\n",
      "[106]\ttraining's auc: 0.930856\tvalid_1's auc: 0.926788\n",
      "[107]\ttraining's auc: 0.930885\tvalid_1's auc: 0.926801\n",
      "[108]\ttraining's auc: 0.930905\tvalid_1's auc: 0.926799\n",
      "[109]\ttraining's auc: 0.930924\tvalid_1's auc: 0.926794\n",
      "[110]\ttraining's auc: 0.930948\tvalid_1's auc: 0.926802\n",
      "[111]\ttraining's auc: 0.930992\tvalid_1's auc: 0.926822\n",
      "[112]\ttraining's auc: 0.931023\tvalid_1's auc: 0.926832\n",
      "[113]\ttraining's auc: 0.931073\tvalid_1's auc: 0.926842\n",
      "[114]\ttraining's auc: 0.931098\tvalid_1's auc: 0.926848\n",
      "[115]\ttraining's auc: 0.931131\tvalid_1's auc: 0.926859\n",
      "[116]\ttraining's auc: 0.931163\tvalid_1's auc: 0.926869\n",
      "[117]\ttraining's auc: 0.931206\tvalid_1's auc: 0.926883\n",
      "[118]\ttraining's auc: 0.931238\tvalid_1's auc: 0.926892\n",
      "[119]\ttraining's auc: 0.931296\tvalid_1's auc: 0.926894\n",
      "[120]\ttraining's auc: 0.931349\tvalid_1's auc: 0.926905\n",
      "[121]\ttraining's auc: 0.931394\tvalid_1's auc: 0.926927\n",
      "[122]\ttraining's auc: 0.93144\tvalid_1's auc: 0.926927\n",
      "[123]\ttraining's auc: 0.931519\tvalid_1's auc: 0.926958\n",
      "[124]\ttraining's auc: 0.93158\tvalid_1's auc: 0.92699\n",
      "[125]\ttraining's auc: 0.931638\tvalid_1's auc: 0.927013\n",
      "[126]\ttraining's auc: 0.931703\tvalid_1's auc: 0.927029\n",
      "[127]\ttraining's auc: 0.931764\tvalid_1's auc: 0.927068\n",
      "[128]\ttraining's auc: 0.931827\tvalid_1's auc: 0.927076\n",
      "[129]\ttraining's auc: 0.931851\tvalid_1's auc: 0.927082\n",
      "[130]\ttraining's auc: 0.931876\tvalid_1's auc: 0.927088\n",
      "[131]\ttraining's auc: 0.931893\tvalid_1's auc: 0.927095\n",
      "[132]\ttraining's auc: 0.931909\tvalid_1's auc: 0.927099\n",
      "[133]\ttraining's auc: 0.931929\tvalid_1's auc: 0.927099\n",
      "[134]\ttraining's auc: 0.931945\tvalid_1's auc: 0.927099\n",
      "[135]\ttraining's auc: 0.931972\tvalid_1's auc: 0.927107\n",
      "[136]\ttraining's auc: 0.93199\tvalid_1's auc: 0.927124\n",
      "[137]\ttraining's auc: 0.932021\tvalid_1's auc: 0.927126\n",
      "[138]\ttraining's auc: 0.932047\tvalid_1's auc: 0.927139\n",
      "[139]\ttraining's auc: 0.932082\tvalid_1's auc: 0.927157\n",
      "[140]\ttraining's auc: 0.93209\tvalid_1's auc: 0.927159\n",
      "[141]\ttraining's auc: 0.932104\tvalid_1's auc: 0.927159\n",
      "[142]\ttraining's auc: 0.932148\tvalid_1's auc: 0.92717\n",
      "[143]\ttraining's auc: 0.932169\tvalid_1's auc: 0.927177\n",
      "[144]\ttraining's auc: 0.932205\tvalid_1's auc: 0.927175\n",
      "[145]\ttraining's auc: 0.932229\tvalid_1's auc: 0.927197\n",
      "[146]\ttraining's auc: 0.932269\tvalid_1's auc: 0.927204\n",
      "[147]\ttraining's auc: 0.932288\tvalid_1's auc: 0.927204\n",
      "[148]\ttraining's auc: 0.93232\tvalid_1's auc: 0.9272\n",
      "[149]\ttraining's auc: 0.932344\tvalid_1's auc: 0.927209\n",
      "[150]\ttraining's auc: 0.932386\tvalid_1's auc: 0.927219\n",
      "[151]\ttraining's auc: 0.932408\tvalid_1's auc: 0.927228\n",
      "[152]\ttraining's auc: 0.932456\tvalid_1's auc: 0.927224\n",
      "[153]\ttraining's auc: 0.932496\tvalid_1's auc: 0.927245\n",
      "[154]\ttraining's auc: 0.932541\tvalid_1's auc: 0.927252\n",
      "[155]\ttraining's auc: 0.932595\tvalid_1's auc: 0.927269\n",
      "[156]\ttraining's auc: 0.932623\tvalid_1's auc: 0.927272\n",
      "[157]\ttraining's auc: 0.932663\tvalid_1's auc: 0.927278\n",
      "[158]\ttraining's auc: 0.932707\tvalid_1's auc: 0.927293\n",
      "[159]\ttraining's auc: 0.932762\tvalid_1's auc: 0.92732\n",
      "[160]\ttraining's auc: 0.932792\tvalid_1's auc: 0.92732\n",
      "[161]\ttraining's auc: 0.932833\tvalid_1's auc: 0.927325\n",
      "[162]\ttraining's auc: 0.932862\tvalid_1's auc: 0.927334\n",
      "[163]\ttraining's auc: 0.932881\tvalid_1's auc: 0.927339\n",
      "[164]\ttraining's auc: 0.932906\tvalid_1's auc: 0.927335\n",
      "[165]\ttraining's auc: 0.93295\tvalid_1's auc: 0.927343\n",
      "[166]\ttraining's auc: 0.932974\tvalid_1's auc: 0.92734\n",
      "[167]\ttraining's auc: 0.933026\tvalid_1's auc: 0.927337\n",
      "[168]\ttraining's auc: 0.93308\tvalid_1's auc: 0.927341\n",
      "[169]\ttraining's auc: 0.933122\tvalid_1's auc: 0.927322\n",
      "[170]\ttraining's auc: 0.933167\tvalid_1's auc: 0.927329\n",
      "[171]\ttraining's auc: 0.933209\tvalid_1's auc: 0.927337\n",
      "[172]\ttraining's auc: 0.933254\tvalid_1's auc: 0.927348\n",
      "[173]\ttraining's auc: 0.933274\tvalid_1's auc: 0.927339\n",
      "[174]\ttraining's auc: 0.933334\tvalid_1's auc: 0.927348\n",
      "[175]\ttraining's auc: 0.933396\tvalid_1's auc: 0.927348\n",
      "[176]\ttraining's auc: 0.93348\tvalid_1's auc: 0.927397\n",
      "[177]\ttraining's auc: 0.933559\tvalid_1's auc: 0.927399\n",
      "[178]\ttraining's auc: 0.933618\tvalid_1's auc: 0.927421\n",
      "[179]\ttraining's auc: 0.933652\tvalid_1's auc: 0.927428\n",
      "[180]\ttraining's auc: 0.933701\tvalid_1's auc: 0.927432\n",
      "[181]\ttraining's auc: 0.933734\tvalid_1's auc: 0.92743\n",
      "[182]\ttraining's auc: 0.933794\tvalid_1's auc: 0.927439\n",
      "[183]\ttraining's auc: 0.933814\tvalid_1's auc: 0.927438\n",
      "[184]\ttraining's auc: 0.933859\tvalid_1's auc: 0.927446\n",
      "[185]\ttraining's auc: 0.93389\tvalid_1's auc: 0.927446\n",
      "[186]\ttraining's auc: 0.933931\tvalid_1's auc: 0.927439\n",
      "[187]\ttraining's auc: 0.933955\tvalid_1's auc: 0.927438\n",
      "[188]\ttraining's auc: 0.93401\tvalid_1's auc: 0.927436\n",
      "[189]\ttraining's auc: 0.934068\tvalid_1's auc: 0.927442\n",
      "[190]\ttraining's auc: 0.934112\tvalid_1's auc: 0.927453\n",
      "[191]\ttraining's auc: 0.934146\tvalid_1's auc: 0.927454\n",
      "[192]\ttraining's auc: 0.934233\tvalid_1's auc: 0.927454\n",
      "[193]\ttraining's auc: 0.934258\tvalid_1's auc: 0.927447\n",
      "[194]\ttraining's auc: 0.934286\tvalid_1's auc: 0.927451\n",
      "[195]\ttraining's auc: 0.934338\tvalid_1's auc: 0.927453\n",
      "[196]\ttraining's auc: 0.934416\tvalid_1's auc: 0.927459\n",
      "[197]\ttraining's auc: 0.934451\tvalid_1's auc: 0.927469\n",
      "[198]\ttraining's auc: 0.934502\tvalid_1's auc: 0.927471\n",
      "[199]\ttraining's auc: 0.93454\tvalid_1's auc: 0.927485\n",
      "[200]\ttraining's auc: 0.93466\tvalid_1's auc: 0.927499\n",
      "[201]\ttraining's auc: 0.934706\tvalid_1's auc: 0.927486\n",
      "[202]\ttraining's auc: 0.934724\tvalid_1's auc: 0.927476\n",
      "[203]\ttraining's auc: 0.934786\tvalid_1's auc: 0.927477\n",
      "[204]\ttraining's auc: 0.934806\tvalid_1's auc: 0.927479\n",
      "[205]\ttraining's auc: 0.934866\tvalid_1's auc: 0.927489\n",
      "[206]\ttraining's auc: 0.934906\tvalid_1's auc: 0.927485\n",
      "[207]\ttraining's auc: 0.934932\tvalid_1's auc: 0.927487\n",
      "[208]\ttraining's auc: 0.934941\tvalid_1's auc: 0.927486\n",
      "[209]\ttraining's auc: 0.935006\tvalid_1's auc: 0.927482\n",
      "[210]\ttraining's auc: 0.935086\tvalid_1's auc: 0.927484\n",
      "[211]\ttraining's auc: 0.935173\tvalid_1's auc: 0.927483\n",
      "[212]\ttraining's auc: 0.935222\tvalid_1's auc: 0.927488\n",
      "[213]\ttraining's auc: 0.935241\tvalid_1's auc: 0.927491\n",
      "[214]\ttraining's auc: 0.93526\tvalid_1's auc: 0.927491\n",
      "[215]\ttraining's auc: 0.935283\tvalid_1's auc: 0.927491\n",
      "[216]\ttraining's auc: 0.935393\tvalid_1's auc: 0.927479\n",
      "[217]\ttraining's auc: 0.935446\tvalid_1's auc: 0.92748\n",
      "[218]\ttraining's auc: 0.935481\tvalid_1's auc: 0.927474\n",
      "[219]\ttraining's auc: 0.935587\tvalid_1's auc: 0.927455\n",
      "[220]\ttraining's auc: 0.935629\tvalid_1's auc: 0.927462\n",
      "[221]\ttraining's auc: 0.9357\tvalid_1's auc: 0.927457\n",
      "[222]\ttraining's auc: 0.935753\tvalid_1's auc: 0.927463\n",
      "[223]\ttraining's auc: 0.935876\tvalid_1's auc: 0.927438\n",
      "[224]\ttraining's auc: 0.935904\tvalid_1's auc: 0.927443\n",
      "[225]\ttraining's auc: 0.93593\tvalid_1's auc: 0.92745\n",
      "[226]\ttraining's auc: 0.935977\tvalid_1's auc: 0.927451\n",
      "[227]\ttraining's auc: 0.936018\tvalid_1's auc: 0.92745\n",
      "[228]\ttraining's auc: 0.936174\tvalid_1's auc: 0.92744\n",
      "[229]\ttraining's auc: 0.936179\tvalid_1's auc: 0.927437\n",
      "[230]\ttraining's auc: 0.936222\tvalid_1's auc: 0.927438\n",
      "[231]\ttraining's auc: 0.936256\tvalid_1's auc: 0.927431\n",
      "[232]\ttraining's auc: 0.936298\tvalid_1's auc: 0.927428\n",
      "[233]\ttraining's auc: 0.936325\tvalid_1's auc: 0.927424\n",
      "[234]\ttraining's auc: 0.936349\tvalid_1's auc: 0.927421\n",
      "[235]\ttraining's auc: 0.936375\tvalid_1's auc: 0.927428\n",
      "[236]\ttraining's auc: 0.936425\tvalid_1's auc: 0.927424\n",
      "[237]\ttraining's auc: 0.936516\tvalid_1's auc: 0.927408\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[238]\ttraining's auc: 0.9366\tvalid_1's auc: 0.927404\n",
      "[239]\ttraining's auc: 0.936623\tvalid_1's auc: 0.927404\n",
      "[240]\ttraining's auc: 0.936664\tvalid_1's auc: 0.927404\n",
      "[241]\ttraining's auc: 0.936718\tvalid_1's auc: 0.927404\n",
      "[242]\ttraining's auc: 0.936744\tvalid_1's auc: 0.927396\n",
      "[243]\ttraining's auc: 0.936826\tvalid_1's auc: 0.927407\n",
      "[244]\ttraining's auc: 0.936847\tvalid_1's auc: 0.927399\n",
      "[245]\ttraining's auc: 0.936947\tvalid_1's auc: 0.927381\n",
      "[246]\ttraining's auc: 0.936974\tvalid_1's auc: 0.927369\n",
      "[247]\ttraining's auc: 0.937001\tvalid_1's auc: 0.927364\n",
      "[248]\ttraining's auc: 0.937013\tvalid_1's auc: 0.92736\n",
      "[249]\ttraining's auc: 0.937036\tvalid_1's auc: 0.927352\n",
      "[250]\ttraining's auc: 0.937054\tvalid_1's auc: 0.927352\n",
      "[251]\ttraining's auc: 0.937094\tvalid_1's auc: 0.927342\n",
      "[252]\ttraining's auc: 0.937155\tvalid_1's auc: 0.927356\n",
      "[253]\ttraining's auc: 0.937199\tvalid_1's auc: 0.927342\n",
      "[254]\ttraining's auc: 0.937223\tvalid_1's auc: 0.927343\n",
      "[255]\ttraining's auc: 0.937259\tvalid_1's auc: 0.92734\n",
      "[256]\ttraining's auc: 0.937282\tvalid_1's auc: 0.92733\n",
      "[257]\ttraining's auc: 0.93732\tvalid_1's auc: 0.927325\n",
      "[258]\ttraining's auc: 0.93734\tvalid_1's auc: 0.927325\n",
      "[259]\ttraining's auc: 0.937428\tvalid_1's auc: 0.92732\n",
      "[260]\ttraining's auc: 0.937478\tvalid_1's auc: 0.927308\n",
      "[261]\ttraining's auc: 0.937489\tvalid_1's auc: 0.927308\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=798, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=798\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.15602359629209078, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.15602359629209078\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.24397531382432613, subsample=1.0 will be ignored. Current value: bagging_fraction=0.24397531382432613\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.05176012844110056, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.05176012844110056\n",
      "[1]\ttraining's auc: 0.922373\tvalid_1's auc: 0.92222\n",
      "[2]\ttraining's auc: 0.922595\tvalid_1's auc: 0.922607\n",
      "[3]\ttraining's auc: 0.923145\tvalid_1's auc: 0.923356\n",
      "[4]\ttraining's auc: 0.923344\tvalid_1's auc: 0.923558\n",
      "[5]\ttraining's auc: 0.923661\tvalid_1's auc: 0.923784\n",
      "[6]\ttraining's auc: 0.924153\tvalid_1's auc: 0.924303\n",
      "[7]\ttraining's auc: 0.92428\tvalid_1's auc: 0.924503\n",
      "[8]\ttraining's auc: 0.924659\tvalid_1's auc: 0.924842\n",
      "[9]\ttraining's auc: 0.924751\tvalid_1's auc: 0.924922\n",
      "[10]\ttraining's auc: 0.924865\tvalid_1's auc: 0.925042\n",
      "[11]\ttraining's auc: 0.924874\tvalid_1's auc: 0.925088\n",
      "[12]\ttraining's auc: 0.925021\tvalid_1's auc: 0.925325\n",
      "[13]\ttraining's auc: 0.925082\tvalid_1's auc: 0.925416\n",
      "[14]\ttraining's auc: 0.925122\tvalid_1's auc: 0.925513\n",
      "[15]\ttraining's auc: 0.925218\tvalid_1's auc: 0.925556\n",
      "[16]\ttraining's auc: 0.92529\tvalid_1's auc: 0.925605\n",
      "[17]\ttraining's auc: 0.92538\tvalid_1's auc: 0.925681\n",
      "[18]\ttraining's auc: 0.925463\tvalid_1's auc: 0.925802\n",
      "[19]\ttraining's auc: 0.925506\tvalid_1's auc: 0.925841\n",
      "[20]\ttraining's auc: 0.925644\tvalid_1's auc: 0.925974\n",
      "[21]\ttraining's auc: 0.925685\tvalid_1's auc: 0.926008\n",
      "[22]\ttraining's auc: 0.925864\tvalid_1's auc: 0.926153\n",
      "[23]\ttraining's auc: 0.925863\tvalid_1's auc: 0.926135\n",
      "[24]\ttraining's auc: 0.92601\tvalid_1's auc: 0.926313\n",
      "[25]\ttraining's auc: 0.926117\tvalid_1's auc: 0.926435\n",
      "[26]\ttraining's auc: 0.926217\tvalid_1's auc: 0.926468\n",
      "[27]\ttraining's auc: 0.926299\tvalid_1's auc: 0.926542\n",
      "[28]\ttraining's auc: 0.926345\tvalid_1's auc: 0.926623\n",
      "[29]\ttraining's auc: 0.926409\tvalid_1's auc: 0.926688\n",
      "[30]\ttraining's auc: 0.926486\tvalid_1's auc: 0.926738\n",
      "[31]\ttraining's auc: 0.926517\tvalid_1's auc: 0.926794\n",
      "[32]\ttraining's auc: 0.926568\tvalid_1's auc: 0.926855\n",
      "[33]\ttraining's auc: 0.926621\tvalid_1's auc: 0.926892\n",
      "[34]\ttraining's auc: 0.92665\tvalid_1's auc: 0.926914\n",
      "[35]\ttraining's auc: 0.926692\tvalid_1's auc: 0.926955\n",
      "[36]\ttraining's auc: 0.926723\tvalid_1's auc: 0.92698\n",
      "[37]\ttraining's auc: 0.92682\tvalid_1's auc: 0.927088\n",
      "[38]\ttraining's auc: 0.926875\tvalid_1's auc: 0.927133\n",
      "[39]\ttraining's auc: 0.926961\tvalid_1's auc: 0.927183\n",
      "[40]\ttraining's auc: 0.927014\tvalid_1's auc: 0.927219\n",
      "[41]\ttraining's auc: 0.927075\tvalid_1's auc: 0.927318\n",
      "[42]\ttraining's auc: 0.927123\tvalid_1's auc: 0.927349\n",
      "[43]\ttraining's auc: 0.927156\tvalid_1's auc: 0.927346\n",
      "[44]\ttraining's auc: 0.927219\tvalid_1's auc: 0.927421\n",
      "[45]\ttraining's auc: 0.927245\tvalid_1's auc: 0.927454\n",
      "[46]\ttraining's auc: 0.927259\tvalid_1's auc: 0.927447\n",
      "[47]\ttraining's auc: 0.927304\tvalid_1's auc: 0.927488\n",
      "[48]\ttraining's auc: 0.92736\tvalid_1's auc: 0.927562\n",
      "[49]\ttraining's auc: 0.927508\tvalid_1's auc: 0.927692\n",
      "[50]\ttraining's auc: 0.927535\tvalid_1's auc: 0.927706\n",
      "[51]\ttraining's auc: 0.927577\tvalid_1's auc: 0.927711\n",
      "[52]\ttraining's auc: 0.927662\tvalid_1's auc: 0.927776\n",
      "[53]\ttraining's auc: 0.927689\tvalid_1's auc: 0.927792\n",
      "[54]\ttraining's auc: 0.927803\tvalid_1's auc: 0.927888\n",
      "[55]\ttraining's auc: 0.927893\tvalid_1's auc: 0.92797\n",
      "[56]\ttraining's auc: 0.927959\tvalid_1's auc: 0.928022\n",
      "[57]\ttraining's auc: 0.927998\tvalid_1's auc: 0.928047\n",
      "[58]\ttraining's auc: 0.928068\tvalid_1's auc: 0.928118\n",
      "[59]\ttraining's auc: 0.928141\tvalid_1's auc: 0.928166\n",
      "[60]\ttraining's auc: 0.928188\tvalid_1's auc: 0.928204\n",
      "[61]\ttraining's auc: 0.928219\tvalid_1's auc: 0.928214\n",
      "[62]\ttraining's auc: 0.928236\tvalid_1's auc: 0.928207\n",
      "[63]\ttraining's auc: 0.928298\tvalid_1's auc: 0.928252\n",
      "[64]\ttraining's auc: 0.92832\tvalid_1's auc: 0.928265\n",
      "[65]\ttraining's auc: 0.928374\tvalid_1's auc: 0.928303\n",
      "[66]\ttraining's auc: 0.928395\tvalid_1's auc: 0.928318\n",
      "[67]\ttraining's auc: 0.928447\tvalid_1's auc: 0.92834\n",
      "[68]\ttraining's auc: 0.928463\tvalid_1's auc: 0.928347\n",
      "[69]\ttraining's auc: 0.928495\tvalid_1's auc: 0.928414\n",
      "[70]\ttraining's auc: 0.928566\tvalid_1's auc: 0.928451\n",
      "[71]\ttraining's auc: 0.928673\tvalid_1's auc: 0.92854\n",
      "[72]\ttraining's auc: 0.928687\tvalid_1's auc: 0.928559\n",
      "[73]\ttraining's auc: 0.928698\tvalid_1's auc: 0.928569\n",
      "[74]\ttraining's auc: 0.928743\tvalid_1's auc: 0.928604\n",
      "[75]\ttraining's auc: 0.928835\tvalid_1's auc: 0.928675\n",
      "[76]\ttraining's auc: 0.928879\tvalid_1's auc: 0.92872\n",
      "[77]\ttraining's auc: 0.928932\tvalid_1's auc: 0.92874\n",
      "[78]\ttraining's auc: 0.928969\tvalid_1's auc: 0.928771\n",
      "[79]\ttraining's auc: 0.928987\tvalid_1's auc: 0.928781\n",
      "[80]\ttraining's auc: 0.929036\tvalid_1's auc: 0.928789\n",
      "[81]\ttraining's auc: 0.929093\tvalid_1's auc: 0.928796\n",
      "[82]\ttraining's auc: 0.929223\tvalid_1's auc: 0.928866\n",
      "[83]\ttraining's auc: 0.929273\tvalid_1's auc: 0.928885\n",
      "[84]\ttraining's auc: 0.929313\tvalid_1's auc: 0.928931\n",
      "[85]\ttraining's auc: 0.929338\tvalid_1's auc: 0.928932\n",
      "[86]\ttraining's auc: 0.92937\tvalid_1's auc: 0.928945\n",
      "[87]\ttraining's auc: 0.929414\tvalid_1's auc: 0.928958\n",
      "[88]\ttraining's auc: 0.929473\tvalid_1's auc: 0.928977\n",
      "[89]\ttraining's auc: 0.929518\tvalid_1's auc: 0.929041\n",
      "[90]\ttraining's auc: 0.929572\tvalid_1's auc: 0.929066\n",
      "[91]\ttraining's auc: 0.929599\tvalid_1's auc: 0.929073\n",
      "[92]\ttraining's auc: 0.929674\tvalid_1's auc: 0.929129\n",
      "[93]\ttraining's auc: 0.929715\tvalid_1's auc: 0.929141\n",
      "[94]\ttraining's auc: 0.929761\tvalid_1's auc: 0.92916\n",
      "[95]\ttraining's auc: 0.929821\tvalid_1's auc: 0.929227\n",
      "[96]\ttraining's auc: 0.929852\tvalid_1's auc: 0.929225\n",
      "[97]\ttraining's auc: 0.929952\tvalid_1's auc: 0.929279\n",
      "[98]\ttraining's auc: 0.929966\tvalid_1's auc: 0.929278\n",
      "[99]\ttraining's auc: 0.930014\tvalid_1's auc: 0.929299\n",
      "[100]\ttraining's auc: 0.930081\tvalid_1's auc: 0.929336\n",
      "[101]\ttraining's auc: 0.930097\tvalid_1's auc: 0.929343\n",
      "[102]\ttraining's auc: 0.930147\tvalid_1's auc: 0.929366\n",
      "[103]\ttraining's auc: 0.930167\tvalid_1's auc: 0.929391\n",
      "[104]\ttraining's auc: 0.930198\tvalid_1's auc: 0.929403\n",
      "[105]\ttraining's auc: 0.930258\tvalid_1's auc: 0.929444\n",
      "[106]\ttraining's auc: 0.930282\tvalid_1's auc: 0.929464\n",
      "[107]\ttraining's auc: 0.930334\tvalid_1's auc: 0.929497\n",
      "[108]\ttraining's auc: 0.930367\tvalid_1's auc: 0.929514\n",
      "[109]\ttraining's auc: 0.93039\tvalid_1's auc: 0.929521\n",
      "[110]\ttraining's auc: 0.930425\tvalid_1's auc: 0.929534\n",
      "[111]\ttraining's auc: 0.930441\tvalid_1's auc: 0.929532\n",
      "[112]\ttraining's auc: 0.930485\tvalid_1's auc: 0.929544\n",
      "[113]\ttraining's auc: 0.930506\tvalid_1's auc: 0.929554\n",
      "[114]\ttraining's auc: 0.930542\tvalid_1's auc: 0.929574\n",
      "[115]\ttraining's auc: 0.930588\tvalid_1's auc: 0.9296\n",
      "[116]\ttraining's auc: 0.930599\tvalid_1's auc: 0.9296\n",
      "[117]\ttraining's auc: 0.930633\tvalid_1's auc: 0.929613\n",
      "[118]\ttraining's auc: 0.930644\tvalid_1's auc: 0.92962\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[119]\ttraining's auc: 0.930676\tvalid_1's auc: 0.929628\n",
      "[120]\ttraining's auc: 0.930706\tvalid_1's auc: 0.929633\n",
      "[121]\ttraining's auc: 0.93076\tvalid_1's auc: 0.92964\n",
      "[122]\ttraining's auc: 0.930805\tvalid_1's auc: 0.929655\n",
      "[123]\ttraining's auc: 0.930846\tvalid_1's auc: 0.929671\n",
      "[124]\ttraining's auc: 0.930917\tvalid_1's auc: 0.929694\n",
      "[125]\ttraining's auc: 0.930987\tvalid_1's auc: 0.929725\n",
      "[126]\ttraining's auc: 0.931029\tvalid_1's auc: 0.929729\n",
      "[127]\ttraining's auc: 0.931072\tvalid_1's auc: 0.929718\n",
      "[128]\ttraining's auc: 0.931115\tvalid_1's auc: 0.929733\n",
      "[129]\ttraining's auc: 0.931136\tvalid_1's auc: 0.929744\n",
      "[130]\ttraining's auc: 0.931146\tvalid_1's auc: 0.92975\n",
      "[131]\ttraining's auc: 0.931193\tvalid_1's auc: 0.929788\n",
      "[132]\ttraining's auc: 0.931197\tvalid_1's auc: 0.929788\n",
      "[133]\ttraining's auc: 0.931238\tvalid_1's auc: 0.929809\n",
      "[134]\ttraining's auc: 0.931247\tvalid_1's auc: 0.929816\n",
      "[135]\ttraining's auc: 0.931312\tvalid_1's auc: 0.929839\n",
      "[136]\ttraining's auc: 0.931348\tvalid_1's auc: 0.929845\n",
      "[137]\ttraining's auc: 0.931376\tvalid_1's auc: 0.929851\n",
      "[138]\ttraining's auc: 0.931393\tvalid_1's auc: 0.929864\n",
      "[139]\ttraining's auc: 0.931425\tvalid_1's auc: 0.929875\n",
      "[140]\ttraining's auc: 0.931451\tvalid_1's auc: 0.92989\n",
      "[141]\ttraining's auc: 0.931483\tvalid_1's auc: 0.929902\n",
      "[142]\ttraining's auc: 0.931534\tvalid_1's auc: 0.929931\n",
      "[143]\ttraining's auc: 0.931564\tvalid_1's auc: 0.92994\n",
      "[144]\ttraining's auc: 0.931599\tvalid_1's auc: 0.929946\n",
      "[145]\ttraining's auc: 0.931649\tvalid_1's auc: 0.929968\n",
      "[146]\ttraining's auc: 0.93167\tvalid_1's auc: 0.929976\n",
      "[147]\ttraining's auc: 0.931706\tvalid_1's auc: 0.929987\n",
      "[148]\ttraining's auc: 0.931718\tvalid_1's auc: 0.929984\n",
      "[149]\ttraining's auc: 0.931785\tvalid_1's auc: 0.930016\n",
      "[150]\ttraining's auc: 0.931814\tvalid_1's auc: 0.930026\n",
      "[151]\ttraining's auc: 0.931834\tvalid_1's auc: 0.930035\n",
      "[152]\ttraining's auc: 0.931869\tvalid_1's auc: 0.930052\n",
      "[153]\ttraining's auc: 0.931916\tvalid_1's auc: 0.930064\n",
      "[154]\ttraining's auc: 0.931977\tvalid_1's auc: 0.930092\n",
      "[155]\ttraining's auc: 0.932028\tvalid_1's auc: 0.930121\n",
      "[156]\ttraining's auc: 0.93205\tvalid_1's auc: 0.930128\n",
      "[157]\ttraining's auc: 0.932138\tvalid_1's auc: 0.930153\n",
      "[158]\ttraining's auc: 0.932162\tvalid_1's auc: 0.930154\n",
      "[159]\ttraining's auc: 0.932242\tvalid_1's auc: 0.930164\n",
      "[160]\ttraining's auc: 0.932262\tvalid_1's auc: 0.930159\n",
      "[161]\ttraining's auc: 0.932291\tvalid_1's auc: 0.930162\n",
      "[162]\ttraining's auc: 0.932332\tvalid_1's auc: 0.930166\n",
      "[163]\ttraining's auc: 0.932412\tvalid_1's auc: 0.930187\n",
      "[164]\ttraining's auc: 0.932437\tvalid_1's auc: 0.930185\n",
      "[165]\ttraining's auc: 0.932487\tvalid_1's auc: 0.930176\n",
      "[166]\ttraining's auc: 0.932513\tvalid_1's auc: 0.930177\n",
      "[167]\ttraining's auc: 0.932528\tvalid_1's auc: 0.930174\n",
      "[168]\ttraining's auc: 0.932576\tvalid_1's auc: 0.930166\n",
      "[169]\ttraining's auc: 0.932598\tvalid_1's auc: 0.930164\n",
      "[170]\ttraining's auc: 0.932641\tvalid_1's auc: 0.930159\n",
      "[171]\ttraining's auc: 0.93266\tvalid_1's auc: 0.930158\n",
      "[172]\ttraining's auc: 0.932736\tvalid_1's auc: 0.930171\n",
      "[173]\ttraining's auc: 0.932788\tvalid_1's auc: 0.930191\n",
      "[174]\ttraining's auc: 0.932841\tvalid_1's auc: 0.930193\n",
      "[175]\ttraining's auc: 0.932923\tvalid_1's auc: 0.930186\n",
      "[176]\ttraining's auc: 0.932947\tvalid_1's auc: 0.930189\n",
      "[177]\ttraining's auc: 0.932999\tvalid_1's auc: 0.930195\n",
      "[178]\ttraining's auc: 0.933033\tvalid_1's auc: 0.930187\n",
      "[179]\ttraining's auc: 0.933056\tvalid_1's auc: 0.930197\n",
      "[180]\ttraining's auc: 0.933138\tvalid_1's auc: 0.930211\n",
      "[181]\ttraining's auc: 0.933185\tvalid_1's auc: 0.930223\n",
      "[182]\ttraining's auc: 0.933252\tvalid_1's auc: 0.930229\n",
      "[183]\ttraining's auc: 0.933275\tvalid_1's auc: 0.930231\n",
      "[184]\ttraining's auc: 0.933301\tvalid_1's auc: 0.930234\n",
      "[185]\ttraining's auc: 0.933403\tvalid_1's auc: 0.930241\n",
      "[186]\ttraining's auc: 0.933436\tvalid_1's auc: 0.930242\n",
      "[187]\ttraining's auc: 0.933453\tvalid_1's auc: 0.930251\n",
      "[188]\ttraining's auc: 0.93348\tvalid_1's auc: 0.930248\n",
      "[189]\ttraining's auc: 0.933579\tvalid_1's auc: 0.93025\n",
      "[190]\ttraining's auc: 0.933597\tvalid_1's auc: 0.93025\n",
      "[191]\ttraining's auc: 0.933667\tvalid_1's auc: 0.930247\n",
      "[192]\ttraining's auc: 0.933738\tvalid_1's auc: 0.930238\n",
      "[193]\ttraining's auc: 0.933753\tvalid_1's auc: 0.930237\n",
      "[194]\ttraining's auc: 0.933842\tvalid_1's auc: 0.930254\n",
      "[195]\ttraining's auc: 0.933864\tvalid_1's auc: 0.930259\n",
      "[196]\ttraining's auc: 0.934001\tvalid_1's auc: 0.930259\n",
      "[197]\ttraining's auc: 0.934049\tvalid_1's auc: 0.93026\n",
      "[198]\ttraining's auc: 0.934078\tvalid_1's auc: 0.930256\n",
      "[199]\ttraining's auc: 0.934087\tvalid_1's auc: 0.930258\n",
      "[200]\ttraining's auc: 0.934175\tvalid_1's auc: 0.93027\n",
      "[201]\ttraining's auc: 0.934202\tvalid_1's auc: 0.93027\n",
      "[202]\ttraining's auc: 0.934227\tvalid_1's auc: 0.930273\n",
      "[203]\ttraining's auc: 0.934315\tvalid_1's auc: 0.930254\n",
      "[204]\ttraining's auc: 0.934323\tvalid_1's auc: 0.930258\n",
      "[205]\ttraining's auc: 0.934405\tvalid_1's auc: 0.930269\n",
      "[206]\ttraining's auc: 0.934435\tvalid_1's auc: 0.93027\n",
      "[207]\ttraining's auc: 0.934445\tvalid_1's auc: 0.930275\n",
      "[208]\ttraining's auc: 0.934554\tvalid_1's auc: 0.930286\n",
      "[209]\ttraining's auc: 0.934588\tvalid_1's auc: 0.930284\n",
      "[210]\ttraining's auc: 0.934598\tvalid_1's auc: 0.930278\n",
      "[211]\ttraining's auc: 0.934604\tvalid_1's auc: 0.930279\n",
      "[212]\ttraining's auc: 0.934624\tvalid_1's auc: 0.930282\n",
      "[213]\ttraining's auc: 0.934659\tvalid_1's auc: 0.930294\n",
      "[214]\ttraining's auc: 0.934772\tvalid_1's auc: 0.930281\n",
      "[215]\ttraining's auc: 0.934803\tvalid_1's auc: 0.930271\n",
      "[216]\ttraining's auc: 0.934833\tvalid_1's auc: 0.930271\n",
      "[217]\ttraining's auc: 0.934944\tvalid_1's auc: 0.930277\n",
      "[218]\ttraining's auc: 0.934953\tvalid_1's auc: 0.93028\n",
      "[219]\ttraining's auc: 0.934986\tvalid_1's auc: 0.930271\n",
      "[220]\ttraining's auc: 0.934992\tvalid_1's auc: 0.930269\n",
      "[221]\ttraining's auc: 0.935023\tvalid_1's auc: 0.930269\n",
      "[222]\ttraining's auc: 0.935062\tvalid_1's auc: 0.930267\n",
      "[223]\ttraining's auc: 0.935095\tvalid_1's auc: 0.93026\n",
      "[224]\ttraining's auc: 0.935203\tvalid_1's auc: 0.930245\n",
      "[225]\ttraining's auc: 0.935227\tvalid_1's auc: 0.93024\n",
      "[226]\ttraining's auc: 0.935233\tvalid_1's auc: 0.930241\n",
      "[227]\ttraining's auc: 0.935263\tvalid_1's auc: 0.930251\n",
      "[228]\ttraining's auc: 0.935316\tvalid_1's auc: 0.930251\n",
      "[229]\ttraining's auc: 0.93541\tvalid_1's auc: 0.930243\n",
      "[230]\ttraining's auc: 0.935505\tvalid_1's auc: 0.930232\n",
      "[231]\ttraining's auc: 0.935564\tvalid_1's auc: 0.930225\n",
      "[232]\ttraining's auc: 0.935633\tvalid_1's auc: 0.930214\n",
      "[233]\ttraining's auc: 0.935682\tvalid_1's auc: 0.930212\n",
      "[234]\ttraining's auc: 0.935815\tvalid_1's auc: 0.930213\n",
      "[235]\ttraining's auc: 0.935851\tvalid_1's auc: 0.930206\n",
      "[236]\ttraining's auc: 0.935895\tvalid_1's auc: 0.930202\n",
      "[237]\ttraining's auc: 0.93593\tvalid_1's auc: 0.930207\n",
      "[238]\ttraining's auc: 0.935958\tvalid_1's auc: 0.93021\n",
      "[239]\ttraining's auc: 0.936021\tvalid_1's auc: 0.930206\n",
      "[240]\ttraining's auc: 0.936026\tvalid_1's auc: 0.930205\n",
      "[241]\ttraining's auc: 0.936055\tvalid_1's auc: 0.930201\n",
      "[242]\ttraining's auc: 0.936059\tvalid_1's auc: 0.930201\n",
      "[243]\ttraining's auc: 0.936134\tvalid_1's auc: 0.930211\n",
      "[244]\ttraining's auc: 0.936206\tvalid_1's auc: 0.930203\n",
      "[245]\ttraining's auc: 0.936261\tvalid_1's auc: 0.930205\n",
      "[246]\ttraining's auc: 0.93627\tvalid_1's auc: 0.93021\n",
      "[247]\ttraining's auc: 0.936378\tvalid_1's auc: 0.930196\n",
      "[248]\ttraining's auc: 0.936401\tvalid_1's auc: 0.930201\n",
      "[249]\ttraining's auc: 0.936438\tvalid_1's auc: 0.930198\n",
      "[250]\ttraining's auc: 0.936446\tvalid_1's auc: 0.930202\n",
      "[251]\ttraining's auc: 0.93652\tvalid_1's auc: 0.930205\n",
      "[252]\ttraining's auc: 0.936571\tvalid_1's auc: 0.930215\n",
      "[253]\ttraining's auc: 0.936625\tvalid_1's auc: 0.930223\n",
      "[254]\ttraining's auc: 0.936726\tvalid_1's auc: 0.930205\n",
      "[255]\ttraining's auc: 0.936791\tvalid_1's auc: 0.930206\n",
      "[256]\ttraining's auc: 0.936843\tvalid_1's auc: 0.930197\n",
      "[257]\ttraining's auc: 0.93686\tvalid_1's auc: 0.930193\n",
      "[258]\ttraining's auc: 0.936895\tvalid_1's auc: 0.930198\n",
      "[259]\ttraining's auc: 0.936927\tvalid_1's auc: 0.930206\n",
      "[260]\ttraining's auc: 0.936939\tvalid_1's auc: 0.930205\n",
      "[261]\ttraining's auc: 0.936984\tvalid_1's auc: 0.930193\n",
      "the number of probability more than 0.00 is 200000:\n",
      "the ratio of probability more than 0.00 is : 1.0000\n",
      "---------------------------------------------------\n",
      "\n",
      "the number of probability more than 0.10 is 99067:\n",
      "the ratio of probability more than 0.10 is : 0.4953\n",
      "---------------------------------------------------\n",
      "\n",
      "the number of probability more than 0.20 is 91112:\n",
      "the ratio of probability more than 0.20 is : 0.4556\n",
      "---------------------------------------------------\n",
      "\n",
      "the number of probability more than 0.30 is 85178:\n",
      "the ratio of probability more than 0.30 is : 0.4259\n",
      "---------------------------------------------------\n",
      "\n",
      "the number of probability more than 0.40 is 78643:\n",
      "the ratio of probability more than 0.40 is : 0.3932\n",
      "---------------------------------------------------\n",
      "\n",
      "the number of probability more than 0.50 is 71506:\n",
      "the ratio of probability more than 0.50 is : 0.3575\n",
      "---------------------------------------------------\n",
      "\n",
      "the number of probability more than 0.60 is 63403:\n",
      "the ratio of probability more than 0.60 is : 0.3170\n",
      "---------------------------------------------------\n",
      "\n",
      "the number of probability more than 0.70 is 48970:\n",
      "the ratio of probability more than 0.70 is : 0.2449\n",
      "---------------------------------------------------\n",
      "\n",
      "the number of probability more than 0.80 is 29998:\n",
      "the ratio of probability more than 0.80 is : 0.1500\n",
      "---------------------------------------------------\n",
      "\n",
      "the number of probability more than 0.90 is 27494:\n",
      "the ratio of probability more than 0.90 is : 0.1375\n",
      "---------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Executing...\")\n",
    "Y_exam = np.zeros(X_exam_processed.shape[0])\n",
    "k = 5\n",
    "kf = StratifiedKFold(n_splits=k)\n",
    "for tr_index, val_index in kf.split(X_processed,Y_model):\n",
    "    X_tr,Y_tr = X_processed.iloc[tr_index],Y_model.iloc[tr_index]\n",
    "    X_val, Y_val = X_processed.iloc[val_index],Y_model.iloc[val_index]\n",
    "    \n",
    "    optimized_LGBM.fit(X_tr,Y_tr,eval_metric='auc')\n",
    "    proba = optimized_LGBM.predict_proba(X_exam_processed)[:,1]\n",
    "    Y_exam = Y_exam + proba\n",
    "Y_exam = Y_exam/k\n",
    "thresholds = np.array([0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9])\n",
    "# the ratio of high prob with different thresholds\n",
    "for num in thresholds: \n",
    "    filtered = Y_exam[np.where(Y_exam>=num)]\n",
    "    print(\"the number of probability more than %.2f is %d:\" %(num,len(filtered)))\n",
    "    print(\"the ratio of probability more than %.2f is : %.4f\"%(num, float(len(filtered))/len(Y_exam)))\n",
    "    print('---------------------------------------------------\\n')\n",
    "# res = pd.DataFrame({'business prob':Y_exam})\n",
    "# res.to_csv(\"./part1.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a0e4683c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=522, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=522\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.010815978738787315, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.010815978738787315\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.23684876647852016, subsample=1.0 will be ignored. Current value: bagging_fraction=0.23684876647852016\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.522863566413219, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.522863566413219\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=522, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=522\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.010815978738787315, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.010815978738787315\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.23684876647852016, subsample=1.0 will be ignored. Current value: bagging_fraction=0.23684876647852016\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.522863566413219, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.522863566413219\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=522, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=522\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.010815978738787315, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.010815978738787315\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.23684876647852016, subsample=1.0 will be ignored. Current value: bagging_fraction=0.23684876647852016\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.522863566413219, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.522863566413219\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=522, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=522\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.010815978738787315, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.010815978738787315\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.23684876647852016, subsample=1.0 will be ignored. Current value: bagging_fraction=0.23684876647852016\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.522863566413219, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.522863566413219\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=522, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=522\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.010815978738787315, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.010815978738787315\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.23684876647852016, subsample=1.0 will be ignored. Current value: bagging_fraction=0.23684876647852016\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.522863566413219, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.522863566413219\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=522, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=522\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.010815978738787315, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.010815978738787315\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.23684876647852016, subsample=1.0 will be ignored. Current value: bagging_fraction=0.23684876647852016\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.522863566413219, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.522863566413219\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=522, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=522\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.010815978738787315, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.010815978738787315\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.23684876647852016, subsample=1.0 will be ignored. Current value: bagging_fraction=0.23684876647852016\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.522863566413219, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.522863566413219\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=522, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=522\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.010815978738787315, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.010815978738787315\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.23684876647852016, subsample=1.0 will be ignored. Current value: bagging_fraction=0.23684876647852016\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.522863566413219, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.522863566413219\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=522, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=522\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.010815978738787315, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.010815978738787315\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.23684876647852016, subsample=1.0 will be ignored. Current value: bagging_fraction=0.23684876647852016\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.522863566413219, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.522863566413219\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=522, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=522\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.010815978738787315, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.010815978738787315\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.23684876647852016, subsample=1.0 will be ignored. Current value: bagging_fraction=0.23684876647852016\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.522863566413219, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.522863566413219\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=522, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=522\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.010815978738787315, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.010815978738787315\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.23684876647852016, subsample=1.0 will be ignored. Current value: bagging_fraction=0.23684876647852016\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.522863566413219, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.522863566413219\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=522, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=522\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.010815978738787315, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.010815978738787315\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.23684876647852016, subsample=1.0 will be ignored. Current value: bagging_fraction=0.23684876647852016\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.522863566413219, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.522863566413219\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=522, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=522\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.010815978738787315, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.010815978738787315\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.23684876647852016, subsample=1.0 will be ignored. Current value: bagging_fraction=0.23684876647852016\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.522863566413219, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.522863566413219\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=522, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=522\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.010815978738787315, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.010815978738787315\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.23684876647852016, subsample=1.0 will be ignored. Current value: bagging_fraction=0.23684876647852016\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.522863566413219, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.522863566413219\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=522, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=522\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.010815978738787315, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.010815978738787315\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.23684876647852016, subsample=1.0 will be ignored. Current value: bagging_fraction=0.23684876647852016\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.522863566413219, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.522863566413219\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=522, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=522\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.010815978738787315, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.010815978738787315\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.23684876647852016, subsample=1.0 will be ignored. Current value: bagging_fraction=0.23684876647852016\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.522863566413219, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.522863566413219\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=522, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=522\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.010815978738787315, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.010815978738787315\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.23684876647852016, subsample=1.0 will be ignored. Current value: bagging_fraction=0.23684876647852016\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.522863566413219, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.522863566413219\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=522, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=522\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.010815978738787315, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.010815978738787315\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.23684876647852016, subsample=1.0 will be ignored. Current value: bagging_fraction=0.23684876647852016\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.522863566413219, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.522863566413219\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=522, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=522\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.010815978738787315, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.010815978738787315\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.23684876647852016, subsample=1.0 will be ignored. Current value: bagging_fraction=0.23684876647852016\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.522863566413219, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.522863566413219\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=522, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=522\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.010815978738787315, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.010815978738787315\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.23684876647852016, subsample=1.0 will be ignored. Current value: bagging_fraction=0.23684876647852016\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.522863566413219, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.522863566413219\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=522, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=522\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.010815978738787315, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.010815978738787315\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.23684876647852016, subsample=1.0 will be ignored. Current value: bagging_fraction=0.23684876647852016\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.522863566413219, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.522863566413219\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=522, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=522\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.010815978738787315, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.010815978738787315\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.23684876647852016, subsample=1.0 will be ignored. Current value: bagging_fraction=0.23684876647852016\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.522863566413219, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.522863566413219\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=522, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=522\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.010815978738787315, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.010815978738787315\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.23684876647852016, subsample=1.0 will be ignored. Current value: bagging_fraction=0.23684876647852016\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.522863566413219, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.522863566413219\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=522, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=522\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.010815978738787315, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.010815978738787315\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.23684876647852016, subsample=1.0 will be ignored. Current value: bagging_fraction=0.23684876647852016\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.522863566413219, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.522863566413219\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=522, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=522\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.010815978738787315, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.010815978738787315\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.23684876647852016, subsample=1.0 will be ignored. Current value: bagging_fraction=0.23684876647852016\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.522863566413219, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.522863566413219\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=522, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=522\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.010815978738787315, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.010815978738787315\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.23684876647852016, subsample=1.0 will be ignored. Current value: bagging_fraction=0.23684876647852016\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.522863566413219, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.522863566413219\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=522, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=522\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.010815978738787315, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.010815978738787315\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.23684876647852016, subsample=1.0 will be ignored. Current value: bagging_fraction=0.23684876647852016\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.522863566413219, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.522863566413219\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=522, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=522\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.010815978738787315, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.010815978738787315\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.23684876647852016, subsample=1.0 will be ignored. Current value: bagging_fraction=0.23684876647852016\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.522863566413219, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.522863566413219\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=522, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=522\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.010815978738787315, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.010815978738787315\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.23684876647852016, subsample=1.0 will be ignored. Current value: bagging_fraction=0.23684876647852016\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.522863566413219, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.522863566413219\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=522, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=522\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.010815978738787315, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.010815978738787315\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.23684876647852016, subsample=1.0 will be ignored. Current value: bagging_fraction=0.23684876647852016\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.522863566413219, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.522863566413219\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=522, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=522\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.010815978738787315, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.010815978738787315\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.23684876647852016, subsample=1.0 will be ignored. Current value: bagging_fraction=0.23684876647852016\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.522863566413219, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.522863566413219\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=522, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=522\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.010815978738787315, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.010815978738787315\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.23684876647852016, subsample=1.0 will be ignored. Current value: bagging_fraction=0.23684876647852016\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.522863566413219, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.522863566413219\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=522, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=522\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.010815978738787315, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.010815978738787315\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.23684876647852016, subsample=1.0 will be ignored. Current value: bagging_fraction=0.23684876647852016\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.522863566413219, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.522863566413219\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=522, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=522\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.010815978738787315, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.010815978738787315\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.23684876647852016, subsample=1.0 will be ignored. Current value: bagging_fraction=0.23684876647852016\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.522863566413219, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.522863566413219\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=522, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=522\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.010815978738787315, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.010815978738787315\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.23684876647852016, subsample=1.0 will be ignored. Current value: bagging_fraction=0.23684876647852016\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.522863566413219, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.522863566413219\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=522, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=522\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.010815978738787315, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.010815978738787315\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.23684876647852016, subsample=1.0 will be ignored. Current value: bagging_fraction=0.23684876647852016\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.522863566413219, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.522863566413219\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=522, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=522\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.010815978738787315, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.010815978738787315\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.23684876647852016, subsample=1.0 will be ignored. Current value: bagging_fraction=0.23684876647852016\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.522863566413219, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.522863566413219\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=522, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=522\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.010815978738787315, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.010815978738787315\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.23684876647852016, subsample=1.0 will be ignored. Current value: bagging_fraction=0.23684876647852016\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.522863566413219, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.522863566413219\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=522, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=522\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.010815978738787315, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.010815978738787315\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.23684876647852016, subsample=1.0 will be ignored. Current value: bagging_fraction=0.23684876647852016\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.522863566413219, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.522863566413219\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=522, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=522\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.010815978738787315, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.010815978738787315\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.23684876647852016, subsample=1.0 will be ignored. Current value: bagging_fraction=0.23684876647852016\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.522863566413219, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.522863566413219\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=522, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=522\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.010815978738787315, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.010815978738787315\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.23684876647852016, subsample=1.0 will be ignored. Current value: bagging_fraction=0.23684876647852016\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.522863566413219, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.522863566413219\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=522, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=522\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.010815978738787315, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.010815978738787315\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.23684876647852016, subsample=1.0 will be ignored. Current value: bagging_fraction=0.23684876647852016\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.522863566413219, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.522863566413219\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=522, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=522\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.010815978738787315, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.010815978738787315\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.23684876647852016, subsample=1.0 will be ignored. Current value: bagging_fraction=0.23684876647852016\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.522863566413219, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.522863566413219\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=522, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=522\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.010815978738787315, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.010815978738787315\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.23684876647852016, subsample=1.0 will be ignored. Current value: bagging_fraction=0.23684876647852016\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.522863566413219, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.522863566413219\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=522, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=522\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.010815978738787315, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.010815978738787315\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.23684876647852016, subsample=1.0 will be ignored. Current value: bagging_fraction=0.23684876647852016\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.522863566413219, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.522863566413219\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=522, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=522\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.010815978738787315, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.010815978738787315\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.23684876647852016, subsample=1.0 will be ignored. Current value: bagging_fraction=0.23684876647852016\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.522863566413219, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.522863566413219\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=522, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=522\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.010815978738787315, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.010815978738787315\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.23684876647852016, subsample=1.0 will be ignored. Current value: bagging_fraction=0.23684876647852016\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.522863566413219, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.522863566413219\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=522, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=522\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.010815978738787315, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.010815978738787315\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.23684876647852016, subsample=1.0 will be ignored. Current value: bagging_fraction=0.23684876647852016\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.522863566413219, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.522863566413219\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=522, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=522\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.010815978738787315, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.010815978738787315\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.23684876647852016, subsample=1.0 will be ignored. Current value: bagging_fraction=0.23684876647852016\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.522863566413219, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.522863566413219\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=522, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=522\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.010815978738787315, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.010815978738787315\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.23684876647852016, subsample=1.0 will be ignored. Current value: bagging_fraction=0.23684876647852016\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.522863566413219, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.522863566413219\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=522, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=522\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.010815978738787315, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.010815978738787315\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.23684876647852016, subsample=1.0 will be ignored. Current value: bagging_fraction=0.23684876647852016\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.522863566413219, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.522863566413219\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=522, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=522\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.010815978738787315, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.010815978738787315\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.23684876647852016, subsample=1.0 will be ignored. Current value: bagging_fraction=0.23684876647852016\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.522863566413219, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.522863566413219\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=522, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=522\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.010815978738787315, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.010815978738787315\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.23684876647852016, subsample=1.0 will be ignored. Current value: bagging_fraction=0.23684876647852016\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.522863566413219, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.522863566413219\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=522, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=522\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.010815978738787315, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.010815978738787315\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.23684876647852016, subsample=1.0 will be ignored. Current value: bagging_fraction=0.23684876647852016\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.522863566413219, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.522863566413219\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=522, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=522\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.010815978738787315, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.010815978738787315\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.23684876647852016, subsample=1.0 will be ignored. Current value: bagging_fraction=0.23684876647852016\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.522863566413219, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.522863566413219\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "# Y_exam = np.zeros(X_exam_processed.shape[0])\n",
    "\n",
    "accuracy_Arr = np.array([])\n",
    "popup_Arr = np.array([])\n",
    "survey_Arr = np.array([])\n",
    "\n",
    "k = 5\n",
    "kf = StratifiedKFold(n_splits=k)\n",
    "thresholds = [0.3,0.4,0.5,0.6,0.7,0.8,0.9,0.92,0.93,0.94,0.95]\n",
    "for th in thresholds:\n",
    "    popup_P = 0\n",
    "    survey_P = 0\n",
    "    accuracy = 0\n",
    "    for tr_index, val_index in kf.split(X_processed,Y_model):\n",
    "        X_tr,Y_tr = X_processed.iloc[tr_index],Y_model.iloc[tr_index]\n",
    "        X_val, Y_val = X_processed.iloc[val_index],Y_model.iloc[val_index]\n",
    "\n",
    "        optimized_LGBM.fit(X_tr,Y_tr,eval_metric='auc')\n",
    "        # Generate the columns\n",
    "        proba = optimized_LGBM.predict_proba(X_val)[:,1]\n",
    "        pred = pd.DataFrame({'business prob_pred':proba})\n",
    "        popup = pd.DataFrame({'popup':np.zeros(X_val.shape[0])})\n",
    "        survey = pd.DataFrame({'survey':np.zeros(X_val.shape[0])})\n",
    "#         login = pd.DataFrame({'login':np.zeros(X_val.shape[0])})\n",
    "        \n",
    "        # Merge\n",
    "        res = pd.concat([pred,popup],axis=1)\n",
    "        res = pd.concat([res,survey],axis=1)\n",
    "#         res = pd.concat([res,login],axis=1)\n",
    "        \n",
    "        # If predicted proba is more than th, put his popup as 1\n",
    "        res.loc[res['business prob_pred'] >= th, 'popup'] = 1\n",
    "        res.loc[ (res['business prob_pred'] >= th)&(X_val['last_5_days_sum']>0) , 'survey'] = 1\n",
    "        \n",
    "        accuracy += accuracy_score(Y_val, res['popup'])\n",
    "        res = pd.concat([res,Y_val.reset_index(drop=True)],axis=1) # Merge res with Y_val\n",
    "        popup_P += res.loc[res['popup']==1,'business'].sum()*(500000*0.01) - res['popup'].sum()*400\n",
    "        survey_P += res.loc[res['survey']==1,'business'].sum()*(500000*0.036) - res['survey'].sum()*5000*0.18\n",
    "        \n",
    "    accuracy_Arr = np.append(accuracy_Arr,accuracy/k)\n",
    "    popup_Arr = np.append(popup_Arr,popup_P/k)\n",
    "    survey_Arr = np.append(survey_Arr,survey_P/k)\n",
    "    \n",
    "\n",
    "#     print('---------------------------------')\n",
    "#     print(accuracy_score(Y_val, res['popup']))\n",
    "#     print('---------------------------------')\n",
    "#     print('net profit:')\n",
    "#     profit = res.loc[res['popup']==1,'business'].sum()*(500000*0.01) - res['popup'].sum()*400\n",
    "#     print(profit)\n",
    "#     print('---------------------------------')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ac832ca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    threshold  avg_Accuracy  avg_Popup_Profit  avg_Survey_Porfit\n",
      "0        0.30      0.712170        26961360.0         24250860.0\n",
      "1        0.40      0.746003        28053960.0         24463440.0\n",
      "2        0.50      0.782204        28767520.0         24416820.0\n",
      "3        0.60      0.819901        28647200.0         23722740.0\n",
      "4        0.70      0.881643        26022520.0         20329560.0\n",
      "5        0.80      0.952078        18627200.0         13962420.0\n",
      "6        0.90      0.957921        17053560.0         12749220.0\n",
      "7        0.92      0.957950        17013240.0         12725100.0\n",
      "8        0.93      0.957959        17004480.0         12718800.0\n",
      "9        0.94      0.957946        16991160.0         12715560.0\n",
      "10       0.95      0.957945        16986880.0         12712140.0\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({'threshold':thresholds, 'avg_Accuracy':accuracy_Arr, 'avg_Popup_Profit':popup_Arr, 'avg_Survey_Porfit':survey_Arr})\n",
    "df.set_index('threshold')\n",
    "print(df)\n",
    "#    threshold  avg_Accuracy  avg_Popup_Profit  avg_Survey_Porfit\n",
    "# 0        0.0      0.068291        -8240960.0         46341540.0\n",
    "# 1        0.1      0.640494        23696040.0        117750240.0\n",
    "# 2        0.2      0.682034        25660280.0        121567680.0\n",
    "# 3        0.3      0.713838        27021680.0        123940980.0\n",
    "# 4        0.4      0.747154        28083480.0        125021880.0\n",
    "# 5        0.5      0.782841        28742040.0        124332840.0\n",
    "# 6        0.6      0.821378        28614400.0        120353400.0\n",
    "# 7        0.7      0.882643        25932680.0        104465880.0\n",
    "# 8        0.8      0.950920        18802240.0         70784640.0\n",
    "# 9        0.9      0.957690        17100240.0         63607140.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4b62788d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data preprocessing...\n"
     ]
    }
   ],
   "source": [
    "X_exam = pd.read_csv('X_exam.csv')\n",
    "print(\"Data preprocessing...\")\n",
    "dist_GIT_exam = rangesum(\n",
    "    'GIT', \n",
    "    r\"202205[0-9]{2}\", \n",
    "    \"cts\", \n",
    "    equal_dist(31)\n",
    ")(X_exam)\n",
    "dist_VAT_exam = rangesum(\n",
    "    'VAT', \n",
    "    r\"20220[17](?:[01][0-9]|2[0-5])\", \n",
    "    \"ts\", \n",
    "    np.concatenate((equal_dist(25), equal_dist(25)))\n",
    ")(X_exam)\n",
    "entire_days = 31 + 29 + 31 + 30 + 31 + 30 + 31 + 25\n",
    "entire_exam = rangesum(\n",
    "    'Entire', \n",
    "    r\"2022[0-9]{4}\", \n",
    "    \"cts\", \n",
    "    equal_dist(entire_days)\n",
    ")(X_exam)\n",
    "\n",
    "age_code_exam = np.array(X_exam['age_code'])\n",
    "gender_code_exam = np.array(X_exam['gender'])\n",
    "region_code_exam = np.array(X_exam['region_code'])\n",
    "cat_Featrues_exam = []\n",
    "cat_Featrues_exam.append(['gender',age_code_exam])\n",
    "cat_Featrues_exam.append(['age_code',age_code_exam])\n",
    "cat_Featrues_exam.append(['region_code',region_code_exam])\n",
    "\n",
    "# Get columns of \"c\" prefix of last 5 days of month\n",
    "last_5_days = [\n",
    "    *[f\"c202201{i + 27}\" for i in range(5)],\n",
    "    *[f\"c202202{i + 24}\" for i in range(5)],\n",
    "    *[f\"c202203{i + 27}\" for i in range(5)],\n",
    "    *[f\"c202204{i + 26}\" for i in range(5)],\n",
    "    *[f\"c202205{i + 27}\" for i in range(5)],\n",
    "    *[f\"c202206{i + 26}\" for i in range(5)],\n",
    "    *[f\"c202207{i + 27}\" for i in range(5)],\n",
    "]\n",
    "last_5_days_sum_exam = X_exam.filter(last_5_days, axis=1).fillna(0).sum(axis=1)\n",
    "last_5_days_sum_exam = X_exam.filter(last_5_days, axis=1).fillna(0).sum(axis=1)\n",
    "last5_code_exam = np.array(last_5_days_sum_exam)\n",
    "last_5_days_sum_list_exam =[]\n",
    "last_5_days_sum_list_exam.append(['last_5_days_sum',last5_code_exam])\n",
    "\n",
    "X_exam_processed = preprocess(\n",
    "    X_exam, \n",
    "    [\n",
    "        cat_Featrues_exam,\n",
    "        dist_GIT_exam,\n",
    "        dist_VAT_exam,\n",
    "        entire_exam,\n",
    "        last_5_days_sum_list_exam\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "236756b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=522, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=522\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.010815978738787315, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.010815978738787315\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.23684876647852016, subsample=1.0 will be ignored. Current value: bagging_fraction=0.23684876647852016\n",
      "[LightGBM] [Warning] lambda_l2 is set=2.522863566413219, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.522863566413219\n"
     ]
    }
   ],
   "source": [
    "optimized_LGBM.fit(X_processed,Y_model,eval_metric='auc')\n",
    "proba = optimized_LGBM.predict_proba(X_exam_processed)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7adf231e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   business_prob  popup  survey\n",
      "0       0.440112      0       0\n",
      "1       0.002921      0       0\n",
      "2       0.485339      0       0\n",
      "3       0.004235      0       0\n",
      "4       0.037652      0       0\n"
     ]
    }
   ],
   "source": [
    "final = pd.DataFrame({'business_prob':proba})\n",
    "P = pd.DataFrame({'popup':np.zeros(X_exam_processed.shape[0],dtype=int)})\n",
    "S = pd.DataFrame({'survey':np.zeros(X_exam_processed.shape[0],dtype=int)})\n",
    "\n",
    "final = pd.concat([final,P],axis=1)\n",
    "final = pd.concat([final,S],axis=1)\n",
    "\n",
    "final.loc[final['business_prob'] >= 0.5, 'popup'] = int(1)\n",
    "final.loc[(final['business_prob'] >= 0.7) & (X_exam_processed['last_5_days_sum']>0), 'survey'] = int(1)\n",
    "print(final.head())\n",
    "final.to_csv(\"./submission.csv\",index=False)\n",
    "#    business_prob  popup  survey\n",
    "# 0       0.440112      0       0\n",
    "# 1       0.002921      0       0\n",
    "# 2       0.485339      0       0\n",
    "# 3       0.004235      0       0\n",
    "# 4       0.037652      0       0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fe7579fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48479"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final['survey'].sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
