{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf413c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import optuna\n",
    "from optuna.trial import Trial\n",
    "from optuna.samplers import TPESampler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from typing import List, Any, Tuple\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5363f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Loading\n",
    "X_model = pd.read_csv('X_model.csv')\n",
    "Y_model = pd.read_csv('Y_model.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6318e489",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78f4c031",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defining preprocessors...\n"
     ]
    }
   ],
   "source": [
    "# Define preprocessors\n",
    "print(\"Defining preprocessors...\")\n",
    "def column(colnames: List[str]):\n",
    "    def _column(X: pd.DataFrame):\n",
    "        X = X.fillna(0)\n",
    "        return [\n",
    "            [colname, X[colname].values] for colname in colnames\n",
    "        ]\n",
    "    return _column\n",
    "\n",
    "def rangesum(\n",
    "    name:str, \n",
    "    regex: str, \n",
    "    prefixes: str, \n",
    "    dist: np.ndarray\n",
    "):\n",
    "    def _rangesum(X: pd.DataFrame):\n",
    "        X = X.fillna(0)\n",
    "        return [\n",
    "            [\n",
    "                prefix + name, \n",
    "                X.filter(regex=(prefix + regex), axis=1).values.dot(dist)\n",
    "            ] for prefix in prefixes\n",
    "        ]\n",
    "    return _rangesum\n",
    "\n",
    "def _fillna(X: np.ndarray) -> np.ndarray:\n",
    "    return np.nan_to_num(X, copy=True, nan=0)\n",
    "\n",
    "def array_divide(\n",
    "    numerator: List[Tuple[str, np.ndarray]], \n",
    "    denominator: List[Tuple[str, np.ndarray]]\n",
    ") -> List[Any]:\n",
    "    assert len(numerator) == len(denominator)\n",
    "    return [\n",
    "        [\n",
    "            \"r\" + numerator_colname, \n",
    "            _fillna(np.divide(numerator_col, denominator_col))\n",
    "        ] for [numerator_colname, numerator_col], [_, denominator_col] in zip(numerator, denominator)\n",
    "    ]\n",
    "\n",
    "def one_hot_encode(column: str) -> pd.DataFrame:\n",
    "    def _one_hot_encode(X: pd.DataFrame):\n",
    "        X = X.fillna(0)\n",
    "        df_dummies = pd.get_dummies(X[column], prefix=column)\n",
    "        return [\n",
    "            [colname, df_dummies[colname].values] for colname in df_dummies.columns\n",
    "        ]\n",
    "    return _one_hot_encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b684019",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(X: pd.DataFrame, processors: List[Any]) -> pd.DataFrame:\n",
    "    X_new = pd.DataFrame()\n",
    "\n",
    "    for processor in processors:\n",
    "        for colname, col in processor if type(processor) == type([]) else processor(X):\n",
    "            X_new[colname] = col\n",
    "\n",
    "    X_new = X_new.fillna(0)\n",
    "\n",
    "    X_new = pd.DataFrame(scaler.fit_transform(X_new), columns=X_new.columns)\n",
    "\n",
    "    return X_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "653c146c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def equal_dist(length: int) -> np.ndarray:\n",
    "    return np.ones(length)\n",
    "\n",
    "def linear_dist(length: int) -> np.ndarray:\n",
    "    return np.arange(start=0, stop=1, step=1/length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b1f1984",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data preprocessing...\n"
     ]
    }
   ],
   "source": [
    "print(\"Data preprocessing...\")\n",
    "dist_GIT = rangesum(\n",
    "    'GIT', \n",
    "    r\"202205[0-9]{2}\", \n",
    "    \"cts\", \n",
    "    equal_dist(31)\n",
    ")(X_model)\n",
    "dist_VAT = rangesum(\n",
    "    'VAT', \n",
    "    r\"20220[17](?:[01][0-9]|2[0-5])\", \n",
    "    \"ts\", \n",
    "    np.concatenate((equal_dist(25), equal_dist(25)))\n",
    ")(X_model)\n",
    "entire_days = 31 + 29 + 31 + 30 + 31 + 30 + 31 + 25\n",
    "entire = rangesum(\n",
    "    'Entire', \n",
    "    r\"2022[0-9]{4}\", \n",
    "    \"cts\", \n",
    "    equal_dist(entire_days)\n",
    ")(X_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "75c276f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_processed = preprocess(\n",
    "    X_model, \n",
    "    [\n",
    "        column(['age_code']),\n",
    "        one_hot_encode('gender'),\n",
    "        one_hot_encode('region_code'),\n",
    "        dist_GIT,\n",
    "        dist_VAT,\n",
    "        entire,\n",
    "        # array_divide(dist_GIT, entire), # rel_GIT\n",
    "        # array_divide(dist_VAT, entire[1:]), # rel_VAT\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "674724ed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "750c1d6c71fe4a44b328fcdeb120abaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=198, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=198\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1797587862399534, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1797587862399534\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5538398612031032, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5538398612031032\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.5101226762587391, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.5101226762587391\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=198, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=198\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1797587862399534, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1797587862399534\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5538398612031032, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5538398612031032\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.5101226762587391, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.5101226762587391\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=198, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=198\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1797587862399534, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1797587862399534\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5538398612031032, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5538398612031032\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.5101226762587391, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.5101226762587391\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=198, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=198\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1797587862399534, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1797587862399534\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5538398612031032, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5538398612031032\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.5101226762587391, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.5101226762587391\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=198, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=198\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1797587862399534, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1797587862399534\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5538398612031032, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5538398612031032\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.5101226762587391, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.5101226762587391\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=117, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=117\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.00794888621681748, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00794888621681748\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.607278529686255, subsample=1.0 will be ignored. Current value: bagging_fraction=0.607278529686255\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.023950461737247658, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.023950461737247658\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=117, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=117\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.00794888621681748, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00794888621681748\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.607278529686255, subsample=1.0 will be ignored. Current value: bagging_fraction=0.607278529686255\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.023950461737247658, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.023950461737247658\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=117, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=117\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.00794888621681748, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00794888621681748\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.607278529686255, subsample=1.0 will be ignored. Current value: bagging_fraction=0.607278529686255\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.023950461737247658, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.023950461737247658\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=117, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=117\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.00794888621681748, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00794888621681748\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.607278529686255, subsample=1.0 will be ignored. Current value: bagging_fraction=0.607278529686255\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.023950461737247658, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.023950461737247658\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=117, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=117\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.00794888621681748, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00794888621681748\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.607278529686255, subsample=1.0 will be ignored. Current value: bagging_fraction=0.607278529686255\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.023950461737247658, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.023950461737247658\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=137, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=137\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.033978428997953995, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.033978428997953995\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.28674052785973747, subsample=1.0 will be ignored. Current value: bagging_fraction=0.28674052785973747\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.7617877404389514, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.7617877404389514\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=137, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=137\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.033978428997953995, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.033978428997953995\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.28674052785973747, subsample=1.0 will be ignored. Current value: bagging_fraction=0.28674052785973747\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.7617877404389514, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.7617877404389514\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=137, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=137\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.033978428997953995, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.033978428997953995\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.28674052785973747, subsample=1.0 will be ignored. Current value: bagging_fraction=0.28674052785973747\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.7617877404389514, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.7617877404389514\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=137, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=137\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.033978428997953995, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.033978428997953995\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.28674052785973747, subsample=1.0 will be ignored. Current value: bagging_fraction=0.28674052785973747\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.7617877404389514, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.7617877404389514\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=137, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=137\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.033978428997953995, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.033978428997953995\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.28674052785973747, subsample=1.0 will be ignored. Current value: bagging_fraction=0.28674052785973747\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.7617877404389514, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.7617877404389514\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=101, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=101\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.2114915657280268, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.2114915657280268\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7444065357912806, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7444065357912806\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.12805083561081954, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.12805083561081954\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=101, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=101\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.2114915657280268, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.2114915657280268\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7444065357912806, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7444065357912806\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.12805083561081954, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.12805083561081954\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=101, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=101\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.2114915657280268, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.2114915657280268\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7444065357912806, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7444065357912806\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.12805083561081954, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.12805083561081954\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=101, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=101\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.2114915657280268, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.2114915657280268\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7444065357912806, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7444065357912806\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.12805083561081954, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.12805083561081954\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=101, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=101\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.2114915657280268, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.2114915657280268\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7444065357912806, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7444065357912806\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.12805083561081954, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.12805083561081954\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=130, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=130\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.33655148021223236, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.33655148021223236\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.710195101098715, subsample=1.0 will be ignored. Current value: bagging_fraction=0.710195101098715\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.04707475333409883, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.04707475333409883\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=130, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=130\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.33655148021223236, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.33655148021223236\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.710195101098715, subsample=1.0 will be ignored. Current value: bagging_fraction=0.710195101098715\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.04707475333409883, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.04707475333409883\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=130, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=130\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.33655148021223236, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.33655148021223236\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.710195101098715, subsample=1.0 will be ignored. Current value: bagging_fraction=0.710195101098715\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.04707475333409883, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.04707475333409883\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=130, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=130\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.33655148021223236, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.33655148021223236\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.710195101098715, subsample=1.0 will be ignored. Current value: bagging_fraction=0.710195101098715\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.04707475333409883, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.04707475333409883\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=130, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=130\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.33655148021223236, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.33655148021223236\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.710195101098715, subsample=1.0 will be ignored. Current value: bagging_fraction=0.710195101098715\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.04707475333409883, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.04707475333409883\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=138, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=138\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01183222442589104, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01183222442589104\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.672359470244823, subsample=1.0 will be ignored. Current value: bagging_fraction=0.672359470244823\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.05028255657518079, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.05028255657518079\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=138, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=138\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01183222442589104, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01183222442589104\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.672359470244823, subsample=1.0 will be ignored. Current value: bagging_fraction=0.672359470244823\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.05028255657518079, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.05028255657518079\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=138, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=138\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01183222442589104, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01183222442589104\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.672359470244823, subsample=1.0 will be ignored. Current value: bagging_fraction=0.672359470244823\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.05028255657518079, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.05028255657518079\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=138, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=138\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01183222442589104, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01183222442589104\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.672359470244823, subsample=1.0 will be ignored. Current value: bagging_fraction=0.672359470244823\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.05028255657518079, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.05028255657518079\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=138, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=138\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.01183222442589104, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.01183222442589104\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.672359470244823, subsample=1.0 will be ignored. Current value: bagging_fraction=0.672359470244823\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.05028255657518079, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.05028255657518079\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=154, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=154\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.010193412864005831, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.010193412864005831\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.3410644203040326, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3410644203040326\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0012297454589144474, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0012297454589144474\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=154, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=154\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.010193412864005831, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.010193412864005831\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.3410644203040326, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3410644203040326\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0012297454589144474, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0012297454589144474\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=154, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=154\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.010193412864005831, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.010193412864005831\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.3410644203040326, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3410644203040326\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0012297454589144474, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0012297454589144474\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=154, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=154\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.010193412864005831, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.010193412864005831\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.3410644203040326, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3410644203040326\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0012297454589144474, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0012297454589144474\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=154, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=154\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.010193412864005831, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.010193412864005831\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.3410644203040326, subsample=1.0 will be ignored. Current value: bagging_fraction=0.3410644203040326\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0012297454589144474, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0012297454589144474\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=122, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=122\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.1011678173734487, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.1011678173734487\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5661996225066176, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5661996225066176\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.03366920064003658, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.03366920064003658\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=122, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=122\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.1011678173734487, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.1011678173734487\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5661996225066176, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5661996225066176\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.03366920064003658, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.03366920064003658\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=122, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=122\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.1011678173734487, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.1011678173734487\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5661996225066176, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5661996225066176\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.03366920064003658, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.03366920064003658\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=122, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=122\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.1011678173734487, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.1011678173734487\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5661996225066176, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5661996225066176\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.03366920064003658, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.03366920064003658\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=122, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=122\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.1011678173734487, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.1011678173734487\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5661996225066176, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5661996225066176\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.03366920064003658, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.03366920064003658\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=125, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=125\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.794915457925842, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.794915457925842\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9841201083992284, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9841201083992284\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0021170589840723572, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0021170589840723572\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=125, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=125\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.794915457925842, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.794915457925842\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9841201083992284, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9841201083992284\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0021170589840723572, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0021170589840723572\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=125, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=125\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.794915457925842, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.794915457925842\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9841201083992284, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9841201083992284\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0021170589840723572, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0021170589840723572\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=125, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=125\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.794915457925842, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.794915457925842\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9841201083992284, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9841201083992284\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0021170589840723572, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0021170589840723572\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=125, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=125\n",
      "[LightGBM] [Warning] lambda_l1 is set=2.794915457925842, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.794915457925842\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9841201083992284, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9841201083992284\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0021170589840723572, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0021170589840723572\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=185, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=185\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.020334236166341394, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.020334236166341394\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4474478579091379, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4474478579091379\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.038857551326347876, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.038857551326347876\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=185, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=185\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.020334236166341394, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.020334236166341394\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4474478579091379, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4474478579091379\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.038857551326347876, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.038857551326347876\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=185, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=185\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.020334236166341394, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.020334236166341394\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4474478579091379, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4474478579091379\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.038857551326347876, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.038857551326347876\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=185, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=185\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.020334236166341394, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.020334236166341394\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4474478579091379, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4474478579091379\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.038857551326347876, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.038857551326347876\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=185, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=185\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.020334236166341394, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.020334236166341394\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4474478579091379, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4474478579091379\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.038857551326347876, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.038857551326347876\n",
      "{'max_depth': 10, 'learning_rate': 0.06749042709410855, 'num_leaves': 861, 'min_data_in_leaf': 198, 'max_bin': 260, 'lambda_l1': 0.1797587862399534, 'lambda_l2': 0.5101226762587391, 'min_child_weight': 4, 'bagging_fraction': 0.5538398612031032, 'pos_bagging_fraction': 0.8877450359595508, 'neg_bagging_fraction': 0.004408679786679026}\n"
     ]
    }
   ],
   "source": [
    "#optimize by using optuna\n",
    "def optimizeLGBM(trial):\n",
    "    lgbm = LGBMClassifier(\n",
    "                          task = \"train\",\n",
    "                          objective = \"binary\", #cross-entropy\n",
    "#                           boosting = \"gdbt\", #rf\n",
    "                          n_estimators=100,\n",
    "                          # to deal with overfitting, very important param\n",
    "                          max_depth = trial.suggest_int('max_depth',10,20),\n",
    "                          learning_rate = trial.suggest_float('learning_rate',0.02,0.1),\n",
    "                          num_leaves = trial.suggest_int('num_leaves',500,1000),\n",
    "                          min_data_in_leaf = trial.suggest_int('min_data_in_leaf',100,200),\n",
    "                          metric = \"auc\",\n",
    "                          #if max_bin becomes small, the accuracy goes up\n",
    "                          max_bin = trial.suggest_int('max_bin',255,300),\n",
    "                          tree_learner = \"data\",\n",
    "                          lambda_l1 = trial.suggest_loguniform('lambda_l1', 1e-3, 10.0),\n",
    "                          lambda_l2 = trial.suggest_loguniform('lambda_l2', 1e-3, 10.0),\n",
    "                          # to deal with overfitting\n",
    "                          min_child_weight = trial.suggest_int('min_child_weight', 1, 10),\n",
    "                          random_state=100,\n",
    "                          #for bagging imbalanced\n",
    "                          bagging_fraction = trial.suggest_float('bagging_fraction', 0,1),\n",
    "                          pos_bagging_fraction = trial.suggest_float('pos_bagging_fraction', 0,1),\n",
    "                          neg_bagging_fraction = trial.suggest_float('neg_bagging_fraction', 0,1),\n",
    "                          is_unbalance = True\n",
    "#                           class_weight={0: 1, 1: 14.291397}\n",
    "#                           boosting = \"gdbt\", #rf\n",
    "#                           min_gain_to_split = ,\n",
    "#                           bagging_fraction = ,\n",
    "#                           early_stopping_round = ,\n",
    "    )\n",
    "    #cross validation K=5\n",
    "    score = cross_val_score(lgbm, X_processed, Y_model, cv=StratifiedKFold(n_splits=5, shuffle=True),\n",
    "                            scoring=\"roc_auc\")\n",
    "    return score.mean()\n",
    "\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "LGBM_study = optuna.create_study(direction='maximize')\n",
    "LGBM_study.optimize(optimizeLGBM, show_progress_bar=True, n_trials=10)\n",
    "\n",
    "# Print the best parameters\n",
    "print(LGBM_study.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b5e99aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply model and fit\n",
    "optimized_LGBM = LGBMClassifier(task = \"predict\",\n",
    "                          objective = \"binary\", # cross-entropy\n",
    "#                           boosting = gdbt, #rf\n",
    "                          n_estimators=100,\n",
    "                          # to deal with overfitting, very important param\n",
    "                          max_depth = LGBM_study.best_params['max_depth'],\n",
    "                          learning_rate = LGBM_study.best_params['learning_rate'], # if it becomes 0.01(maybe?)the result proba becomes extremely small\n",
    "                          num_leaves = LGBM_study.best_params['num_leaves'],\n",
    "                          min_data_in_leaf = LGBM_study.best_params['min_data_in_leaf'],\n",
    "                          metric = \"auc\",\n",
    "                          #if max_bin becomes small, the accuracy goes up\n",
    "                          max_bin = LGBM_study.best_params['max_bin'],\n",
    "                          tree_learner = \"data\",\n",
    "                          lambda_l1 = LGBM_study.best_params['lambda_l1'],\n",
    "                          lambda_l2 = LGBM_study.best_params['lambda_l2'],\n",
    "                          # to deal with overfitting\n",
    "                          min_child_weight = LGBM_study.best_params['min_child_weight'], #LGBM_study.best_params['min_child_weight']\n",
    "                          random_state=100,\n",
    "                          bagging_fraction = LGBM_study.best_params['bagging_fraction'],\n",
    "                          pos_bagging_fraction = LGBM_study.best_params['pos_bagging_fraction'],\n",
    "                          neg_bagging_fraction = LGBM_study.best_params['pos_bagging_fraction'],\n",
    "                          is_unbalance = True\n",
    "                               )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "142fa419",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] min_data_in_leaf is set=198, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=198\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1797587862399534, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1797587862399534\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5538398612031032, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5538398612031032\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.5101226762587391, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.5101226762587391\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=198, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=198\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1797587862399534, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1797587862399534\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5538398612031032, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5538398612031032\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.5101226762587391, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.5101226762587391\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=198, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=198\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1797587862399534, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1797587862399534\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5538398612031032, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5538398612031032\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.5101226762587391, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.5101226762587391\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=198, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=198\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1797587862399534, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1797587862399534\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5538398612031032, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5538398612031032\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.5101226762587391, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.5101226762587391\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=198, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=198\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.1797587862399534, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1797587862399534\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5538398612031032, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5538398612031032\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.5101226762587391, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.5101226762587391\n",
      "Average ROC AUC Score 0.8786365497775094\n",
      "Standard Deviation of ROC AUC Score 0.0006171363645405311\n",
      "[0.87843769 0.87948166 0.87784048 0.87820868 0.87921424]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 5 artists>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# evaluate\n",
    "scores = cross_val_score(\n",
    "    optimized_LGBM, \n",
    "    X_processed, \n",
    "    Y_model, \n",
    "    cv=StratifiedKFold(n_splits=5, shuffle=True\n",
    "                       ,random_state=100\n",
    "                      ),\n",
    "    scoring='roc_auc'\n",
    ")\n",
    "print(\"Average ROC AUC Score\", np.mean(scores))\n",
    "print(\"Standard Deviation of ROC AUC Score\", np.std(scores))\n",
    "# Plot 5 scores in bar plot\n",
    "print(scores)\n",
    "plt.bar(list(map(lambda i: f\"Fold #{i}\", range(1, 6))), scores)\n",
    "\n",
    "#0.8753111530570191\n",
    "#0.8756329404995423\n",
    "#0.8780611462672319 when iterate 10 times\n",
    "#0.8786665892827801 when iterate 100 times\n",
    "#0.8786365497775094 -> trial 7 when iterate 10 times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d01cec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_exam = pd.read_csv('../data/X_exam.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8ab45d22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data preprocessing...\n"
     ]
    }
   ],
   "source": [
    "print(\"Data preprocessing...\")\n",
    "dist_GIT = rangesum(\n",
    "    'GIT', \n",
    "    r\"202205[0-9]{2}\", \n",
    "    \"cts\", \n",
    "    equal_dist(31)\n",
    ")(X_exam)\n",
    "dist_VAT = rangesum(\n",
    "    'VAT', \n",
    "    r\"20220[17](?:[01][0-9]|2[0-5])\", \n",
    "    \"ts\", \n",
    "    np.concatenate((equal_dist(25), equal_dist(25)))\n",
    ")(X_exam)\n",
    "entire_days = 31 + 29 + 31 + 30 + 31 + 30 + 31 + 25\n",
    "entire = rangesum(\n",
    "    'Entire', \n",
    "    r\"2022[0-9]{4}\", \n",
    "    \"cts\", \n",
    "    equal_dist(entire_days)\n",
    ")(X_exam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3a7ac4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_exam_preprocess = preprocess(\n",
    "    X_exam, \n",
    "    [\n",
    "        column(['age_code']),\n",
    "        one_hot_encode('gender'),\n",
    "        one_hot_encode('region_code'),\n",
    "        dist_GIT,\n",
    "        dist_VAT,\n",
    "        entire\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9c7e049a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age_code</th>\n",
       "      <th>gender_1</th>\n",
       "      <th>gender_2</th>\n",
       "      <th>region_code_0</th>\n",
       "      <th>region_code_1</th>\n",
       "      <th>region_code_2</th>\n",
       "      <th>region_code_4</th>\n",
       "      <th>region_code_5</th>\n",
       "      <th>region_code_6</th>\n",
       "      <th>region_code_7</th>\n",
       "      <th>...</th>\n",
       "      <th>region_code_17</th>\n",
       "      <th>region_code_18</th>\n",
       "      <th>cGIT</th>\n",
       "      <th>tGIT</th>\n",
       "      <th>sGIT</th>\n",
       "      <th>tVAT</th>\n",
       "      <th>sVAT</th>\n",
       "      <th>cEntire</th>\n",
       "      <th>tEntire</th>\n",
       "      <th>sEntire</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008197</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000195</td>\n",
       "      <td>0.004158</td>\n",
       "      <td>0.003473</td>\n",
       "      <td>0.004441</td>\n",
       "      <td>0.000978</td>\n",
       "      <td>0.002425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001943</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008197</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008194</td>\n",
       "      <td>0.004158</td>\n",
       "      <td>0.020179</td>\n",
       "      <td>0.013322</td>\n",
       "      <td>0.003421</td>\n",
       "      <td>0.009199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.538462</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002049</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000512</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003608</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002079</td>\n",
       "      <td>0.003622</td>\n",
       "      <td>0.000278</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.000997</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age_code  gender_1  gender_2  region_code_0  region_code_1  region_code_2  \\\n",
       "0  0.230769       0.0       1.0            0.0            0.0            0.0   \n",
       "1  0.692308       0.0       1.0            0.0            0.0            0.0   \n",
       "2  0.230769       0.0       1.0            0.0            0.0            1.0   \n",
       "3  0.538462       1.0       0.0            0.0            1.0            0.0   \n",
       "4  0.538462       0.0       1.0            0.0            0.0            1.0   \n",
       "\n",
       "   region_code_4  region_code_5  region_code_6  region_code_7  ...  \\\n",
       "0            1.0            0.0            0.0            0.0  ...   \n",
       "1            0.0            0.0            0.0            0.0  ...   \n",
       "2            0.0            0.0            0.0            0.0  ...   \n",
       "3            0.0            0.0            0.0            0.0  ...   \n",
       "4            0.0            0.0            0.0            0.0  ...   \n",
       "\n",
       "   region_code_17  region_code_18      cGIT  tGIT      sGIT      tVAT  \\\n",
       "0             0.0             0.0  0.008197   0.0  0.000195  0.004158   \n",
       "1             0.0             0.0  0.000000   0.0  0.000000  0.000000   \n",
       "2             0.0             0.0  0.008197   0.0  0.008194  0.004158   \n",
       "3             0.0             0.0  0.002049   0.0  0.000512  0.000000   \n",
       "4             0.0             0.0  0.000000   0.0  0.000000  0.002079   \n",
       "\n",
       "       sVAT   cEntire   tEntire   sEntire  \n",
       "0  0.003473  0.004441  0.000978  0.002425  \n",
       "1  0.000000  0.001943  0.000000  0.002560  \n",
       "2  0.020179  0.013322  0.003421  0.009199  \n",
       "3  0.000000  0.003608  0.000000  0.002000  \n",
       "4  0.003622  0.000278  0.000489  0.000997  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_exam_preprocess.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a29356",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_exam = np.zeros(X_exam.shape[0])\n",
    "k = 5\n",
    "kf = StratifiedKFold(n_splits=k)\n",
    "for tr_index, val_index in kf.split(X_model,Y_model):\n",
    "    X_tr,Y_tr = X_model.iloc[tr_index],Y_model.iloc[tr_index]\n",
    "    X_val, Y_val = X_model.iloc[val_index],Y_model.iloc[val_index]\n",
    "    \n",
    "    optimized_LGBM.fit(X_tr,Y_tr,eval_metric='auc',eval_set=[(X_tr,Y_tr),(X_val,Y_val)])\n",
    "    proba = optimized_LGBM.predict_proba(X_exam)[:,1]\n",
    "    Y_exam = Y_exam + proba\n",
    "Y_exam = Y_exam/k\n",
    "thresholds = np.array([0.5,0.7,0.75,0.8])\n",
    "# the ratio of high prob with different thresholds\n",
    "for num in thresholds: \n",
    "    filtered = Y_exam[np.where(Y_exam>num)]\n",
    "    print(\"the number of probability more than %.2f is %d:\" %(num,len(filtered)))\n",
    "    print(\"the ratio of probability more than %.2f is : %.4f\"%(num, float(len(filtered))/len(Y_exam)))\n",
    "    print('---------------------------------------------------\\n')\n",
    "# res = pd.DataFrame({'business prob':Y_exam})\n",
    "# res.to_csv(\"./part1.csv\")\n",
    "# the number of probability more than 0.50 is 64713:\n",
    "# the ratio of probability more than 0.50 is : 0.3236\n",
    "# ---------------------------------------------------\n",
    "\n",
    "# the number of probability more than 0.70 is 36457:\n",
    "# the ratio of probability more than 0.70 is : 0.1823\n",
    "# ---------------------------------------------------\n",
    "\n",
    "# the number of probability more than 0.75 is 20901:\n",
    "# the ratio of probability more than 0.75 is : 0.1045\n",
    "# ---------------------------------------------------\n",
    "\n",
    "# the number of probability more than 0.80 is 10084:\n",
    "# the ratio of probability more than 0.80 is : 0.0504\n",
    "# ---------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61c0fc1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## task2\n",
    "for th in [0.4,0.45,0.5,0.55, 0.6]:\n",
    "    profit = 0\n",
    "    for tr_index, val_index in kf.split(X_model,Y_model):\n",
    "        X_tr,Y_tr = X_model.iloc[tr_index],Y_model.iloc[tr_index]\n",
    "        X_val, Y_val = X_model.iloc[val_index],Y_model.iloc[val_index]\n",
    "\n",
    "        optimized_LGBM.fit(X_tr,Y_tr,eval_metric='auc')\n",
    "        proba = optimized_LGBM.predict_proba(X_val)[:,1]\n",
    "\n",
    "        df = pd.DataFrame({'business_prob':proba},index=val_index)\n",
    "        res = pd.concat([Y_val,df],axis=1)\n",
    "        filtered = res[res['business_prob']>th]\n",
    "\n",
    "        profit += filtered['business'].sum()* 500000*0.01 - 400*filtered.shape[0]\n",
    "    # avg profit\n",
    "    print(\"---------------------------------------------------------\")\n",
    "    print(\"when threshold is %.2f, the avg profit is %.2f\" %(th,profit/5))\n",
    "    print(\"---------------------------------------------------------\")\n",
    "# when threshold is 0.4, the avg profit is 25932640.00\n",
    "# when threshold is 0.45, the avg profit is 26372160.00\n",
    "# when threshold is 0.5, the avg profit is 26628040.00\n",
    "# when threshold is 0.55, the avg profit is 26650400.00\n",
    "# when threshold is 0.6, the avg profit is 26306360.00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5f823e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# references\n",
    "# https://lightgbm.readthedocs.io/en/latest/Parameters.html\n",
    "# http://devdoc.net/bigdata/LightGBM-doc-2.2.2/Parallel-Learning-Guide.html\n",
    "# https://lightgbm.readthedocs.io/en/latest/pythonapi/lightgbm.LGBMClassifier.html\n",
    "# https://www.kaggle.com/code/rmiperrier/tps-mar-lgbm-predict-proba-vs-predict/notebook\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
    "# https://www.kaggle.com/code/kageyama/predict-by-lightgbm\n",
    "# https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_csv.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('ai_learning')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "3fbfc89dcf5742aaeef0feb656121d5a1cfee5cf52a7760ff9deb55a4a1d42e1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
